{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca660e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6752d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"gan.ipynb\" in os.listdir():\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9385901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474d6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fcc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils.batch import rebatch\n",
    "from src.data_utils.data import get_training_iterators\n",
    "from src.model.loss_optim import MultiGPULossCompute, SimpleLossCompute\n",
    "from src.model.model import make_model, NoamOpt, LabelSmoothing, translate_sentence\n",
    "from src.utils.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853e827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = get_tokenizer(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2094ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: MyIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, test_iter, train_idx, dev_idx, test_idx = get_training_iterators(\"tur\", batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a76160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe2d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini dev set\n",
    "with open(\"data/tr/tur.dev.tgt\", encoding=\"utf-8\") as infile:\n",
    "    toystrings = [x.strip() for x in infile.readlines()[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e9227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toyset = [torch.LongTensor([1] + tok.Encode(x) + [2])  for x in toystrings]\n",
    "toyset = torch.nn.utils.rnn.pad_sequence(sequences=toyset, padding_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0c8188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
       "        [ 5605,     8,  1330,  ...,     8,   771,  2804],\n",
       "        [27861,  2475, 10284,  ...,  3987,  5057, 11694],\n",
       "        ...,\n",
       "        [    3,     3,     3,  ...,     3,     3,     3],\n",
       "        [    3,     3,     3,  ...,     3,     3,     3],\n",
       "        [    3,     3,     3,  ...,     3,     3,     3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa5a24",
   "metadata": {},
   "source": [
    "Two critics:\n",
    "- Input related to output or not\n",
    "- Classifier into poetry, prose, generated, scrambled poetry\n",
    "\n",
    "One word/token selector:\n",
    "- Choose tokens from input sequence to use for topic\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b709c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import torchtext as tt\n",
    "from src.data_utils.batch import MyIterator\n",
    "from src.model.model import batch_size_val\n",
    "\n",
    "def each_line(fname):\n",
    "    c = 0\n",
    "    lines = []\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            if line.count(\" \") > 200 or line.count(\" \") < 10:\n",
    "                continue\n",
    "            lines.append(line.strip())\n",
    "            c += 1\n",
    "            if c >= 2000000: \n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def make_iter(lines, tokenizer, batch_size=256):\n",
    "    \n",
    "    def tok(seq):\n",
    "        return tokenizer.EncodeAsIds(seq)\n",
    "\n",
    "    field = data.Field(tokenize=tok, init_token=1, eos_token=2, pad_token=3, use_vocab=False)\n",
    "    #ds = data.TabularDataset(fpath, \"tsv\", [(\"src\", field)], skip_header=True)\n",
    "\n",
    "    examples = [tt.data.Example.fromdict({\"src\": x}, {\"src\": (\"src\", field)}) for x in lines]\n",
    "    ds = tt.data.Dataset(examples, {\"src\": field})\n",
    "    iter = MyIterator(ds, batch_size=batch_size, device=\"cpu\",\n",
    "                             repeat=False, sort_key=lambda x: len(x.src),\n",
    "                             batch_size_fn=batch_size_val, train=False, sort=True)\n",
    "\n",
    "    return iter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b8dcd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/example.py:52: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "prose_iter = make_iter(each_line(\"data/tr/prose/prose_gan.txt\"), tok, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb60edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "to_scramble = each_line(\"data/tr/tur.train.tgt\")\n",
    "scrambled = []\n",
    "for poem in to_scramble:\n",
    "    new_poem = poem.split(\"¬\")\n",
    "    random.shuffle(new_poem)\n",
    "    scrambled.append(\"¬\".join(new_poem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_iter = make_iter(scrambled, tok, batch_size=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a3757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbaa96c4",
   "metadata": {
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68c72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bd4ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from src.model.model import MultiHeadedAttention, PositionwiseFeedForward, \\\n",
    "                    PositionalEncoding, Encoder, EncoderLayer, Generator, Embeddings\n",
    "import torch.nn as nn\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, src_embed, generator):\n",
    "        super(Critic, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        self.generator = generator\n",
    "        self.steps = 0\n",
    "\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"Pass the input (and mask) through each layer in turn.\"\"\"\n",
    "        x = self.src_embed(x)\n",
    "        for layer in self.encoder.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.encoder.norm(x)    \n",
    "\n",
    "\n",
    "def make_critic(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"\"\"Helper: Construct a model from hyper-parameters.\"\"\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    generator = Generator(d_model, tgt_vocab)\n",
    "    embed = nn.Sequential(Embeddings(d_model, src_vocab), c(position))\n",
    "    encoder = Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N)\n",
    "    critic = Critic(encoder, embed, generator)\n",
    "    \n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in critic.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "\n",
    "    return critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a01ac364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/plzen1/home/memduh/versetorch/src/model/model.py:264: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "ntokens = 32000\n",
    "enc_dec = make_model(ntokens, ntokens, N=6).to(device)\n",
    "token_selector = make_critic(ntokens, 2, N=2).to(device)\n",
    "style_critic = make_critic(ntokens, 4, N=2).to(device)\n",
    "relevance_critic = make_critic(ntokens + 1, 1, N=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1f2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "\n",
    "def prep_tensors( src, trg, pad=3):\n",
    "    src_mask = (src != pad).unsqueeze(-2)\n",
    "    trg_in = trg[:, :-1]\n",
    "    trg_y = trg[:, 1:]\n",
    "    trg_mask = make_std_mask(trg_in, pad)\n",
    "    return src, trg_y, src_mask, trg_mask\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    \"\"\"Create a mask to hide padding and future words.\"\"\"\n",
    "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "    tgt_mask = tgt_mask & Variable(\n",
    "        subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "    return tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb11ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f519b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a93f0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dae_input(tgt, token_selector):\n",
    "    select_prob_embeds = token_selector.forward(tgt.to(device), \n",
    "                                         (tgt != 3).unsqueeze(-2).to(device))\n",
    "    select_prob = token_selector.generator(select_prob_embeds)\n",
    "    select_indices = torch.max(select_prob, dim=2).indices.type(torch.ByteTensor)\n",
    "    dae_list = []\n",
    "    for ind, row in zip(select_indices, tgt):\n",
    "        dae_list.append(torch.masked_select(row, ind)[:15])\n",
    "    dae_input = torch.nn.utils.rnn.pad_sequence(dae_list, batch_first=False, padding_value=3)\n",
    "    return dae_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc8eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55acd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "740266cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebatched = (rebatch(3, b) for b in train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa72320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a323a19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "548db73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.adafactor import Adafactor\n",
    "\n",
    "enc_dec_opt = NoamOpt(enc_dec.src_embed[0].d_model, 1, 2000,\n",
    "                        torch.optim.Adam(enc_dec.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "#enc_dec_opt = Adafactor(enc_dec.parameters())\n",
    "\n",
    "style_criterion = nn.BCELoss()\n",
    "relevance_criterion = nn.BCELoss()\n",
    "\n",
    "token_optim = Adafactor(token_selector.parameters())\n",
    "style_optim = Adafactor(style_critic.parameters())\n",
    "rel_optim = Adafactor(relevance_critic.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "563f360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9a064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance_input(dae_input, tgt):\n",
    "    mid_point = torch.ones((tgt.shape[0], 1), dtype=torch.long) * ntokens\n",
    "    return torch.cat((dae_input, mid_point.to(device), tgt), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8261d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_steps = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f019d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get validation iterator\n",
    "\n",
    "\n",
    "def validate_batch(model, src, max_len=256, start_symbol=1, end_symbol=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    src_mask = (src != 3).unsqueeze(-2)\n",
    "    memory = model.encode(src.to(device), src_mask.to(device))\n",
    "    ys = torch.ones(src.shape[0], 1).fill_(start_symbol).type_as(src.data).to(device)\n",
    "    finished = torch.zeros((src.shape[0], 1))\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask,\n",
    "                           Variable(ys).to(device),\n",
    "                           Variable(subsequent_mask(ys.size(1)).type_as(src.data)).to(device))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        # next_word = next_word.data_utils[0]\n",
    "        unsqueezed = next_word.unsqueeze(1)\n",
    "        for c, token in enumerate(unsqueezed):\n",
    "            if token == end_symbol:\n",
    "                finished[c] = 1\n",
    "        if sum(finished) >= src.shape[0]:\n",
    "            break\n",
    "        ys = torch.cat([ys, unsqueezed], dim=1)\n",
    "                        # torch.ones(src.shape[0], 1).type_as(src.data_utils).fill_(next_word).to(device)], dim=1)\n",
    "    return ys\n",
    "\n",
    "\n",
    "def greedy_generate(model, src, max_len=256, start_symbol=1, end_symbol=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    src_mask = (src != 3).unsqueeze(-2)\n",
    "    memory = model.encode(src.to(device), src_mask.to(device))\n",
    "    ys = torch.ones(src.shape[0], 1).fill_(start_symbol).type_as(src.data).to(device)\n",
    "    finished = torch.zeros((src.shape[0], 1))\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask,\n",
    "                           Variable(ys).to(device),\n",
    "                           Variable(subsequent_mask(ys.size(1)).type_as(src.data)).to(device))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        # next_word = next_word.data_utils[0]\n",
    "        unsqueezed = next_word.unsqueeze(1)\n",
    "        for c, token in enumerate(unsqueezed):\n",
    "            if finished[c] == 1:\n",
    "                unsqueezed[c] = 3\n",
    "            if token == end_symbol:\n",
    "                finished[c] = 1\n",
    "        if sum(finished) >= src.shape[0]:\n",
    "            break\n",
    "        ys = torch.cat([ys, unsqueezed], dim=1)\n",
    "                        # torch.ones(src.shape[0], 1).type_as(src.data_utils).fill_(next_word).to(device)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0897944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_smoothing = LabelSmoothing(size=32000, padding_idx=3, smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856c0faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ayrılığın sınırlı ışığında¬ışıldar gözler¬dar gelir dünya¬sıkıcı karanlıktan¬çıkış başlar¬sevgi akla gelince¬ışık küçücüktür¬sevgi karanlığında¬sonsuzluğu hatırlatır insana¬ışık kandırıcıdır belki¬ayrılığı sevenler için¬orada yuvarlak bir masa¬üç beş sigara biraz da çay¬sevgi karanlığında herşey¬coşkuyla¬zaten aranan da o değil mi¬sınırlı değilmiş hiçbir şey',\n",
       " 'Şair sözün gösterer,¬Gözel gözün gösterer.¬Payız özün gösterer,¬Saralmış yarpağıyla.¬Uzaqda quzey durar,¬Şa ⁇ ta qelbi hey vurar.¬Önümde muzey qurar,¬Heyat çılpaqlığıyla.¬Yel eser deyinerek,¬ ⁇ um-paltar geyinerek,¬Fe ⁇ r eder öyünərek¬Insan torpaqlığıyla.',\n",
       " 'Ey yakarış¬Ey uyanış¬Ey sevgi¬Ey aşk¬Ey arayış¬Ey tükeniş¬Ey özleyiş¬Uyanın artık¬O derin uykulardan¬Ve devam edin¬Katıksızca aramaya¬Aşkı,sevdayı,¬Yakarışı,uyanışı¬Arayışı,tükenişi¬Özleyişi,özlemi',\n",
       " 'ben ölsemde aşkım cümle alemde¬kulakdan kulaga yayılır belki¬adımız gecer her bir kalemde¬gönül nikahımız kıyılır belki¬sevdik sevildik ölürcesine¬başını sonunu bilircesine¬haykırdım dagları delercesine¬ölmeyen sevdamız duyulur belki',\n",
       " 'Lale, sümbül, çiğdem, Nergizim derken,¬Hercai menekşe, kıs kıs gülerken.¬Kardelenim boynu bükük beklerken,,¬İhanete hiç yol olur mu ahmak.¬Hani İnsan nerde kaldı bu sıra,¬Sürüsel varlıksa yolcu ahıra,¬At eşekle döndü bak gör katıra,¬Kısırlardan hiç döl olur mu ahmak.¬Kemaletle evrilir kişi özü,¬Vezir de, rezil de eyleyen sözü,¬Yakanı ateştir, pişiren közü,¬Yanmadan da hiç kül olur mu ahmak.',\n",
       " 'herkes her şey¬yok hiçbir şey¬şey¬şey¬şey¬bir ben bir şey değilim¬bir de hiçler¬hiçbir şey değil¬bu bence böyleciler¬ve de bizden çok bizciler¬çoğala çoğala¬artı eksi sonsuza doğru¬dolumsu kar tanelerince¬düşer yeni açmış¬menekşenin tepesine¬geçit vermezler¬altın levhanın¬solgun ve¬kör uçlu oklarına¬kapılarını birbirine vurmakta¬beyt-i efkârın¬bu karanlık akşamüstü tipisi¬oyuk öylesine büyük ki¬tutmaz çıktığı yeri bir daha¬alemin köhne çivisi',\n",
       " 'Saklasam samanı saklar gibi yaşımı¬Ihtıyarlığımda işime bilmem yararmı¬Anlatırmı geçmişten tenim arzularını¬Gelip,geçen yolcuların geride unuttuklarını¬Sahi işe yararmı,saklasam yaşımı¬Saçlarıma düşen yıldızlar,kararırmı¬Tenim buruşmuş ken dirilip,uyanırmı¬Tutarmı dizlerim kırlarda papatyalarımı¬Gözlerim yine eskisi gibi capcanlı¬Yüreğim ilk günki gibi sevgiliye ayarlı¬Avuçlarımda bir serce yine kalırmı¬Tutarmı sevgilim gözlerinde arzularımı¬Ötermi bülbüller gül dalında baharımı¬Derin maviler yine beni sararmı¬Yaşanırmı yaşayamadıklarım sil baştan¬Yaptığım hatalar doğruluğa çıkarmı¬Saklasam yaşımı işime yararmı¬Sakla samanı gelir zamanı,uyarmı¬Nasrettinin mayası beyşehir gölüne sığarmı¬Dişlerim yeniden,sıralanırmı,sahi¬Çocukluğum ah çocukluğum¬Uçurtmam ve bilyelerim¬Bilik oynadığım çocukluk akrenlerim¬Tikoo oyununda alnımdaki terim¬Futbol maçı sonrası ağzımı dayayıpta su içtiğim çeşme¬Yine yüreğimi ferahlarmı¬Saklasam çocukluğumu¬Duvarlara yazı yazdığım gençliğimi¬O güzel bayramlarımı,saklasam¬İlk öptüğüm sevgili yerine uykuda yastığımı¬Oltayla ttuğum ilk balığımı¬Salsam suya canlanırmı¬Gördüğüm işlemeli ahşap evler kalırmı¬Bahçelerinde zambaklar,güller¬Hanım eli ve mor sümbüller¬Saklasam yaşımı,kalırmı¬Sahi eski komşuluklar canlanırmı.....!',\n",
       " 'Bu millet kimlerle gurur duymadı,¬Yurttaşa lan diyenleri alkışla...¬Kafa yorma boşver, uydu uymadı,¬Sözlerinden cayanları alkışla...¬Meydanları doldur, yürekten bağır,¬Beraber yürürken şarkıyı çağır.¬Zemin oynaklaştı bak ağır ağır,¬Alttan alttan oyanları alkışla...¬Yalancı muteber, inan sözüne,¬Çok şükür de, tükürse de yüzüne.¬Gündüz vakti fener tutup gözüne,¬Din, imanla soyanları alkışla...¬Aydınlanma kötü, karşı dur kinle,¬Kandırsınlar seni şeytanla, cinle.¬Zekana hakaret edeni dinle,¬Seni aptal sayanları alkışla...',\n",
       " 'Gülerken ağladım, gün yüzü görmedim¬Eller gibi dünyadan muradımı almadım¬Kırılsın kollarım sevdiğim saramadım¬Ne yaşadım, ne yaşıyorum, ne yaşarım¬Gülmedi felek bu bahtı karaya¬Nice zalimler girdi araya¬Ne desin ki evlat ana babaya¬Talihe küsüp kaderimi yaşadım',\n",
       " 'Kaderi değiştirmek bazen bizim elimizde değilki¬Ve her şeye yeniden başlamak istiyorum¬Küçük bir evim olsun¬Küçükte bir bahçesi¬Belki evlenirim bir kızım olur¬Gözyaşlarımız hayatımıza çare değil ki¬İnandığım her şey bir bir değişti¬Belki de bütün sorun benim huylarım¬Kaybetmeleri de kazanmalar kadar kabullenmek¬Belki de tek çare bu bilmiyorum¬Ben hep derdim ki istersen olur her şey¬Mücadele ve uğraşlarla varılır istenilen yola¬Bazen öyle bir denk geliyor ki¬Ne kadar çok istiyorsun o olması istediğin şeyi¬Kazanmak için ne uğraşlar didinmeler¬Öyle bir denk geliyor ki¬Ne söylesen ne yapsan boş¬Ve elin kolun bağlanıyor yapacak bir şey de kalmıyor geriye¬Hangi yolu denesen orada bir engel¬Tek sorun biliyorum kaybetmeleri kabullenememek¬İstiyoruz ki her şey,istediğimiz gibi olsun¬Oluruna bırakamamak benim en büyük sorunum¬İstiyorum ki hep güzel şeyler yaşayalım¬Hep güzel şeyler olsun¬Bak işte bende akıllandım sandığın gibi değilim artık¬Eskisi gibi gücümde yok uğraşlara¬Biri kaderimi yazsın benim biride yönetsin¬Ve ben her şeye yeniden başlamak istiyorum¬Başka bir şehirde yeni bir hayatla¬Bambaşka biri olsun bu içimdeki ben¬Sabahları uyanıp şarkılar söyleyeyim o küçük evimde¬Bahçemde kuşların sesini dinleyeyim¬Yeşilliklerin kokusunu çekerek içime¬Çiçekler ekerim bir bir saksılara¬Bundan sonra yorulmam orda burda arzularımla¬İşime gider gelirim¬Bırakırım onun dışındakileri oluruna¬Ve anladım bak artık akıllandım¬Kazanmalar kadar kaybetmelerde var insan hayatında¬Bu kaybediş için kahrolmam artık',\n",
       " \"İstanbul Balıklı Rum hastanesinden içeri¬Bir yaşlı kadın girdi, üstelik Rum, adı da Eleni¬Girmiş vakt-i zamanında, zaman-ı mekana¬Üzerinde beyaz esvaplar, maruzat verir doktora¬Hazır, bürülmüş, kapıda kefen beyaz¬Ama Eleni, ama Eleni dimdik ayakta hele telli saçları¬Penceresine konan kardan serçe kuşları¬İstanbul Balıklı Rum hastanesinin koridoru uzun uzun¬Belli ki ömür burada kıssadan uzun¬Koridorlar, koğuşlar dökmüş saçlarını tel tel¬Eleni, Eleni sırma saçlarınla olmuşsun şimdi kel..¬Dudaklar büzülmüş, bel egilmiş, göz torbalı¬Eleni'nin kalbi hala onsekizinde olmalı¬Kimler geçti bilirmisin surlar içinde bu hastanede¬Kiminin arkada gözü, kiminin Eminönü'nde¬Kimi bıçak sırtında, kimi bıçağın altında¬Kimi geçim derdinde kimi kaybolan zamanda¬istanbul Balıklı Rum hastanesinin bahçesinde güller açtı¬Kaldırdı eleni ellerini, tanrıya açtı¬Çamlar açtı, kavak açtı, duvar açtı ellerini¬Yalvardı tanrıya kurtar diye beni...¬Aksanı İstanbullu balıkçı Hayri'den ögrenmiş¬Rastgele demeyi hüznün sümbülü Eleni¬Hep yedi tepe derdi, derdim de olsa yedi tepe¬Sonunda gözlük takıldı, gözlüksüz mavi gözlere.¬Balıklı Rum hastanesinde bir kız yatar¬Üstelik Rum adıda Eleni¬Mavi gözleriyle, sırma saçları, ince belli Eleni¬İstanbul'un arka sokaklarını, lüks restorantlarını¬En iyi o bilir, ondandır ayağının kırığı¬En fazla iki gün durdu hastane loşunda¬Yeni loş duvarlar arasında kayboldu zannımca¬Silivrikapıyı bilmezdi, edecek kalıcı mekan¬Ne dost kalacak çevreden, ne de serv-i revan..\",\n",
       " 'Güneşin kızıl yanakları allanınca¬Sürgün yüreklere¬Düşer sevdalar¬Asma yaprağına¬Sarıp sarmaladığım yar¬Süslemesi sen olan¬Ne çok hayallerim var',\n",
       " 'Dışarısı ayaz¬Dışarısı beyaz¬Dışarısı buz¬Ağlamaklı sus pus¬Yine yaban ele düştü yolumuz¬İçerimiz tufan¬İçerimiz duman¬İçerimiz kan¬Gurbet elde kırılan¬Yüreğimiz,kanadımız,kolumuz¬Aramızda çöl¬Aramızda kum¬Aramızda uçurum¬Böylesine uzak kaldı koynumuz',\n",
       " 'Tesir etmez yağan kurşun,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Zoru seçmem ilim varken.¬Özümde sözümde Allah,¬Esirger elhamdullah,¬Hamt eden kurtulur vallah,¬Korkum yok ya hey derken.¬Sabırla dağlar aşarım,¬Yılmadan durmaz koşarım,¬Bilemem kaç gün yaşarım,¬Kaygı duymam ecel sırken,¬Kitabım kuranı kerim,¬En engin naçiz sözlerin,¬Her lahzada Allah derim,¬Söylerim sesim gür iken.¬Garibim yola çıkarım,¬Nefsin gururun yıkarım,¬Daim ileri bakarım,¬Gidemem önüm sur iken.¬Aşık kaya durmaz söyler,¬Divane gönlünü eyler,¬Gitti nice sultan beyler,¬Gam yemem ölüm varken.',\n",
       " 'Gözlerim kapalı, hissetmiyorum dünyanın ahengini¬Adını duyuyorum ama, bilemiyorum cümle rengini¬Göremiyorum bak, çünkü buna gözlerim engel¬Uzat ve tut ellerimi, bekletmeden hemen gel¬Duymuyor kulaklarım, kuşların güzel seslerini¬Söylemiyor dilim, sevdiklerime güzel sözlerimi¬Diyemiyorum bak, çünkü buna dilim engel¬İşaretimi gör, işaretsiz hemen bana gel¬Koşmak istiyor ayaklarım, nefesim bitene kadar¬Durmayı düşünmüyorum, rüzgar itene kadar¬Yürüyemiyorum bak, çünkü buna bacaklarım engel¬Bekletme ne olur, yanıma koşarak gel¬İnsanların başlarına gelecekleri, nereden belli¬Her insan değil midir ki; potansiyel bir engelli¬Empatiniz anlasın bizi, kaderiniz olmadan engel¬Şuursuzca yaşama hayatını, dualarınla gel',\n",
       " 'Mutluluk önünde bak,yakalamak zor,¬Seven sevilenin hep karşısında hor.¬Tutuşmuş kalpler alev alev sanki kor,¬Ruh doyar da, bedenlerimiz aç kalır..¬Seversin sevilirsin ama yürümez,¬Sevilen hiç ayaklarını sürümez.¬Yanmayan ateşin dumanı bürümez,¬Gelecek olmaz, herşey arkada kalır.¬Kendime bakarken yüzde kara kaşım,¬Yıllar akmış gitmiş,kırk ⁇ a gelmiş yaşım.¬Türlü acıyı tatmış,talihsiz başım,¬Söz unutulur, burda yazılanlar kalır...¬Bu hayata sıkı sıkıya sarılıp,¬Sevdiğin kadının peşine takılıp,¬Birgün bu yorgun bedenimde yakılıp,¬Ben giderim,aşkımız mazide kalır..',\n",
       " 'Ehlibeytim sevgim sana,¬Canım da can Ali, Ali.¬Sen ki ışık nursun bana,¬Damarda kan Ali, Ali.¬Cansın, teksin yoktur dengin,¬Karanlığa ilim zengin¬Çok türapsın, pek çok engin¬Şerefli şan Ali, Ali¬Sende gördük adaleti,¬Sen önlersin felaketi,¬Yetim kaldı Ehlibeyti,¬Mazluma yan Ali, Ali.¬Yolumuza yezit çıktı,¬Bağrımıza hançer soktu,¬Evi ocağımız yaktı,¬Evsize, han Ali, Ali¬Kanımız içildi tas, tas,¬Maraş Çorum Gazi Sivas,¬Sevenlerin tutuyor yas¬Daha da dün Ali, Ali.¬Ali uzun sana aşık,¬Yaktı bizi mazman eşek,¬Yağdı bize kurşun fişek,¬Kustular kin Ali, Ali.',\n",
       " 'Oy Nazile Nazile¬Şimdi gelir saz ile¬Sazı sözü bırakıp¬Göbek atar naz ile...¬Kızın adı müyesser¬Tablo gibi şaheser¬Huyu, güzelliğiyle¬O tanrıdan bir eser...¬Oy Mahmure Mahmure¬Gözü benzer kömüre¬Cilveli bakışıyla¬Ömür katar ömüre...¬Kızın adı Münevver¬Yüzün bana dönüver¬El dalına değil de¬Gül dalıma konuver...¬Oy Adile Adile¬Çıkalım biz tatile¬Sarmaş dolaş olalım¬Uzanalım sahile...¬O yarin adı Güzin¬Geçmedi ona sözüm¬Bu sevdanın yüzünden¬Eridi,soldu yüzüm¬Oy atiye atiye¬Bu gece gel yatıya¬Candarmalar gelince¬Saklanırız çatıya...¬Kızın adı dürüye¬Dön de bir bak geriye¬Ben canımı veririm¬Senin gibi huriye...¬Oy Cevriye Cevriye¬Boyu benzer serviye¬Onca bekar dururken¬Gönül vermiş evliye...¬Haber salın Fatma’ya¬Gece gelsin yatmaya¬Bende öyle yürek yok¬Elin bile tutmaya....',\n",
       " 'Sen gidersen dayanamam ben¬Sarhoş olur geceler birden¬Kör pınar gibi zamansız¬Ay dağlarıma gölge düşer¬Nereye baksam hicran yağar¬Çiy döker sabahlarım¬Kör kütük sarhoş olur aşk¬Yeni ateşler istemem¬Yanacaksam eğer sen yak¬Bu sevdanın akışı belli¬Peri çay gibi munzur gibi¬Geri dönmez gidenler¬Fırat gibi dicle gibi¬Söyledimya giden gidene¬Daha öpmeden gülüşünü¬Aha tam şuramda¬Pervazsız bir arzu¬En ıssız yerden savurur¬Yıldırımlar düşer başıma¬Yer yerinden oynar¬Daha diyeceklerim var sana¬Baksam yüzüne¬Bir yudum kahve gözlerin¬Havva anadan kalma bir aşk¬Demem o ki sıcak kanlı¬Esmer topraklardan geldim¬Kitaplar arasında unutulmuş¬Güller gibi yaprak yaprak¬Kilit vurulmuş aşka¬Şimdi¬Yayla güneşi gibi anılar¬Oysa gittiğin yer çok uzak¬Ateş böceğine döndü düşlerim¬Temmuz sıcağında zemheri ayında¬Unuttuğun yüzüm olmayacaktı¬Deşelemeseydin acısını¬Bu kadar erken sırdaşlığın...¬Hadi dök diyorsun¬Bir ilkbahar yıldızları gibi¬oysa¬Hınca hınç heybem sevgi dolu¬Dipsiz uçurumlarda¬Fosilleşmiş bir ceset gibi¬Bak üşüyor üşüyorum¬Bütün günler kara kış şimdi',\n",
       " 'İslam sancağını taşıyan sensin¬Yürü be Mehmet’im kim tutar seni.¬Huşuyla dinini yaşayan sensin¬Yürü be Mehmet’im kim tutar seni.¬Gururla göğsünü ger de görsünler¬Zalime dersini ver de görsünler¬Düşmanı yerlere ser de görsünler¬Yürü be Mehmet’im kim tutar seni.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.Decode(x.tolist()) for x in toyset.transpose(0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d7b214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cz-acc\t     cz-dae   eng-baseline  tur-acc\t  tur-dae\r\n",
      "cz-baseline  eng-acc  eng-dae\t    tur-baseline\r\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70729842",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = sorted(os.listdir(\"checkpoints/tur-dae\"), reverse=False, key=lambda x: int(x.partition(\".\")[0]))\n",
    "hundred_k_plus = [x for x in last if len(x) > 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d596b9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"checkpoints/tur-dae/\" + hundred_k_plus[0])\n",
    "token_selector.load_state_dict(checkpoint['selector_state_dict'])\n",
    "token_optim.load_state_dict(checkpoint['selector_optim_state_dict'])\n",
    "enc_dec.load_state_dict(checkpoint['model_state_dict'])\n",
    "#enc_dec_opt.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9115fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n",
      "Skipped overlong sample while batching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:733.)\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[0.0828, 0.2911, 0.4840, 0.1421],\n",
      "        [0.2397, 0.1369, 0.4136, 0.2098]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[0.4944, 0.0673, 0.3445, 0.0937],\n",
      "        [0.7420, 0.0362, 0.1320, 0.0898]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[0.5870, 0.1640, 0.0427, 0.2063],\n",
      "        [0.7260, 0.1334, 0.0985, 0.0422],\n",
      "        [0.8260, 0.1045, 0.0271, 0.0424],\n",
      "        [0.6001, 0.2649, 0.0287, 0.1063],\n",
      "        [0.6293, 0.0960, 0.1530, 0.1218],\n",
      "        [0.5640, 0.2067, 0.1007, 0.1287],\n",
      "        [0.8927, 0.0283, 0.0576, 0.0214],\n",
      "        [0.6823, 0.0909, 0.1616, 0.0652],\n",
      "        [0.6290, 0.0742, 0.1346, 0.1622],\n",
      "        [0.4441, 0.1834, 0.3464, 0.0261],\n",
      "        [0.8813, 0.0410, 0.0211, 0.0565],\n",
      "        [0.7922, 0.1241, 0.0468, 0.0369],\n",
      "        [0.6862, 0.1507, 0.1068, 0.0563],\n",
      "        [0.8664, 0.0621, 0.0254, 0.0461],\n",
      "        [0.3100, 0.0804, 0.5073, 0.1023],\n",
      "        [0.7105, 0.1245, 0.0627, 0.1023],\n",
      "        [0.6165, 0.1096, 0.1794, 0.0946],\n",
      "        [0.6738, 0.1061, 0.1584, 0.0617],\n",
      "        [0.7098, 0.0346, 0.1125, 0.1431],\n",
      "        [0.6513, 0.1471, 0.1105, 0.0911],\n",
      "        [0.7843, 0.1133, 0.0833, 0.0191],\n",
      "        [0.8566, 0.0431, 0.0750, 0.0253],\n",
      "        [0.5909, 0.1260, 0.2464, 0.0368],\n",
      "        [0.8821, 0.0272, 0.0335, 0.0572],\n",
      "        [0.3907, 0.2784, 0.1273, 0.2036],\n",
      "        [0.8532, 0.0496, 0.0120, 0.0852],\n",
      "        [0.5749, 0.0669, 0.0798, 0.2785],\n",
      "        [0.3849, 0.5009, 0.0566, 0.0575],\n",
      "        [0.6677, 0.1283, 0.0690, 0.1350],\n",
      "        [0.4401, 0.1900, 0.1093, 0.2606],\n",
      "        [0.5062, 0.1035, 0.0715, 0.3188],\n",
      "        [0.7499, 0.0915, 0.1004, 0.0582],\n",
      "        [0.7484, 0.0714, 0.1161, 0.0641],\n",
      "        [0.6579, 0.1298, 0.1144, 0.0979],\n",
      "        [0.3723, 0.0968, 0.1666, 0.3643],\n",
      "        [0.7143, 0.0894, 0.0958, 0.1005],\n",
      "        [0.7635, 0.0838, 0.1107, 0.0419],\n",
      "        [0.7311, 0.0525, 0.1599, 0.0565],\n",
      "        [0.7170, 0.1733, 0.0546, 0.0551],\n",
      "        [0.8416, 0.0303, 0.0558, 0.0722],\n",
      "        [0.5827, 0.1236, 0.0727, 0.2210],\n",
      "        [0.5428, 0.1580, 0.1402, 0.1590],\n",
      "        [0.6603, 0.0588, 0.1275, 0.1534],\n",
      "        [0.7708, 0.0392, 0.1287, 0.0613],\n",
      "        [0.5352, 0.0521, 0.1931, 0.2195],\n",
      "        [0.4630, 0.0654, 0.3108, 0.1609],\n",
      "        [0.8111, 0.0420, 0.1059, 0.0410],\n",
      "        [0.5283, 0.0798, 0.2419, 0.1500],\n",
      "        [0.7900, 0.1119, 0.0467, 0.0514],\n",
      "        [0.5064, 0.1363, 0.1556, 0.2017],\n",
      "        [0.8905, 0.0212, 0.0711, 0.0172],\n",
      "        [0.5495, 0.0799, 0.0664, 0.3042],\n",
      "        [0.7261, 0.0758, 0.0683, 0.1298],\n",
      "        [0.5737, 0.2192, 0.0921, 0.1151],\n",
      "        [0.6378, 0.1463, 0.1317, 0.0842],\n",
      "        [0.6818, 0.0894, 0.0304, 0.1984],\n",
      "        [0.7543, 0.0150, 0.1350, 0.0958],\n",
      "        [0.8175, 0.0551, 0.0522, 0.0751],\n",
      "        [0.4699, 0.1588, 0.2907, 0.0806],\n",
      "        [0.6775, 0.0283, 0.1875, 0.1067],\n",
      "        [0.7587, 0.0648, 0.0744, 0.1021],\n",
      "        [0.7531, 0.1067, 0.0626, 0.0776],\n",
      "        [0.8962, 0.0255, 0.0183, 0.0601],\n",
      "        [0.5912, 0.0728, 0.2127, 0.1233],\n",
      "        [0.6815, 0.1363, 0.0297, 0.1525],\n",
      "        [0.6757, 0.0187, 0.2389, 0.0667],\n",
      "        [0.7713, 0.1224, 0.0524, 0.0540],\n",
      "        [0.4318, 0.0837, 0.1618, 0.3227],\n",
      "        [0.5638, 0.1074, 0.1201, 0.2086],\n",
      "        [0.5187, 0.1892, 0.1123, 0.1799],\n",
      "        [0.5893, 0.1027, 0.1285, 0.1796],\n",
      "        [0.8007, 0.0484, 0.1303, 0.0207],\n",
      "        [0.6806, 0.0393, 0.1183, 0.1617],\n",
      "        [0.6960, 0.0854, 0.1626, 0.0561],\n",
      "        [0.7055, 0.0779, 0.0851, 0.1316],\n",
      "        [0.8152, 0.0628, 0.0616, 0.0604],\n",
      "        [0.7797, 0.0257, 0.1151, 0.0795],\n",
      "        [0.5868, 0.0921, 0.0254, 0.2957],\n",
      "        [0.5422, 0.1677, 0.1693, 0.1208],\n",
      "        [0.5441, 0.1101, 0.1602, 0.1855],\n",
      "        [0.6620, 0.0987, 0.1561, 0.0833],\n",
      "        [0.6609, 0.0951, 0.1968, 0.0472],\n",
      "        [0.7443, 0.0198, 0.1752, 0.0607],\n",
      "        [0.4951, 0.0882, 0.2972, 0.1195],\n",
      "        [0.7340, 0.1114, 0.0376, 0.1171],\n",
      "        [0.8075, 0.0639, 0.0970, 0.0315],\n",
      "        [0.5202, 0.1694, 0.2478, 0.0626],\n",
      "        [0.8658, 0.0132, 0.0839, 0.0371],\n",
      "        [0.7357, 0.0470, 0.0519, 0.1654],\n",
      "        [0.8532, 0.0280, 0.0574, 0.0614],\n",
      "        [0.6025, 0.0910, 0.2646, 0.0420],\n",
      "        [0.6208, 0.0957, 0.0584, 0.2250],\n",
      "        [0.6540, 0.0607, 0.1122, 0.1732],\n",
      "        [0.6895, 0.0688, 0.0676, 0.1741],\n",
      "        [0.8142, 0.0713, 0.0208, 0.0937],\n",
      "        [0.7465, 0.0601, 0.1305, 0.0629],\n",
      "        [0.7857, 0.1002, 0.0497, 0.0643],\n",
      "        [0.8617, 0.0329, 0.0511, 0.0543],\n",
      "        [0.3491, 0.1937, 0.0720, 0.3853],\n",
      "        [0.6669, 0.1114, 0.1740, 0.0477],\n",
      "        [0.3320, 0.2339, 0.3292, 0.1049],\n",
      "        [0.4669, 0.0768, 0.2139, 0.2424],\n",
      "        [0.8700, 0.0162, 0.0614, 0.0524],\n",
      "        [0.5127, 0.1587, 0.2081, 0.1205],\n",
      "        [0.6581, 0.1104, 0.2001, 0.0314],\n",
      "        [0.5450, 0.0273, 0.3125, 0.1151],\n",
      "        [0.4755, 0.1436, 0.1671, 0.2139],\n",
      "        [0.6263, 0.0446, 0.2400, 0.0891],\n",
      "        [0.6629, 0.0365, 0.2404, 0.0603],\n",
      "        [0.5368, 0.2936, 0.1129, 0.0567],\n",
      "        [0.7456, 0.0787, 0.1050, 0.0708],\n",
      "        [0.5167, 0.3240, 0.1224, 0.0368],\n",
      "        [0.8623, 0.0670, 0.0483, 0.0223],\n",
      "        [0.6927, 0.1171, 0.0862, 0.1041],\n",
      "        [0.6158, 0.0701, 0.0738, 0.2403],\n",
      "        [0.5399, 0.1806, 0.1500, 0.1295],\n",
      "        [0.7893, 0.0716, 0.0492, 0.0899],\n",
      "        [0.5931, 0.1315, 0.0695, 0.2059],\n",
      "        [0.7206, 0.0508, 0.1162, 0.1124],\n",
      "        [0.7441, 0.0540, 0.0369, 0.1650],\n",
      "        [0.5735, 0.1751, 0.0643, 0.1871],\n",
      "        [0.8619, 0.0157, 0.0229, 0.0995],\n",
      "        [0.7361, 0.0138, 0.1838, 0.0664],\n",
      "        [0.7199, 0.1410, 0.0601, 0.0790],\n",
      "        [0.7206, 0.0993, 0.1046, 0.0755],\n",
      "        [0.8120, 0.0439, 0.1039, 0.0402],\n",
      "        [0.7819, 0.0217, 0.1102, 0.0861],\n",
      "        [0.6145, 0.0957, 0.1815, 0.1084],\n",
      "        [0.6613, 0.1608, 0.0841, 0.0938],\n",
      "        [0.3530, 0.1009, 0.0992, 0.4469],\n",
      "        [0.6567, 0.0675, 0.1666, 0.1093],\n",
      "        [0.8718, 0.0519, 0.0233, 0.0530],\n",
      "        [0.3860, 0.0958, 0.2684, 0.2498],\n",
      "        [0.5365, 0.0320, 0.2226, 0.2089],\n",
      "        [0.7058, 0.0558, 0.1309, 0.1076],\n",
      "        [0.8265, 0.0523, 0.0346, 0.0867],\n",
      "        [0.7767, 0.0204, 0.1128, 0.0901],\n",
      "        [0.6919, 0.0414, 0.2237, 0.0430],\n",
      "        [0.5337, 0.3543, 0.0204, 0.0917],\n",
      "        [0.6741, 0.1287, 0.0628, 0.1344],\n",
      "        [0.8469, 0.0401, 0.0711, 0.0419],\n",
      "        [0.7499, 0.0963, 0.0524, 0.1014],\n",
      "        [0.6671, 0.0362, 0.1098, 0.1869],\n",
      "        [0.6874, 0.0697, 0.1657, 0.0772],\n",
      "        [0.5907, 0.0201, 0.3078, 0.0814],\n",
      "        [0.3210, 0.2407, 0.2644, 0.1739],\n",
      "        [0.5530, 0.0917, 0.2879, 0.0675],\n",
      "        [0.7966, 0.0678, 0.0514, 0.0842],\n",
      "        [0.7032, 0.0278, 0.1928, 0.0762],\n",
      "        [0.7633, 0.0221, 0.1579, 0.0567]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[0.3625, 0.0655, 0.2599, 0.3120],\n",
      "        [0.7834, 0.0068, 0.1778, 0.0319],\n",
      "        [0.9307, 0.0116, 0.0154, 0.0424],\n",
      "        [0.7659, 0.0303, 0.1377, 0.0662],\n",
      "        [0.9067, 0.0287, 0.0445, 0.0201],\n",
      "        [0.9041, 0.0098, 0.0540, 0.0320],\n",
      "        [0.7814, 0.0249, 0.1018, 0.0919],\n",
      "        [0.9023, 0.0101, 0.0649, 0.0227],\n",
      "        [0.7901, 0.0154, 0.1732, 0.0214],\n",
      "        [0.6360, 0.0813, 0.2269, 0.0558],\n",
      "        [0.7648, 0.0387, 0.1388, 0.0577],\n",
      "        [0.6393, 0.0674, 0.1970, 0.0963],\n",
      "        [0.6915, 0.0280, 0.1364, 0.1441],\n",
      "        [0.8549, 0.0135, 0.0264, 0.1052],\n",
      "        [0.7163, 0.0922, 0.0567, 0.1348],\n",
      "        [0.7165, 0.1283, 0.0920, 0.0633],\n",
      "        [0.9094, 0.0104, 0.0600, 0.0202],\n",
      "        [0.7617, 0.0210, 0.1550, 0.0623],\n",
      "        [0.7219, 0.0312, 0.1942, 0.0527],\n",
      "        [0.6521, 0.1351, 0.1542, 0.0587],\n",
      "        [0.8937, 0.0180, 0.0384, 0.0499],\n",
      "        [0.8125, 0.0032, 0.1409, 0.0433],\n",
      "        [0.7885, 0.0466, 0.0825, 0.0824],\n",
      "        [0.8926, 0.0079, 0.0607, 0.0388],\n",
      "        [0.7604, 0.0414, 0.0920, 0.1062],\n",
      "        [0.7987, 0.0648, 0.0465, 0.0900],\n",
      "        [0.9541, 0.0039, 0.0304, 0.0116],\n",
      "        [0.6997, 0.0113, 0.2102, 0.0789],\n",
      "        [0.9200, 0.0209, 0.0299, 0.0292],\n",
      "        [0.8541, 0.0444, 0.0493, 0.0522],\n",
      "        [0.6989, 0.0324, 0.2007, 0.0679],\n",
      "        [0.9231, 0.0318, 0.0291, 0.0159],\n",
      "        [0.9373, 0.0142, 0.0305, 0.0180],\n",
      "        [0.6883, 0.0140, 0.2321, 0.0655],\n",
      "        [0.7423, 0.0408, 0.0684, 0.1485],\n",
      "        [0.5394, 0.0496, 0.2722, 0.1388],\n",
      "        [0.6001, 0.0832, 0.2538, 0.0629],\n",
      "        [0.3485, 0.0466, 0.5386, 0.0663],\n",
      "        [0.7337, 0.0376, 0.1041, 0.1246],\n",
      "        [0.6970, 0.0736, 0.1387, 0.0907],\n",
      "        [0.7336, 0.0387, 0.0776, 0.1501],\n",
      "        [0.8387, 0.0183, 0.0848, 0.0581]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(23.1412) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ayrılığın sınırlı ışığında¬ışıldar gözler¬dar gelir dünya¬sıkıcıyla¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de¬bir de', 'Şair sözün gösterer,¬Gözel gözün gösterer.¬Payızını ver de ver,¬Şairlik, şiir, şiir.¬Şair sözün göstersin,¬Gözel gözün göstersin,¬Payızını ver de ver,¬Şairlik, şiir, şiir.¬Şair sözün göstersin,¬Gözel gözün göstersin,¬Payızını ver de ver,¬Şairlik, şiir, şiir.¬Şair sözün göstersin,¬Gözel gözün göstersin,¬Payızını ver de ver,¬Şairlik, şiir, şiir.', 'Ey yakarış¬Ey uyanış¬Ey sevgi¬Ey aşk¬Ey arayış¬Ey aşk¬Ey arayış¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬', 'ben ölsemde aşkım cümle alemde¬kulakdan kulaga yayılır belki¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir gün gelirde¬bir', 'Lale, sümbül, çiğdem, Nergizim derken,¬Hercai menekşe, sümbül, çiğdem, çiğdem.¬Bir de sen, bir de ben, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de ben, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de sen, bir de ben,¬Bir de sen, bir de sen, bir de sen, bir de ben, bir de sen, bir de ben,¬Bir', 'herkes her şey¬yok hiçbir şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey', 'Saklasam samanı saklar gibi yaşımı¬Ihtıyarlığımda bir damla gözyaşım¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla gözyaşım var¬Bir damla', 'Bu millet kimlerle gurur duymadı,¬Yurttaşa lan diyenleri alkışladı...¬Bu millet bir gün bir gün bir gün doymadı,¬Yurttaşa lan diyenleri alkışladı...¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün bir gün ağladı,¬Yurttaşa lan diyenleri alkışladı...¬Bu millet bir gün bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün bir gün ağladı,¬Yurttaşa lan diyenleri alkışladı...¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün ağladı,¬Yurttaşa lan diyenleri alkışladı...¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün ağladı,¬Bu millet bir gün bir gün bir gün ağladı,¬Yurttaşa lan diyenleri alkışladı...', 'Gülerken ağladım, gün yüzü görmedim¬Eller gibi dünyadan muradımı almadım¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬Bir gün olsun bir gün olsun gülmedim¬', 'Kendi değiştirmek bazen bizim elimizde değilki¬Ve başlamak yeniden başlamak istiyorum¬Bir evim var¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir evim¬Bir', 'Onsekiz mahallesinden içeri¬Bir yaşlı kadın girdi üstelik, adı da bir papeni¬Girdi içeri, bir kadın, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın, bir kadın girdi, bir kadın¬Kadın', 'Güneşin kızıl yanakları allanınca¬Sürgün yüreklere¬Düşer sevdalar¬Asma suratları¬Ve¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün¬Bir gün', 'Dışarısı ayaz¬Dışarısı beyaz¬Dışarısı buz¬Ağlamaklı¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬', 'Tesir etmez yağan,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Allah diyen dilim varken,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬Allah diyen dilim varken,¬Kolay hesap olur arşın,¬', 'Kendimi kapalı, hissetmiyorum dünyanın ahengini¬Adını duyuyorum ama, bilemiyorum cümleni¬Bir türlü çözemiyorum, bir türlü çözemiyorum¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, bir türlü çözemiyorum¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum cümleni¬Bir türlü çözemiyorum, çözemiyorum', 'Mutluluk önünde bak,yakalamak zor,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Mutluluk yolunda bak,yakalamak zor,¬Mutluluk yolunda bak,yakalamak zor,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Mutluluk yolunda bak,yakalamak zor,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Mutluluk yolunda bak,yakalamak zor,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep karşısında dur,¬Seven sevilenin hep', 'Ehlibeytim sevgim sana,¬Canım da can Ali, Ali.¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki, sen ki,¬Sen ki, sen ki, sen ki', 'Oy Nazile Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬Sazı Nazile¬Şimdi gelir¬', 'Sen gidersen dayanamam ben¬Sarhoş olur geceler birden¬Kör pınar gibi zamansız¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬Sen gidersen dayanamam ben¬', 'İslam sancağını taşıyan sensin¬Yürü be Mehmet’im kim tutar seni¬Allah’ın yolunda yürüyen sensin¬Yürü be Mehmet’im kim tutar seni¬Allah’ın yolunda yürüyen sensin¬Yürü be Mehmet’im kim tutar seni¬Allah’ın yolunda yürüyen sensin¬Yürü be Mehmet’im kim tutar seni¬Allah’ın yolunda yürüyen sensin¬Yürü be Mehmet’im kim tutar seni¬Allah’ın yolunda yürüyen sensin¬Yürü be Mehmet’im kim tutar seni']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.1806e-02, 9.8800e-01, 1.7730e-05, 1.7706e-04],\n",
      "        [1.7671e-02, 9.8227e-01, 6.4784e-06, 4.9086e-05],\n",
      "        [4.7167e-02, 9.5250e-01, 5.7659e-05, 2.7964e-04],\n",
      "        [9.7555e-03, 9.9008e-01, 1.3133e-05, 1.4860e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[8.1556e-02, 9.1817e-01, 2.5171e-05, 2.5084e-04],\n",
      "        [2.1096e-01, 7.8872e-01, 1.6285e-05, 2.9764e-04],\n",
      "        [2.8932e-01, 7.1025e-01, 2.3878e-05, 4.0796e-04],\n",
      "        [2.2424e-01, 7.7521e-01, 2.5314e-05, 5.3035e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[3.6650e-03, 1.0571e-04, 9.8359e-01, 1.2641e-02],\n",
      "        [4.0591e-03, 1.6920e-04, 9.9176e-01, 4.0095e-03],\n",
      "        [1.9687e-03, 4.6551e-05, 9.9389e-01, 4.0977e-03],\n",
      "        [3.8247e-03, 6.0476e-05, 9.9403e-01, 2.0888e-03],\n",
      "        [8.8062e-04, 4.7247e-05, 9.9750e-01, 1.5745e-03],\n",
      "        [2.2452e-03, 5.5609e-05, 9.9435e-01, 3.3534e-03],\n",
      "        [2.2710e-03, 4.5993e-05, 9.9557e-01, 2.1175e-03],\n",
      "        [4.9309e-03, 9.7977e-05, 9.9273e-01, 2.2401e-03],\n",
      "        [3.6555e-03, 1.3395e-04, 9.9389e-01, 2.3179e-03],\n",
      "        [8.2562e-03, 7.1441e-05, 9.8622e-01, 5.4512e-03],\n",
      "        [1.5174e-03, 3.1335e-05, 9.9692e-01, 1.5281e-03],\n",
      "        [8.1508e-03, 1.7503e-04, 9.8700e-01, 4.6724e-03],\n",
      "        [2.4962e-03, 4.0559e-05, 9.9380e-01, 3.6638e-03],\n",
      "        [2.3734e-03, 1.2324e-04, 9.8621e-01, 1.1292e-02],\n",
      "        [5.5317e-03, 3.3315e-04, 9.7708e-01, 1.7058e-02],\n",
      "        [1.1404e-03, 4.4792e-05, 9.9740e-01, 1.4111e-03],\n",
      "        [2.1803e-03, 3.7023e-05, 9.9271e-01, 5.0735e-03],\n",
      "        [1.6070e-03, 2.1654e-05, 9.9686e-01, 1.5143e-03],\n",
      "        [7.8794e-03, 2.8893e-04, 9.8807e-01, 3.7567e-03],\n",
      "        [1.4565e-03, 5.2265e-05, 9.9076e-01, 7.7297e-03],\n",
      "        [1.7475e-03, 1.7395e-04, 9.9540e-01, 2.6738e-03],\n",
      "        [2.8389e-03, 8.4932e-05, 9.8636e-01, 1.0715e-02],\n",
      "        [1.3158e-03, 2.4849e-05, 9.9318e-01, 5.4755e-03],\n",
      "        [5.4668e-03, 1.3401e-04, 9.8348e-01, 1.0919e-02],\n",
      "        [3.2473e-03, 5.2037e-05, 9.9495e-01, 1.7474e-03],\n",
      "        [2.4085e-03, 1.9832e-05, 9.9503e-01, 2.5389e-03],\n",
      "        [1.0937e-03, 7.3232e-05, 9.9613e-01, 2.7031e-03],\n",
      "        [7.4436e-03, 1.3187e-04, 9.8011e-01, 1.2319e-02],\n",
      "        [2.1906e-03, 6.3554e-05, 9.9369e-01, 4.0511e-03],\n",
      "        [2.0136e-03, 1.1637e-05, 9.9660e-01, 1.3750e-03],\n",
      "        [1.0834e-02, 2.8362e-04, 9.7123e-01, 1.7655e-02],\n",
      "        [8.3484e-04, 4.1190e-05, 9.9840e-01, 7.2274e-04],\n",
      "        [2.3018e-03, 1.2396e-04, 9.9260e-01, 4.9751e-03],\n",
      "        [1.3413e-03, 3.1233e-05, 9.9649e-01, 2.1403e-03],\n",
      "        [4.9700e-03, 8.0388e-05, 9.8981e-01, 5.1377e-03],\n",
      "        [3.9508e-03, 6.9283e-05, 9.9259e-01, 3.3879e-03],\n",
      "        [1.4930e-03, 2.8475e-05, 9.9508e-01, 3.3976e-03],\n",
      "        [1.9427e-03, 2.7263e-05, 9.9074e-01, 7.2914e-03],\n",
      "        [1.5069e-03, 6.6899e-05, 9.8811e-01, 1.0320e-02],\n",
      "        [7.4366e-04, 2.4687e-05, 9.9732e-01, 1.9073e-03],\n",
      "        [1.0955e-02, 1.3732e-04, 9.8572e-01, 3.1856e-03],\n",
      "        [2.9086e-03, 1.8714e-04, 9.8917e-01, 7.7293e-03],\n",
      "        [3.9573e-03, 1.0633e-04, 9.9158e-01, 4.3544e-03],\n",
      "        [2.6752e-03, 3.7417e-05, 9.9545e-01, 1.8356e-03],\n",
      "        [1.7725e-03, 5.3566e-05, 9.9356e-01, 4.6116e-03],\n",
      "        [6.2012e-03, 7.0365e-05, 9.9050e-01, 3.2286e-03],\n",
      "        [2.3012e-03, 3.6166e-05, 9.9613e-01, 1.5370e-03],\n",
      "        [2.5861e-03, 1.4135e-04, 9.9194e-01, 5.3289e-03],\n",
      "        [4.4070e-03, 2.7669e-05, 9.8276e-01, 1.2807e-02],\n",
      "        [5.5334e-03, 1.1807e-04, 9.8429e-01, 1.0062e-02],\n",
      "        [2.9111e-03, 6.6726e-05, 9.9404e-01, 2.9799e-03],\n",
      "        [8.3883e-03, 2.7460e-04, 9.8305e-01, 8.2852e-03],\n",
      "        [4.5440e-03, 1.0941e-04, 9.8727e-01, 8.0765e-03],\n",
      "        [4.2070e-03, 1.7739e-04, 9.8451e-01, 1.1101e-02],\n",
      "        [8.1380e-03, 1.1164e-04, 9.8619e-01, 5.5554e-03],\n",
      "        [3.7191e-03, 4.9868e-05, 9.9088e-01, 5.3560e-03],\n",
      "        [4.6160e-03, 7.3608e-05, 9.8856e-01, 6.7516e-03],\n",
      "        [3.8960e-03, 9.0560e-05, 9.8594e-01, 1.0078e-02],\n",
      "        [1.3572e-03, 4.2570e-05, 9.8957e-01, 9.0291e-03],\n",
      "        [2.3737e-03, 4.7087e-05, 9.9578e-01, 1.7984e-03],\n",
      "        [3.5193e-03, 2.3104e-04, 9.8297e-01, 1.3284e-02],\n",
      "        [2.1035e-03, 1.0306e-04, 9.9544e-01, 2.3572e-03],\n",
      "        [1.3036e-03, 5.2215e-05, 9.9544e-01, 3.1996e-03],\n",
      "        [6.7334e-03, 2.3576e-04, 9.8395e-01, 9.0809e-03],\n",
      "        [1.5926e-03, 3.4498e-05, 9.9712e-01, 1.2571e-03],\n",
      "        [4.0230e-03, 4.1384e-05, 9.9328e-01, 2.6601e-03],\n",
      "        [1.4814e-03, 5.2105e-05, 9.9546e-01, 3.0111e-03],\n",
      "        [1.8648e-03, 7.2151e-05, 9.9585e-01, 2.2110e-03],\n",
      "        [2.6370e-03, 7.1995e-05, 9.8603e-01, 1.1259e-02],\n",
      "        [1.7702e-03, 2.8467e-05, 9.9736e-01, 8.3685e-04],\n",
      "        [2.7457e-03, 1.5513e-04, 9.9428e-01, 2.8193e-03],\n",
      "        [3.2011e-03, 9.0866e-05, 9.9370e-01, 3.0079e-03],\n",
      "        [2.5115e-03, 5.2995e-05, 9.9647e-01, 9.6171e-04],\n",
      "        [1.9237e-03, 2.4712e-05, 9.9367e-01, 4.3808e-03],\n",
      "        [2.4823e-03, 2.0213e-05, 9.9600e-01, 1.4964e-03],\n",
      "        [2.0029e-03, 3.9281e-05, 9.9398e-01, 3.9788e-03],\n",
      "        [3.3496e-03, 5.0978e-05, 9.9442e-01, 2.1748e-03],\n",
      "        [1.0604e-03, 1.6714e-05, 9.9834e-01, 5.8489e-04],\n",
      "        [8.7651e-04, 3.0583e-05, 9.9697e-01, 2.1239e-03],\n",
      "        [4.5084e-03, 7.1650e-05, 9.8818e-01, 7.2363e-03],\n",
      "        [2.1808e-03, 4.2121e-05, 9.9501e-01, 2.7644e-03],\n",
      "        [6.3548e-03, 1.4320e-04, 9.8895e-01, 4.5537e-03],\n",
      "        [3.5047e-03, 1.6120e-04, 9.9311e-01, 3.2220e-03],\n",
      "        [9.9788e-04, 3.7980e-05, 9.9370e-01, 5.2639e-03],\n",
      "        [3.6379e-03, 8.6060e-05, 9.8781e-01, 8.4685e-03],\n",
      "        [1.4527e-03, 3.2321e-05, 9.9684e-01, 1.6792e-03],\n",
      "        [2.5341e-03, 9.3856e-05, 9.9213e-01, 5.2438e-03],\n",
      "        [5.8491e-03, 3.3957e-04, 9.8364e-01, 1.0171e-02],\n",
      "        [2.8829e-03, 1.0104e-04, 9.8570e-01, 1.1321e-02],\n",
      "        [2.0166e-03, 4.1726e-05, 9.9614e-01, 1.8058e-03],\n",
      "        [5.7394e-04, 1.9559e-05, 9.9832e-01, 1.0859e-03],\n",
      "        [3.2973e-03, 8.3552e-05, 9.8548e-01, 1.1134e-02],\n",
      "        [1.2347e-03, 2.8097e-05, 9.9589e-01, 2.8463e-03],\n",
      "        [7.9572e-04, 3.2863e-05, 9.9776e-01, 1.4094e-03],\n",
      "        [1.3038e-03, 1.1868e-04, 9.8654e-01, 1.2034e-02],\n",
      "        [1.5559e-03, 1.7046e-05, 9.9719e-01, 1.2408e-03],\n",
      "        [4.8843e-03, 7.2671e-05, 9.9291e-01, 2.1373e-03],\n",
      "        [9.6704e-04, 2.0903e-05, 9.9812e-01, 8.9408e-04],\n",
      "        [1.9425e-03, 3.0629e-05, 9.9513e-01, 2.8959e-03],\n",
      "        [2.8704e-03, 1.1158e-04, 9.9133e-01, 5.6865e-03],\n",
      "        [7.8445e-03, 1.2381e-04, 9.8987e-01, 2.1611e-03],\n",
      "        [1.3626e-03, 2.0984e-05, 9.9337e-01, 5.2484e-03],\n",
      "        [2.6189e-03, 6.5293e-05, 9.9202e-01, 5.2939e-03],\n",
      "        [5.5030e-03, 1.2333e-04, 9.8750e-01, 6.8749e-03],\n",
      "        [3.7092e-03, 4.7961e-05, 9.9091e-01, 5.3342e-03],\n",
      "        [2.7713e-03, 1.1350e-04, 9.8700e-01, 1.0112e-02],\n",
      "        [1.0546e-03, 1.8182e-05, 9.9775e-01, 1.1765e-03],\n",
      "        [3.4956e-03, 4.9140e-05, 9.9053e-01, 5.9245e-03],\n",
      "        [1.0402e-03, 3.8608e-05, 9.9806e-01, 8.6582e-04],\n",
      "        [1.3770e-03, 3.5371e-05, 9.9283e-01, 5.7587e-03],\n",
      "        [1.0482e-03, 3.4300e-05, 9.9841e-01, 5.1170e-04],\n",
      "        [1.6828e-03, 2.8576e-05, 9.9483e-01, 3.4559e-03],\n",
      "        [1.8779e-03, 9.8183e-05, 9.9236e-01, 5.6656e-03],\n",
      "        [2.3858e-03, 1.0397e-04, 9.9200e-01, 5.5057e-03],\n",
      "        [6.4084e-03, 1.2721e-04, 9.9150e-01, 1.9634e-03],\n",
      "        [1.7723e-03, 2.0149e-05, 9.9545e-01, 2.7549e-03],\n",
      "        [2.4210e-03, 2.2953e-05, 9.9498e-01, 2.5796e-03],\n",
      "        [3.5803e-03, 7.0279e-05, 9.8517e-01, 1.1175e-02],\n",
      "        [6.5527e-03, 1.0399e-04, 9.8831e-01, 5.0337e-03],\n",
      "        [1.4761e-03, 2.3813e-05, 9.9657e-01, 1.9348e-03],\n",
      "        [1.7939e-03, 6.2829e-05, 9.9457e-01, 3.5769e-03],\n",
      "        [8.0911e-04, 1.8289e-05, 9.9661e-01, 2.5609e-03],\n",
      "        [1.3102e-03, 1.5223e-05, 9.9726e-01, 1.4113e-03],\n",
      "        [2.1098e-03, 3.9856e-05, 9.9506e-01, 2.7899e-03],\n",
      "        [3.1722e-03, 7.6072e-05, 9.9510e-01, 1.6544e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.5220e-05, 5.1493e-06, 2.8290e-02, 9.7166e-01],\n",
      "        [1.2812e-04, 1.5345e-05, 2.2032e-02, 9.7782e-01],\n",
      "        [2.1813e-05, 1.3143e-06, 6.2847e-03, 9.9369e-01],\n",
      "        [2.0177e-05, 2.4114e-06, 6.7854e-03, 9.9319e-01],\n",
      "        [5.8733e-05, 2.5408e-06, 1.8806e-02, 9.8113e-01],\n",
      "        [2.1815e-05, 7.6225e-07, 5.6038e-03, 9.9437e-01],\n",
      "        [5.0326e-05, 5.9358e-06, 1.8563e-02, 9.8138e-01],\n",
      "        [2.4675e-05, 3.6917e-06, 4.5128e-03, 9.9546e-01],\n",
      "        [9.3486e-05, 3.8293e-05, 2.7799e-02, 9.7207e-01],\n",
      "        [1.8663e-05, 1.7731e-06, 4.8515e-02, 9.5146e-01],\n",
      "        [2.9526e-05, 5.3888e-06, 2.3776e-02, 9.7619e-01],\n",
      "        [2.1814e-05, 4.4104e-06, 5.4668e-03, 9.9451e-01],\n",
      "        [3.0950e-05, 3.9886e-06, 1.2619e-02, 9.8735e-01],\n",
      "        [3.6058e-05, 4.2984e-06, 1.2143e-02, 9.8782e-01],\n",
      "        [1.9582e-05, 9.2740e-06, 7.0720e-03, 9.9290e-01],\n",
      "        [7.2852e-05, 5.3219e-06, 2.0514e-02, 9.7941e-01],\n",
      "        [1.7961e-05, 1.4272e-06, 9.7831e-03, 9.9020e-01],\n",
      "        [4.2975e-05, 5.4276e-06, 9.0545e-03, 9.9090e-01],\n",
      "        [3.0202e-05, 1.4721e-06, 1.9837e-02, 9.8013e-01],\n",
      "        [1.3666e-05, 4.0446e-06, 1.6109e-02, 9.8387e-01],\n",
      "        [2.1384e-05, 6.5744e-06, 3.0903e-02, 9.6907e-01],\n",
      "        [3.1252e-05, 2.1026e-06, 9.0664e-03, 9.9090e-01],\n",
      "        [8.3479e-05, 3.6001e-06, 2.9059e-02, 9.7085e-01],\n",
      "        [1.9573e-05, 3.7141e-06, 1.1362e-02, 9.8861e-01],\n",
      "        [4.2050e-05, 5.4411e-06, 1.3905e-02, 9.8605e-01],\n",
      "        [1.2651e-05, 1.8406e-06, 5.8288e-03, 9.9416e-01],\n",
      "        [1.8236e-05, 1.4839e-06, 1.3266e-02, 9.8671e-01],\n",
      "        [3.2539e-05, 4.3602e-06, 1.2037e-02, 9.8793e-01],\n",
      "        [2.3154e-05, 3.1059e-06, 1.0682e-02, 9.8929e-01],\n",
      "        [2.5901e-05, 2.0876e-06, 1.2856e-02, 9.8712e-01],\n",
      "        [1.7861e-04, 4.0331e-06, 1.1437e-02, 9.8838e-01],\n",
      "        [3.3235e-05, 3.0067e-06, 9.9096e-03, 9.9005e-01],\n",
      "        [4.4377e-05, 2.3701e-06, 2.5505e-03, 9.9740e-01],\n",
      "        [3.1028e-05, 4.2058e-06, 1.1102e-02, 9.8886e-01],\n",
      "        [9.3130e-05, 5.2191e-06, 2.8848e-02, 9.7105e-01],\n",
      "        [1.6829e-05, 1.4217e-06, 8.7760e-03, 9.9121e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(63.3902) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[2.6440e-02, 9.7288e-01, 1.9096e-04, 4.9072e-04],\n",
      "        [1.1504e-03, 9.9869e-01, 4.4109e-05, 1.1613e-04],\n",
      "        [8.5328e-04, 9.9901e-01, 4.2022e-05, 9.9584e-05],\n",
      "        [2.7331e-03, 9.9703e-01, 6.5452e-05, 1.7168e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[3.4290e-01, 6.5600e-01, 3.1629e-04, 7.8167e-04],\n",
      "        [3.6488e-01, 6.3293e-01, 1.4254e-03, 7.7150e-04],\n",
      "        [2.1037e-01, 7.8794e-01, 1.0147e-03, 6.7770e-04],\n",
      "        [2.5645e-01, 7.4197e-01, 9.4030e-04, 6.3478e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[6.3158e-04, 1.7394e-04, 9.8933e-01, 9.8680e-03],\n",
      "        [7.9327e-05, 5.3239e-05, 9.9776e-01, 2.1080e-03],\n",
      "        [2.4249e-04, 1.8457e-04, 9.9771e-01, 1.8637e-03],\n",
      "        [4.2956e-04, 1.3731e-04, 9.9476e-01, 4.6747e-03],\n",
      "        [3.3864e-04, 2.5344e-04, 9.8840e-01, 1.1005e-02],\n",
      "        [3.8179e-04, 3.0127e-04, 9.9192e-01, 7.3970e-03],\n",
      "        [2.4786e-04, 1.3824e-04, 9.9807e-01, 1.5399e-03],\n",
      "        [1.5334e-04, 1.1689e-04, 9.9510e-01, 4.6319e-03],\n",
      "        [1.7883e-04, 7.9824e-05, 9.9691e-01, 2.8285e-03],\n",
      "        [9.4812e-04, 2.4056e-04, 9.9543e-01, 3.3845e-03],\n",
      "        [7.4928e-05, 5.1460e-05, 9.9717e-01, 2.7053e-03],\n",
      "        [4.2600e-04, 3.5744e-04, 9.9545e-01, 3.7672e-03],\n",
      "        [1.1871e-04, 9.7041e-05, 9.9860e-01, 1.1836e-03],\n",
      "        [1.8533e-04, 5.7910e-05, 9.9659e-01, 3.1706e-03],\n",
      "        [8.4217e-05, 9.2107e-05, 9.9727e-01, 2.5495e-03],\n",
      "        [1.1948e-04, 1.2072e-04, 9.9747e-01, 2.2925e-03],\n",
      "        [1.4388e-04, 1.8197e-04, 9.9715e-01, 2.5206e-03],\n",
      "        [1.8157e-04, 1.7953e-04, 9.8389e-01, 1.5748e-02],\n",
      "        [1.3976e-04, 3.8216e-05, 9.9823e-01, 1.5873e-03],\n",
      "        [1.1807e-04, 1.2461e-04, 9.9164e-01, 8.1168e-03],\n",
      "        [2.0058e-04, 9.5065e-05, 9.9384e-01, 5.8602e-03],\n",
      "        [1.5225e-04, 1.2092e-04, 9.9837e-01, 1.3566e-03],\n",
      "        [6.2927e-05, 3.7686e-05, 9.9824e-01, 1.6559e-03],\n",
      "        [3.6663e-04, 1.9884e-04, 9.9481e-01, 4.6215e-03],\n",
      "        [3.4095e-04, 1.2776e-04, 9.9675e-01, 2.7781e-03],\n",
      "        [8.1227e-05, 7.6549e-05, 9.9800e-01, 1.8403e-03],\n",
      "        [1.1473e-04, 8.8061e-05, 9.9782e-01, 1.9769e-03],\n",
      "        [1.2616e-04, 7.5940e-05, 9.9762e-01, 2.1795e-03],\n",
      "        [1.5765e-05, 1.1719e-05, 9.9854e-01, 1.4310e-03],\n",
      "        [9.8148e-05, 1.6224e-04, 9.9880e-01, 9.3499e-04],\n",
      "        [6.8498e-05, 2.6818e-05, 9.9746e-01, 2.4497e-03],\n",
      "        [4.4531e-04, 5.4660e-04, 9.8085e-01, 1.8160e-02],\n",
      "        [2.2364e-04, 7.6579e-05, 9.9458e-01, 5.1239e-03],\n",
      "        [2.1639e-04, 2.4388e-04, 9.9537e-01, 4.1661e-03],\n",
      "        [2.1352e-04, 7.1042e-05, 9.9715e-01, 2.5614e-03],\n",
      "        [2.4581e-04, 1.6447e-04, 9.9693e-01, 2.6590e-03],\n",
      "        [3.8615e-05, 4.6762e-05, 9.9881e-01, 1.1006e-03],\n",
      "        [2.6716e-04, 1.6479e-04, 9.9555e-01, 4.0158e-03],\n",
      "        [2.9043e-04, 2.1321e-04, 9.9372e-01, 5.7781e-03],\n",
      "        [1.9065e-04, 1.7125e-04, 9.9225e-01, 7.3876e-03],\n",
      "        [1.2920e-04, 2.3743e-04, 9.9694e-01, 2.6888e-03],\n",
      "        [1.4139e-04, 1.6442e-04, 9.9645e-01, 3.2415e-03],\n",
      "        [1.1557e-04, 7.9187e-05, 9.9409e-01, 5.7201e-03],\n",
      "        [2.8035e-04, 2.3103e-04, 9.9776e-01, 1.7267e-03],\n",
      "        [7.5502e-05, 5.6838e-05, 9.9813e-01, 1.7395e-03],\n",
      "        [1.1647e-04, 6.3840e-05, 9.9525e-01, 4.5737e-03],\n",
      "        [3.1328e-04, 3.0838e-04, 9.9404e-01, 5.3382e-03],\n",
      "        [6.2622e-05, 5.8475e-05, 9.9782e-01, 2.0635e-03],\n",
      "        [2.4531e-04, 1.0639e-04, 9.9546e-01, 4.1901e-03],\n",
      "        [5.0400e-04, 7.0948e-04, 9.8506e-01, 1.3724e-02],\n",
      "        [2.3629e-04, 8.5955e-05, 9.9829e-01, 1.3836e-03],\n",
      "        [1.2767e-04, 6.4774e-05, 9.9587e-01, 3.9346e-03],\n",
      "        [2.8644e-04, 1.2289e-04, 9.9475e-01, 4.8373e-03],\n",
      "        [3.3245e-04, 1.4329e-04, 9.9584e-01, 3.6836e-03],\n",
      "        [1.9417e-04, 1.4480e-04, 9.9262e-01, 7.0410e-03],\n",
      "        [1.5172e-04, 5.3542e-05, 9.9838e-01, 1.4174e-03],\n",
      "        [2.0986e-04, 6.2931e-05, 9.9899e-01, 7.3932e-04],\n",
      "        [1.7518e-04, 1.1115e-04, 9.9639e-01, 3.3271e-03],\n",
      "        [2.6757e-04, 1.9447e-04, 9.9504e-01, 4.4953e-03],\n",
      "        [5.7024e-05, 3.3688e-05, 9.9854e-01, 1.3667e-03],\n",
      "        [1.2469e-04, 1.3045e-04, 9.9813e-01, 1.6151e-03],\n",
      "        [2.7312e-04, 1.3854e-04, 9.9282e-01, 6.7672e-03],\n",
      "        [5.4651e-05, 8.8687e-05, 9.9647e-01, 3.3863e-03],\n",
      "        [1.1756e-04, 1.9847e-05, 9.9745e-01, 2.4146e-03],\n",
      "        [5.6764e-05, 4.1185e-05, 9.9803e-01, 1.8727e-03],\n",
      "        [1.2782e-04, 3.8086e-05, 9.9625e-01, 3.5866e-03],\n",
      "        [1.2583e-04, 2.0542e-04, 9.9504e-01, 4.6242e-03],\n",
      "        [2.0472e-04, 1.3551e-04, 9.9705e-01, 2.6125e-03],\n",
      "        [5.0326e-05, 2.1692e-05, 9.9861e-01, 1.3226e-03],\n",
      "        [4.3211e-05, 1.0178e-04, 9.9640e-01, 3.4574e-03],\n",
      "        [1.5320e-04, 8.0667e-05, 9.9650e-01, 3.2696e-03],\n",
      "        [3.2056e-04, 1.1342e-04, 9.9840e-01, 1.1671e-03],\n",
      "        [3.5220e-04, 2.3989e-04, 9.9696e-01, 2.4439e-03],\n",
      "        [4.1667e-04, 1.7773e-04, 9.9389e-01, 5.5145e-03],\n",
      "        [1.3417e-04, 6.9713e-05, 9.9483e-01, 4.9637e-03],\n",
      "        [3.4562e-04, 1.7063e-04, 9.9486e-01, 4.6279e-03],\n",
      "        [2.4908e-04, 1.0223e-04, 9.9554e-01, 4.1092e-03],\n",
      "        [1.6209e-04, 1.0009e-04, 9.9564e-01, 4.0932e-03],\n",
      "        [1.3453e-04, 6.0310e-05, 9.9809e-01, 1.7187e-03],\n",
      "        [1.5861e-04, 1.0659e-04, 9.9757e-01, 2.1624e-03],\n",
      "        [2.9419e-04, 1.0504e-04, 9.9770e-01, 1.9019e-03],\n",
      "        [2.1443e-04, 7.8638e-04, 9.9544e-01, 3.5596e-03],\n",
      "        [1.0726e-04, 1.6586e-04, 9.9465e-01, 5.0733e-03],\n",
      "        [1.7732e-04, 9.5592e-05, 9.9784e-01, 1.8823e-03],\n",
      "        [1.0234e-04, 6.4729e-05, 9.9749e-01, 2.3382e-03],\n",
      "        [8.6960e-05, 1.0218e-04, 9.9910e-01, 7.1074e-04],\n",
      "        [1.8763e-04, 9.5350e-05, 9.9261e-01, 7.1116e-03],\n",
      "        [1.3172e-04, 6.8634e-05, 9.9874e-01, 1.0580e-03],\n",
      "        [8.4964e-04, 5.6971e-04, 9.9210e-01, 6.4777e-03],\n",
      "        [1.8673e-04, 2.0274e-04, 9.9696e-01, 2.6505e-03],\n",
      "        [2.5242e-04, 1.2983e-04, 9.8903e-01, 1.0585e-02],\n",
      "        [6.8240e-05, 1.9655e-05, 9.9815e-01, 1.7584e-03],\n",
      "        [2.9214e-04, 1.4370e-04, 9.9736e-01, 2.2064e-03],\n",
      "        [7.2757e-04, 2.1495e-04, 9.9689e-01, 2.1649e-03],\n",
      "        [2.3195e-04, 9.7376e-05, 9.9673e-01, 2.9407e-03],\n",
      "        [6.5518e-04, 7.2930e-04, 9.9098e-01, 7.6400e-03],\n",
      "        [1.2394e-04, 2.9149e-04, 9.8975e-01, 9.8339e-03],\n",
      "        [2.4086e-04, 1.0138e-04, 9.9707e-01, 2.5835e-03],\n",
      "        [2.7913e-04, 7.5944e-05, 9.9681e-01, 2.8373e-03],\n",
      "        [3.1983e-04, 7.3300e-05, 9.9822e-01, 1.3917e-03],\n",
      "        [3.2610e-04, 2.1183e-04, 9.9589e-01, 3.5732e-03],\n",
      "        [6.9093e-04, 2.5074e-04, 9.9576e-01, 3.2969e-03],\n",
      "        [1.5252e-04, 1.6757e-04, 9.9669e-01, 2.9879e-03],\n",
      "        [4.3440e-04, 9.9594e-05, 9.9546e-01, 4.0104e-03],\n",
      "        [1.1350e-04, 8.6703e-05, 9.9862e-01, 1.1820e-03],\n",
      "        [1.2815e-04, 1.2683e-04, 9.9544e-01, 4.3060e-03],\n",
      "        [1.9340e-04, 1.3467e-04, 9.9735e-01, 2.3225e-03],\n",
      "        [9.7062e-05, 2.1903e-04, 9.9645e-01, 3.2345e-03],\n",
      "        [3.0781e-04, 1.4781e-04, 9.9326e-01, 6.2828e-03],\n",
      "        [5.0944e-04, 2.1938e-04, 9.9578e-01, 3.4944e-03],\n",
      "        [8.9642e-05, 6.0511e-05, 9.9574e-01, 4.1116e-03],\n",
      "        [1.6679e-04, 1.1409e-04, 9.9809e-01, 1.6251e-03],\n",
      "        [7.9516e-05, 3.8003e-05, 9.9668e-01, 3.1975e-03],\n",
      "        [1.0243e-04, 4.2077e-05, 9.9739e-01, 2.4655e-03],\n",
      "        [5.9894e-05, 3.4127e-05, 9.9666e-01, 3.2471e-03],\n",
      "        [1.2091e-04, 9.6279e-05, 9.9636e-01, 3.4210e-03],\n",
      "        [1.2859e-04, 6.9894e-05, 9.9818e-01, 1.6212e-03],\n",
      "        [3.4342e-04, 2.3082e-04, 9.9346e-01, 5.9671e-03],\n",
      "        [1.7165e-04, 1.5834e-04, 9.9810e-01, 1.5735e-03],\n",
      "        [1.5107e-04, 1.6789e-04, 9.9817e-01, 1.5095e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.2559e-06, 1.5842e-06, 2.2386e-03, 9.9776e-01],\n",
      "        [5.9720e-06, 6.3285e-06, 3.3164e-03, 9.9667e-01],\n",
      "        [4.2978e-06, 5.5087e-06, 1.7818e-03, 9.9821e-01],\n",
      "        [2.0923e-06, 2.8362e-06, 2.3788e-03, 9.9762e-01],\n",
      "        [6.5689e-06, 5.1200e-06, 3.1075e-03, 9.9688e-01],\n",
      "        [1.9732e-06, 2.5263e-06, 3.1333e-03, 9.9686e-01],\n",
      "        [5.9604e-06, 3.4211e-06, 1.2372e-02, 9.8762e-01],\n",
      "        [1.5283e-06, 1.4723e-06, 1.6489e-03, 9.9835e-01],\n",
      "        [2.5737e-06, 1.0996e-05, 1.5807e-03, 9.9841e-01],\n",
      "        [2.1571e-06, 3.6807e-06, 3.4314e-03, 9.9656e-01],\n",
      "        [3.0001e-06, 6.9192e-06, 3.7234e-03, 9.9627e-01],\n",
      "        [2.4400e-06, 5.1409e-07, 2.9494e-03, 9.9705e-01],\n",
      "        [8.7900e-07, 9.8848e-07, 1.7093e-03, 9.9829e-01],\n",
      "        [3.6561e-06, 4.5845e-06, 1.4293e-03, 9.9856e-01],\n",
      "        [1.5184e-06, 1.3088e-06, 5.6914e-03, 9.9431e-01],\n",
      "        [1.1651e-06, 1.1890e-06, 9.2072e-04, 9.9908e-01],\n",
      "        [4.1660e-06, 5.0894e-06, 8.9783e-04, 9.9909e-01],\n",
      "        [1.7963e-06, 3.9931e-06, 8.0311e-03, 9.9196e-01],\n",
      "        [2.0276e-06, 5.0568e-07, 1.7583e-03, 9.9824e-01],\n",
      "        [3.8902e-06, 4.4472e-06, 1.9172e-02, 9.8082e-01],\n",
      "        [2.2273e-06, 1.0078e-06, 1.2949e-03, 9.9870e-01],\n",
      "        [1.1838e-05, 6.3493e-06, 2.0586e-03, 9.9792e-01],\n",
      "        [4.2255e-06, 3.0241e-06, 5.8202e-03, 9.9417e-01],\n",
      "        [5.4541e-06, 3.9255e-06, 1.1449e-02, 9.8854e-01],\n",
      "        [4.1521e-06, 2.6392e-06, 2.2218e-03, 9.9777e-01],\n",
      "        [6.2030e-06, 1.0650e-05, 6.3628e-03, 9.9362e-01],\n",
      "        [5.2771e-06, 2.1586e-06, 2.1210e-03, 9.9787e-01],\n",
      "        [5.4835e-06, 4.8202e-06, 4.0929e-03, 9.9590e-01],\n",
      "        [8.1203e-06, 3.9355e-06, 2.0606e-03, 9.9793e-01],\n",
      "        [1.4964e-06, 1.9031e-06, 3.2711e-03, 9.9673e-01],\n",
      "        [1.3934e-06, 7.0461e-07, 1.4193e-03, 9.9858e-01],\n",
      "        [4.8412e-06, 2.6312e-06, 2.6843e-03, 9.9731e-01],\n",
      "        [3.0586e-06, 1.8147e-06, 3.9324e-03, 9.9606e-01],\n",
      "        [1.5774e-06, 4.4069e-06, 2.5116e-03, 9.9748e-01],\n",
      "        [1.2124e-05, 2.2681e-06, 5.7347e-03, 9.9425e-01],\n",
      "        [8.5334e-06, 2.7968e-06, 3.8379e-03, 9.9615e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(81.0211) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[2.4006e-02, 9.7560e-01, 1.6531e-04, 2.3271e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.5642e-01, 4.3223e-02, 2.5244e-04, 1.0104e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[3.4860e-04, 3.7303e-06, 9.9909e-01, 5.6175e-04],\n",
      "        [1.2736e-03, 1.2332e-05, 9.9816e-01, 5.5840e-04],\n",
      "        [2.0904e-04, 2.8680e-06, 9.9918e-01, 6.0321e-04],\n",
      "        [5.2700e-04, 9.7293e-06, 9.9751e-01, 1.9512e-03],\n",
      "        [1.2533e-03, 1.7594e-05, 9.9726e-01, 1.4702e-03],\n",
      "        [5.4188e-04, 1.0750e-05, 9.9742e-01, 2.0243e-03],\n",
      "        [3.0108e-03, 2.3614e-05, 9.9571e-01, 1.2581e-03],\n",
      "        [9.8332e-04, 8.8919e-06, 9.9824e-01, 7.6437e-04],\n",
      "        [3.4173e-04, 7.2285e-06, 9.9688e-01, 2.7703e-03],\n",
      "        [1.6769e-03, 2.9617e-05, 9.9724e-01, 1.0525e-03],\n",
      "        [1.1887e-03, 6.5318e-06, 9.9832e-01, 4.8074e-04],\n",
      "        [8.1905e-04, 2.2493e-05, 9.9811e-01, 1.0483e-03],\n",
      "        [1.8560e-03, 1.2470e-05, 9.9643e-01, 1.7010e-03],\n",
      "        [1.7694e-03, 1.8777e-05, 9.9666e-01, 1.5542e-03],\n",
      "        [2.9499e-03, 7.3618e-06, 9.9497e-01, 2.0707e-03],\n",
      "        [3.1670e-03, 4.0537e-05, 9.9427e-01, 2.5253e-03],\n",
      "        [2.1217e-04, 4.1090e-06, 9.9945e-01, 3.3453e-04],\n",
      "        [3.2583e-03, 3.1814e-05, 9.9424e-01, 2.4670e-03],\n",
      "        [5.0154e-04, 4.6868e-06, 9.9926e-01, 2.3082e-04],\n",
      "        [1.1174e-03, 2.3248e-05, 9.9614e-01, 2.7191e-03],\n",
      "        [8.9073e-04, 6.1739e-06, 9.9825e-01, 8.5532e-04],\n",
      "        [3.4746e-04, 3.4094e-06, 9.9939e-01, 2.5516e-04],\n",
      "        [2.1837e-04, 3.7567e-06, 9.9944e-01, 3.3338e-04],\n",
      "        [2.8734e-04, 4.7314e-06, 9.9943e-01, 2.7459e-04],\n",
      "        [1.9524e-03, 4.1641e-05, 9.9486e-01, 3.1415e-03],\n",
      "        [9.1654e-04, 1.1655e-05, 9.9839e-01, 6.8486e-04],\n",
      "        [8.1520e-04, 4.9627e-06, 9.9840e-01, 7.8314e-04],\n",
      "        [8.0336e-04, 9.6371e-06, 9.9341e-01, 5.7723e-03],\n",
      "        [3.7602e-04, 3.2969e-06, 9.9933e-01, 2.8809e-04],\n",
      "        [3.9060e-04, 6.8284e-06, 9.9899e-01, 6.0790e-04],\n",
      "        [1.2541e-03, 1.4585e-05, 9.9746e-01, 1.2681e-03],\n",
      "        [1.2252e-03, 1.5426e-05, 9.9623e-01, 2.5275e-03],\n",
      "        [1.0467e-03, 1.5063e-05, 9.9839e-01, 5.4512e-04],\n",
      "        [5.8878e-04, 1.4562e-05, 9.9849e-01, 9.1006e-04],\n",
      "        [7.8394e-04, 1.4896e-05, 9.9870e-01, 5.0020e-04],\n",
      "        [6.8698e-04, 1.1589e-05, 9.9859e-01, 7.1384e-04],\n",
      "        [4.6049e-04, 6.3420e-06, 9.9863e-01, 9.0100e-04],\n",
      "        [8.3580e-04, 2.3509e-05, 9.9789e-01, 1.2529e-03],\n",
      "        [3.0445e-04, 1.0252e-05, 9.9909e-01, 5.9093e-04],\n",
      "        [4.4893e-04, 3.1544e-05, 9.9817e-01, 1.3466e-03],\n",
      "        [1.4513e-03, 1.8057e-05, 9.9759e-01, 9.4040e-04],\n",
      "        [1.0006e-03, 1.1835e-05, 9.9733e-01, 1.6589e-03],\n",
      "        [1.4690e-03, 1.8357e-05, 9.9643e-01, 2.0800e-03],\n",
      "        [1.3802e-03, 2.7220e-05, 9.9486e-01, 3.7364e-03],\n",
      "        [2.5934e-04, 6.8602e-06, 9.9894e-01, 7.8963e-04],\n",
      "        [6.4726e-04, 8.6958e-06, 9.9734e-01, 2.0029e-03],\n",
      "        [1.9532e-04, 5.9406e-06, 9.9959e-01, 2.1213e-04],\n",
      "        [4.1339e-04, 6.3740e-06, 9.9802e-01, 1.5581e-03],\n",
      "        [1.3740e-03, 9.0128e-06, 9.9707e-01, 1.5449e-03],\n",
      "        [6.5748e-04, 1.0139e-05, 9.9789e-01, 1.4463e-03],\n",
      "        [3.8144e-04, 2.3059e-05, 9.9793e-01, 1.6693e-03],\n",
      "        [7.9802e-04, 5.0302e-06, 9.9893e-01, 2.6649e-04],\n",
      "        [4.4663e-04, 6.0967e-06, 9.9903e-01, 5.1408e-04],\n",
      "        [2.7774e-03, 1.0831e-04, 9.9007e-01, 7.0482e-03],\n",
      "        [8.0148e-04, 6.9158e-06, 9.9895e-01, 2.4565e-04],\n",
      "        [5.8886e-04, 1.7106e-05, 9.9575e-01, 3.6429e-03],\n",
      "        [8.7596e-04, 2.1520e-05, 9.9840e-01, 7.0102e-04],\n",
      "        [4.9803e-04, 2.4017e-05, 9.9779e-01, 1.6884e-03],\n",
      "        [5.6460e-04, 1.7267e-05, 9.9919e-01, 2.3002e-04],\n",
      "        [8.7279e-04, 1.1248e-05, 9.9751e-01, 1.6054e-03],\n",
      "        [7.5434e-04, 1.5728e-05, 9.9629e-01, 2.9383e-03],\n",
      "        [3.6128e-04, 3.2009e-06, 9.9893e-01, 7.0700e-04],\n",
      "        [1.7075e-03, 3.7238e-05, 9.9386e-01, 4.3933e-03],\n",
      "        [7.1230e-04, 1.0618e-05, 9.9816e-01, 1.1181e-03],\n",
      "        [1.0237e-03, 2.2414e-05, 9.9791e-01, 1.0392e-03],\n",
      "        [2.0008e-03, 2.8429e-05, 9.9425e-01, 3.7173e-03],\n",
      "        [2.3114e-03, 3.1497e-05, 9.9334e-01, 4.3218e-03],\n",
      "        [1.1604e-03, 3.7551e-05, 9.9604e-01, 2.7607e-03],\n",
      "        [2.1265e-03, 4.0265e-05, 9.9607e-01, 1.7649e-03],\n",
      "        [5.1582e-04, 1.3605e-05, 9.9491e-01, 4.5561e-03],\n",
      "        [1.4512e-04, 6.8289e-07, 9.9974e-01, 1.1306e-04],\n",
      "        [2.4084e-03, 8.3306e-06, 9.9622e-01, 1.3657e-03],\n",
      "        [9.5227e-04, 3.4680e-05, 9.9623e-01, 2.7810e-03],\n",
      "        [1.1231e-03, 1.9384e-05, 9.9744e-01, 1.4133e-03],\n",
      "        [1.0878e-03, 5.2472e-06, 9.9687e-01, 2.0334e-03],\n",
      "        [3.5318e-04, 2.2481e-06, 9.9882e-01, 8.2092e-04],\n",
      "        [3.2665e-03, 2.9075e-05, 9.9590e-01, 8.0701e-04],\n",
      "        [2.0612e-03, 3.9266e-05, 9.9635e-01, 1.5518e-03],\n",
      "        [4.8309e-04, 1.2145e-05, 9.9814e-01, 1.3643e-03],\n",
      "        [1.1676e-03, 8.5227e-06, 9.9706e-01, 1.7606e-03],\n",
      "        [2.0249e-03, 1.0182e-05, 9.9655e-01, 1.4122e-03],\n",
      "        [4.8478e-04, 5.8460e-06, 9.9933e-01, 1.8311e-04],\n",
      "        [5.9863e-04, 4.8990e-06, 9.9853e-01, 8.6166e-04],\n",
      "        [1.6191e-03, 1.3893e-05, 9.9608e-01, 2.2844e-03],\n",
      "        [5.6879e-04, 8.0782e-06, 9.9789e-01, 1.5374e-03],\n",
      "        [2.5657e-04, 6.8225e-06, 9.9837e-01, 1.3648e-03],\n",
      "        [6.7328e-04, 6.6281e-06, 9.9865e-01, 6.7055e-04],\n",
      "        [3.2394e-03, 1.6185e-05, 9.9529e-01, 1.4548e-03],\n",
      "        [4.8523e-04, 7.7954e-06, 9.9860e-01, 9.0470e-04],\n",
      "        [5.3654e-04, 8.7007e-06, 9.9906e-01, 3.9120e-04],\n",
      "        [9.0481e-04, 6.2960e-06, 9.9829e-01, 7.9859e-04],\n",
      "        [9.7837e-04, 4.3706e-06, 9.9879e-01, 2.2378e-04],\n",
      "        [1.7080e-04, 3.5960e-06, 9.9949e-01, 3.3224e-04],\n",
      "        [1.0799e-03, 1.9303e-05, 9.9670e-01, 2.2046e-03],\n",
      "        [5.9515e-04, 7.9950e-06, 9.9816e-01, 1.2385e-03],\n",
      "        [3.8472e-04, 3.1949e-06, 9.9844e-01, 1.1677e-03],\n",
      "        [7.5450e-04, 8.6293e-06, 9.9861e-01, 6.3004e-04],\n",
      "        [1.6129e-03, 1.1319e-05, 9.9668e-01, 1.6976e-03],\n",
      "        [2.4694e-04, 3.4344e-06, 9.9917e-01, 5.7819e-04],\n",
      "        [1.6618e-03, 3.3622e-05, 9.9569e-01, 2.6189e-03],\n",
      "        [1.1779e-03, 4.4979e-06, 9.9790e-01, 9.1378e-04],\n",
      "        [7.1795e-04, 1.5138e-06, 9.9845e-01, 8.3031e-04],\n",
      "        [5.8880e-04, 2.1496e-05, 9.9752e-01, 1.8746e-03],\n",
      "        [1.0727e-03, 2.6216e-05, 9.9728e-01, 1.6223e-03],\n",
      "        [4.5382e-04, 3.9257e-06, 9.9891e-01, 6.2953e-04],\n",
      "        [3.5259e-04, 3.9395e-06, 9.9930e-01, 3.4814e-04],\n",
      "        [2.5221e-03, 8.9538e-06, 9.9606e-01, 1.4080e-03],\n",
      "        [1.7171e-03, 3.7543e-05, 9.9651e-01, 1.7354e-03],\n",
      "        [2.6079e-03, 1.0237e-05, 9.9357e-01, 3.8143e-03],\n",
      "        [5.0447e-04, 4.2910e-06, 9.9790e-01, 1.5929e-03],\n",
      "        [5.1226e-04, 1.2644e-05, 9.9867e-01, 8.0780e-04],\n",
      "        [1.5965e-03, 1.0696e-05, 9.9681e-01, 1.5831e-03],\n",
      "        [6.9003e-04, 8.9157e-06, 9.9856e-01, 7.3631e-04],\n",
      "        [2.5562e-04, 9.1089e-06, 9.9844e-01, 1.2961e-03],\n",
      "        [3.9932e-04, 5.0334e-06, 9.9911e-01, 4.8599e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.0124e-06, 9.6001e-08, 4.1396e-04, 9.9958e-01],\n",
      "        [1.2998e-06, 9.9606e-08, 4.5483e-04, 9.9954e-01],\n",
      "        [1.2097e-06, 8.4530e-08, 2.6663e-04, 9.9973e-01],\n",
      "        [6.8798e-06, 1.7930e-07, 4.8714e-04, 9.9951e-01],\n",
      "        [1.3330e-06, 5.9042e-08, 4.6579e-04, 9.9953e-01],\n",
      "        [1.9096e-06, 2.3998e-07, 4.1291e-04, 9.9958e-01],\n",
      "        [3.5221e-06, 1.1212e-07, 3.2807e-04, 9.9967e-01],\n",
      "        [8.6127e-06, 4.0841e-07, 9.8449e-04, 9.9901e-01],\n",
      "        [7.1412e-06, 1.7396e-07, 1.6967e-03, 9.9830e-01],\n",
      "        [3.6310e-06, 1.8100e-07, 5.1109e-04, 9.9949e-01],\n",
      "        [1.5080e-06, 1.4254e-07, 1.0909e-03, 9.9891e-01],\n",
      "        [1.1933e-06, 8.0094e-08, 1.4882e-03, 9.9851e-01],\n",
      "        [7.6093e-06, 2.4566e-07, 1.1899e-03, 9.9880e-01],\n",
      "        [3.2954e-06, 1.7162e-07, 7.3900e-04, 9.9926e-01],\n",
      "        [1.7087e-05, 8.9862e-07, 2.3071e-03, 9.9767e-01],\n",
      "        [3.7600e-06, 2.1185e-07, 1.0039e-03, 9.9899e-01],\n",
      "        [7.9647e-06, 2.4225e-07, 2.5735e-03, 9.9742e-01],\n",
      "        [8.8986e-06, 2.1753e-07, 4.1917e-04, 9.9957e-01],\n",
      "        [2.2762e-06, 5.4350e-08, 9.2386e-04, 9.9907e-01],\n",
      "        [5.3541e-06, 1.4374e-07, 8.2579e-04, 9.9917e-01],\n",
      "        [3.7352e-06, 1.1794e-07, 4.4221e-03, 9.9557e-01],\n",
      "        [4.4616e-07, 1.3411e-07, 4.9151e-04, 9.9951e-01],\n",
      "        [5.0963e-07, 1.3853e-07, 6.4577e-04, 9.9935e-01],\n",
      "        [4.8952e-06, 1.3837e-07, 1.0267e-03, 9.9897e-01],\n",
      "        [3.5143e-06, 2.4314e-07, 6.9428e-04, 9.9930e-01],\n",
      "        [1.2716e-06, 3.0664e-07, 9.7130e-04, 9.9903e-01],\n",
      "        [1.3757e-06, 1.0873e-07, 1.1958e-03, 9.9880e-01],\n",
      "        [1.0096e-05, 1.1328e-06, 1.1368e-02, 9.8862e-01],\n",
      "        [1.7646e-06, 8.1058e-08, 3.4002e-04, 9.9966e-01],\n",
      "        [5.1176e-06, 4.6855e-07, 1.7759e-03, 9.9822e-01],\n",
      "        [3.5601e-06, 1.8857e-07, 9.3306e-04, 9.9906e-01],\n",
      "        [1.7411e-06, 7.8918e-08, 2.9233e-04, 9.9971e-01],\n",
      "        [1.3412e-05, 5.3269e-07, 2.0511e-03, 9.9794e-01],\n",
      "        [7.3541e-06, 1.9618e-07, 4.5438e-04, 9.9954e-01],\n",
      "        [1.9283e-05, 6.7090e-07, 5.5109e-03, 9.9447e-01],\n",
      "        [1.6296e-06, 2.2170e-07, 8.0315e-04, 9.9920e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(86.7775) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.4526e-03, 9.9810e-01, 2.2436e-04, 2.2497e-04],\n",
      "        [4.2723e-05, 9.9992e-01, 7.7605e-06, 2.9658e-05],\n",
      "        [6.0844e-05, 9.9989e-01, 6.9105e-06, 4.2995e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.4701e-01, 8.5224e-01, 2.3256e-04, 5.1806e-04],\n",
      "        [4.9795e-01, 5.0104e-01, 3.8318e-04, 6.2260e-04],\n",
      "        [5.0715e-02, 9.4838e-01, 3.3429e-04, 5.6898e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.5767e-05, 3.6686e-04, 9.9687e-01, 2.7365e-03],\n",
      "        [5.4076e-05, 1.9027e-03, 9.9442e-01, 3.6274e-03],\n",
      "        [1.1020e-05, 2.4978e-04, 9.9857e-01, 1.1704e-03],\n",
      "        [4.5386e-05, 4.5835e-04, 9.9654e-01, 2.9586e-03],\n",
      "        [2.7499e-05, 3.8206e-04, 9.9874e-01, 8.5029e-04],\n",
      "        [3.8309e-05, 4.1006e-04, 9.9887e-01, 6.8087e-04],\n",
      "        [2.2512e-05, 1.4283e-03, 9.9723e-01, 1.3150e-03],\n",
      "        [3.8841e-05, 1.1704e-03, 9.9787e-01, 9.2427e-04],\n",
      "        [4.3820e-05, 6.3952e-04, 9.9768e-01, 1.6383e-03],\n",
      "        [8.0889e-05, 5.4025e-03, 9.9006e-01, 4.4601e-03],\n",
      "        [5.6418e-05, 2.1622e-03, 9.9676e-01, 1.0261e-03],\n",
      "        [3.6750e-05, 4.8534e-04, 9.9676e-01, 2.7187e-03],\n",
      "        [4.7241e-05, 6.0010e-03, 9.9223e-01, 1.7257e-03],\n",
      "        [3.2622e-05, 6.0923e-04, 9.9888e-01, 4.7656e-04],\n",
      "        [3.5286e-05, 8.3307e-04, 9.9667e-01, 2.4629e-03],\n",
      "        [1.9774e-05, 4.4636e-04, 9.9898e-01, 5.5001e-04],\n",
      "        [1.4753e-05, 3.0055e-04, 9.9946e-01, 2.2906e-04],\n",
      "        [4.8862e-05, 2.4263e-03, 9.9338e-01, 4.1487e-03],\n",
      "        [7.6096e-06, 4.5749e-04, 9.9870e-01, 8.3651e-04],\n",
      "        [5.2006e-05, 1.4710e-03, 9.9569e-01, 2.7906e-03],\n",
      "        [1.4477e-05, 5.1046e-04, 9.9848e-01, 9.9798e-04],\n",
      "        [2.2941e-05, 6.8929e-04, 9.9882e-01, 4.6616e-04],\n",
      "        [8.8323e-05, 2.6318e-03, 9.9581e-01, 1.4712e-03],\n",
      "        [2.0650e-05, 2.4808e-03, 9.9564e-01, 1.8634e-03],\n",
      "        [1.4011e-04, 3.0842e-03, 9.8965e-01, 7.1210e-03],\n",
      "        [2.9401e-05, 5.1010e-04, 9.9786e-01, 1.6015e-03],\n",
      "        [3.0450e-05, 4.6575e-04, 9.9860e-01, 8.9925e-04],\n",
      "        [4.2982e-05, 1.6252e-03, 9.9600e-01, 2.3342e-03],\n",
      "        [9.6290e-05, 1.1048e-03, 9.9638e-01, 2.4173e-03],\n",
      "        [3.0514e-05, 1.0304e-03, 9.9698e-01, 1.9566e-03],\n",
      "        [1.1601e-05, 2.3893e-04, 9.9935e-01, 3.9688e-04],\n",
      "        [1.2154e-04, 4.0680e-03, 9.9469e-01, 1.1228e-03],\n",
      "        [6.9354e-05, 8.9652e-04, 9.9827e-01, 7.6755e-04],\n",
      "        [2.3697e-05, 1.9235e-03, 9.9420e-01, 3.8530e-03],\n",
      "        [5.1452e-05, 1.0761e-03, 9.9643e-01, 2.4384e-03],\n",
      "        [2.3880e-05, 4.8196e-04, 9.9718e-01, 2.3153e-03],\n",
      "        [5.1009e-05, 4.8728e-04, 9.9847e-01, 9.9297e-04],\n",
      "        [1.9377e-05, 1.0031e-03, 9.9612e-01, 2.8591e-03],\n",
      "        [8.6493e-05, 1.9030e-03, 9.9669e-01, 1.3236e-03],\n",
      "        [1.6468e-05, 6.3128e-04, 9.9783e-01, 1.5188e-03],\n",
      "        [1.8151e-05, 6.1003e-04, 9.9664e-01, 2.7367e-03],\n",
      "        [4.1684e-05, 5.2481e-04, 9.9828e-01, 1.1561e-03],\n",
      "        [4.0989e-05, 2.3147e-03, 9.9523e-01, 2.4128e-03],\n",
      "        [5.0553e-05, 1.3175e-03, 9.9620e-01, 2.4327e-03],\n",
      "        [4.3861e-05, 4.1125e-03, 9.9450e-01, 1.3457e-03],\n",
      "        [4.6098e-05, 1.1969e-03, 9.9414e-01, 4.6208e-03],\n",
      "        [3.8301e-05, 1.2213e-03, 9.9719e-01, 1.5551e-03],\n",
      "        [1.9086e-05, 5.5778e-04, 9.9832e-01, 1.1034e-03],\n",
      "        [1.8997e-05, 2.6132e-04, 9.9893e-01, 7.8586e-04],\n",
      "        [7.5300e-05, 1.5141e-03, 9.9485e-01, 3.5619e-03],\n",
      "        [1.3493e-04, 3.1028e-03, 9.9415e-01, 2.6168e-03],\n",
      "        [2.1703e-05, 1.2122e-04, 9.9891e-01, 9.4672e-04],\n",
      "        [1.8610e-05, 5.7826e-04, 9.9875e-01, 6.5639e-04],\n",
      "        [3.4222e-05, 6.0208e-04, 9.9690e-01, 2.4681e-03],\n",
      "        [8.2410e-05, 2.5434e-03, 9.9557e-01, 1.8040e-03],\n",
      "        [6.7586e-05, 1.5160e-03, 9.9635e-01, 2.0700e-03],\n",
      "        [3.3520e-05, 5.5930e-04, 9.9899e-01, 4.1291e-04],\n",
      "        [3.4752e-05, 9.9568e-04, 9.9404e-01, 4.9318e-03],\n",
      "        [8.4214e-05, 2.6930e-03, 9.9353e-01, 3.6914e-03],\n",
      "        [9.1412e-05, 6.7327e-03, 9.9022e-01, 2.9541e-03],\n",
      "        [2.7393e-05, 1.3136e-03, 9.9793e-01, 7.2514e-04],\n",
      "        [2.8487e-05, 2.5514e-04, 9.9908e-01, 6.3972e-04],\n",
      "        [9.0193e-05, 5.1036e-03, 9.9070e-01, 4.1074e-03],\n",
      "        [7.4164e-05, 9.8756e-04, 9.9599e-01, 2.9454e-03],\n",
      "        [9.2729e-06, 4.3020e-04, 9.9809e-01, 1.4720e-03],\n",
      "        [2.3930e-05, 9.5477e-04, 9.9709e-01, 1.9358e-03],\n",
      "        [4.7941e-06, 2.4505e-04, 9.9895e-01, 8.0310e-04],\n",
      "        [4.2024e-05, 8.0717e-04, 9.9753e-01, 1.6239e-03],\n",
      "        [1.5471e-05, 1.0185e-03, 9.9765e-01, 1.3177e-03],\n",
      "        [2.8903e-05, 3.4440e-03, 9.8628e-01, 1.0245e-02],\n",
      "        [1.4360e-05, 3.8960e-04, 9.9775e-01, 1.8434e-03],\n",
      "        [2.5801e-05, 1.0719e-03, 9.9808e-01, 8.2210e-04],\n",
      "        [9.8919e-06, 2.4320e-04, 9.9936e-01, 3.8310e-04],\n",
      "        [1.7159e-05, 6.7185e-04, 9.9817e-01, 1.1372e-03],\n",
      "        [5.1253e-05, 2.0062e-03, 9.9481e-01, 3.1318e-03],\n",
      "        [1.8130e-05, 1.0886e-03, 9.9744e-01, 1.4543e-03],\n",
      "        [1.6029e-04, 4.7506e-03, 9.9122e-01, 3.8717e-03],\n",
      "        [5.6252e-05, 4.8884e-04, 9.9733e-01, 2.1224e-03],\n",
      "        [1.9880e-05, 9.3937e-04, 9.9797e-01, 1.0724e-03],\n",
      "        [5.5235e-05, 2.2294e-03, 9.9610e-01, 1.6132e-03],\n",
      "        [7.9146e-06, 2.8073e-04, 9.9816e-01, 1.5487e-03],\n",
      "        [1.2419e-05, 4.6542e-04, 9.9742e-01, 2.1054e-03],\n",
      "        [2.7023e-05, 3.2414e-04, 9.9863e-01, 1.0205e-03],\n",
      "        [3.1088e-05, 4.9925e-04, 9.9735e-01, 2.1161e-03],\n",
      "        [3.5917e-05, 1.0132e-03, 9.9771e-01, 1.2437e-03],\n",
      "        [8.1752e-05, 1.1558e-03, 9.9671e-01, 2.0516e-03],\n",
      "        [3.7131e-05, 1.0504e-03, 9.9707e-01, 1.8455e-03],\n",
      "        [3.5653e-05, 1.2766e-03, 9.9769e-01, 9.9717e-04],\n",
      "        [2.1510e-05, 7.7822e-04, 9.9642e-01, 2.7790e-03],\n",
      "        [1.4849e-05, 7.3988e-04, 9.9644e-01, 2.8056e-03],\n",
      "        [3.5654e-05, 9.5424e-04, 9.9737e-01, 1.6404e-03],\n",
      "        [1.1749e-04, 3.6338e-03, 9.9302e-01, 3.2270e-03],\n",
      "        [1.4377e-05, 3.9865e-04, 9.9837e-01, 1.2152e-03],\n",
      "        [2.9957e-05, 1.1605e-03, 9.9569e-01, 3.1179e-03],\n",
      "        [7.8686e-05, 2.5471e-03, 9.9532e-01, 2.0492e-03],\n",
      "        [1.4234e-05, 2.5692e-04, 9.9845e-01, 1.2788e-03],\n",
      "        [2.1922e-05, 1.7840e-04, 9.9937e-01, 4.2845e-04],\n",
      "        [1.5702e-05, 8.9692e-04, 9.9818e-01, 9.1022e-04],\n",
      "        [4.7274e-05, 4.7280e-04, 9.9549e-01, 3.9862e-03],\n",
      "        [9.3048e-05, 1.8472e-03, 9.8794e-01, 1.0120e-02],\n",
      "        [2.3995e-05, 4.6577e-04, 9.9593e-01, 3.5762e-03],\n",
      "        [1.5299e-05, 5.7161e-04, 9.9797e-01, 1.4388e-03],\n",
      "        [2.3519e-05, 3.0674e-03, 9.9144e-01, 5.4678e-03],\n",
      "        [4.7453e-05, 7.2198e-04, 9.9785e-01, 1.3825e-03],\n",
      "        [1.5281e-05, 2.3419e-04, 9.9799e-01, 1.7569e-03],\n",
      "        [1.0063e-04, 4.1958e-03, 9.9361e-01, 2.0951e-03],\n",
      "        [2.9371e-05, 2.1527e-03, 9.9278e-01, 5.0352e-03],\n",
      "        [1.1554e-05, 4.7394e-04, 9.9789e-01, 1.6203e-03],\n",
      "        [5.6579e-05, 6.5685e-04, 9.9849e-01, 8.0145e-04],\n",
      "        [1.2027e-04, 1.9689e-03, 9.9071e-01, 7.2048e-03],\n",
      "        [9.2696e-06, 3.6860e-04, 9.9742e-01, 2.2037e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.0881e-07, 1.6562e-05, 4.9662e-03, 9.9502e-01],\n",
      "        [2.6267e-07, 4.6031e-06, 2.0246e-03, 9.9797e-01],\n",
      "        [4.7775e-07, 1.2306e-05, 4.1454e-03, 9.9584e-01],\n",
      "        [6.2324e-07, 7.5344e-06, 2.6593e-03, 9.9733e-01],\n",
      "        [7.7205e-07, 1.0653e-05, 4.4728e-03, 9.9552e-01],\n",
      "        [6.9693e-07, 6.4112e-05, 2.8033e-03, 9.9713e-01],\n",
      "        [2.8855e-07, 1.0041e-05, 3.9738e-03, 9.9602e-01],\n",
      "        [5.8390e-07, 2.5224e-05, 3.4084e-03, 9.9657e-01],\n",
      "        [6.6025e-07, 1.9303e-05, 1.9545e-03, 9.9803e-01],\n",
      "        [6.2059e-07, 1.7541e-05, 7.6329e-03, 9.9235e-01],\n",
      "        [1.0426e-06, 1.7026e-05, 1.1545e-03, 9.9883e-01],\n",
      "        [1.2862e-06, 2.1714e-05, 6.0040e-03, 9.9397e-01],\n",
      "        [4.7899e-07, 3.2368e-05, 4.4587e-04, 9.9952e-01],\n",
      "        [2.7227e-07, 7.9691e-06, 3.2557e-04, 9.9967e-01],\n",
      "        [8.2042e-08, 2.3096e-06, 9.6387e-05, 9.9990e-01],\n",
      "        [1.5013e-07, 2.3137e-06, 2.2589e-04, 9.9977e-01],\n",
      "        [1.6093e-07, 5.1524e-06, 5.7563e-04, 9.9942e-01],\n",
      "        [5.0113e-07, 6.4009e-06, 1.8835e-03, 9.9811e-01],\n",
      "        [6.5418e-08, 2.3835e-06, 5.0091e-04, 9.9950e-01],\n",
      "        [6.2927e-08, 1.6862e-06, 1.2707e-04, 9.9987e-01],\n",
      "        [4.1932e-07, 6.3010e-06, 9.7389e-04, 9.9902e-01],\n",
      "        [3.3313e-07, 2.7831e-06, 3.8118e-04, 9.9962e-01],\n",
      "        [1.1652e-07, 2.4170e-06, 6.1226e-04, 9.9939e-01],\n",
      "        [3.3514e-07, 2.1508e-05, 1.4625e-03, 9.9852e-01],\n",
      "        [2.0277e-07, 3.0654e-06, 4.3004e-04, 9.9957e-01],\n",
      "        [6.8433e-08, 2.7239e-06, 3.1475e-04, 9.9968e-01],\n",
      "        [3.3714e-07, 3.9583e-06, 1.7546e-04, 9.9982e-01],\n",
      "        [9.7668e-08, 2.4051e-06, 8.7728e-05, 9.9991e-01],\n",
      "        [1.3918e-07, 5.7039e-06, 8.3683e-04, 9.9916e-01],\n",
      "        [8.7170e-08, 8.1531e-07, 1.4436e-04, 9.9985e-01],\n",
      "        [2.5905e-07, 1.1787e-05, 1.7178e-03, 9.9827e-01],\n",
      "        [2.7100e-07, 8.3243e-06, 5.4148e-04, 9.9945e-01],\n",
      "        [1.4291e-07, 2.6745e-06, 8.4956e-05, 9.9991e-01],\n",
      "        [1.0099e-07, 1.8644e-06, 1.8334e-04, 9.9981e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(89.9398) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[2.5402e-04, 9.9962e-01, 4.0318e-05, 8.9839e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9999e-01, 5.2889e-06, 2.2581e-06, 2.2085e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.5875e-05, 1.5138e-06, 9.9993e-01, 4.5817e-05],\n",
      "        [3.6177e-05, 2.8458e-05, 9.9937e-01, 5.6445e-04],\n",
      "        [2.9943e-05, 2.2463e-06, 9.9990e-01, 6.3999e-05],\n",
      "        [2.3442e-06, 3.8645e-06, 9.9971e-01, 2.8155e-04],\n",
      "        [1.0279e-05, 2.3553e-06, 9.9984e-01, 1.4606e-04],\n",
      "        [3.4368e-06, 8.3575e-07, 9.9996e-01, 3.6950e-05],\n",
      "        [4.8378e-06, 9.9877e-07, 9.9974e-01, 2.5109e-04],\n",
      "        [1.1379e-05, 1.5027e-06, 9.9975e-01, 2.3997e-04],\n",
      "        [1.4082e-05, 8.9755e-07, 9.9990e-01, 8.4831e-05],\n",
      "        [2.1365e-06, 9.7428e-07, 9.9992e-01, 7.4081e-05],\n",
      "        [5.0111e-06, 9.2353e-06, 9.9951e-01, 4.7398e-04],\n",
      "        [4.7585e-06, 9.5430e-07, 9.9992e-01, 7.5823e-05],\n",
      "        [2.1957e-05, 9.5948e-06, 9.9982e-01, 1.4793e-04],\n",
      "        [1.6436e-05, 1.7384e-06, 9.9989e-01, 8.7145e-05],\n",
      "        [6.8210e-06, 4.4800e-06, 9.9980e-01, 1.9355e-04],\n",
      "        [1.8887e-05, 3.6942e-06, 9.9991e-01, 7.1353e-05],\n",
      "        [1.9890e-05, 1.4909e-06, 9.9993e-01, 4.7558e-05],\n",
      "        [7.7326e-06, 1.4149e-06, 9.9982e-01, 1.6807e-04],\n",
      "        [4.0181e-06, 6.8045e-07, 9.9997e-01, 2.7222e-05],\n",
      "        [2.3959e-06, 7.3848e-07, 9.9996e-01, 3.8245e-05],\n",
      "        [2.2266e-05, 2.5176e-06, 9.9977e-01, 2.0706e-04],\n",
      "        [7.6520e-06, 4.2497e-06, 9.9994e-01, 5.2669e-05],\n",
      "        [1.6846e-05, 1.2772e-06, 9.9979e-01, 1.9665e-04],\n",
      "        [1.1074e-05, 1.3992e-05, 9.9959e-01, 3.8960e-04],\n",
      "        [3.5687e-05, 2.7694e-06, 9.9981e-01, 1.5454e-04],\n",
      "        [9.1563e-06, 3.9379e-06, 9.9969e-01, 2.9864e-04],\n",
      "        [3.2926e-06, 2.3850e-06, 9.9995e-01, 4.4957e-05],\n",
      "        [1.0655e-05, 1.8340e-06, 9.9994e-01, 5.0076e-05],\n",
      "        [6.1732e-06, 1.7408e-06, 9.9980e-01, 1.9193e-04],\n",
      "        [1.8991e-05, 2.6773e-06, 9.9985e-01, 1.2346e-04],\n",
      "        [8.4223e-06, 1.9047e-06, 9.9985e-01, 1.3549e-04],\n",
      "        [8.3683e-06, 7.7858e-07, 9.9991e-01, 7.7997e-05],\n",
      "        [4.2620e-06, 1.6550e-06, 9.9981e-01, 1.8724e-04],\n",
      "        [1.7150e-05, 9.5444e-07, 9.9991e-01, 7.3303e-05],\n",
      "        [3.0302e-05, 2.8053e-06, 9.9971e-01, 2.5284e-04],\n",
      "        [5.2812e-06, 4.8841e-07, 9.9975e-01, 2.4327e-04],\n",
      "        [3.6930e-05, 4.7210e-06, 9.9965e-01, 3.0641e-04],\n",
      "        [1.0332e-05, 4.1892e-07, 9.9990e-01, 9.2897e-05],\n",
      "        [1.1133e-05, 1.3877e-06, 9.9992e-01, 6.7391e-05],\n",
      "        [3.5581e-06, 1.1632e-06, 9.9979e-01, 2.0862e-04],\n",
      "        [3.8002e-06, 2.1916e-06, 9.9985e-01, 1.4845e-04],\n",
      "        [6.1441e-06, 2.3726e-06, 9.9995e-01, 3.8034e-05],\n",
      "        [6.1246e-06, 1.3713e-06, 9.9995e-01, 4.2589e-05],\n",
      "        [2.4911e-05, 3.8722e-06, 9.9986e-01, 1.1532e-04],\n",
      "        [9.7319e-06, 7.8503e-07, 9.9993e-01, 5.6225e-05],\n",
      "        [4.5099e-06, 1.4029e-06, 9.9986e-01, 1.3399e-04],\n",
      "        [2.9238e-05, 1.5633e-06, 9.9925e-01, 7.1530e-04],\n",
      "        [6.7481e-06, 3.0220e-06, 9.9983e-01, 1.6506e-04],\n",
      "        [1.6789e-05, 3.0289e-06, 9.9991e-01, 7.4965e-05],\n",
      "        [3.6944e-06, 6.9522e-07, 9.9998e-01, 1.1550e-05],\n",
      "        [3.3479e-05, 4.5132e-06, 9.9984e-01, 1.2289e-04],\n",
      "        [3.9489e-06, 5.8382e-07, 9.9990e-01, 9.1817e-05],\n",
      "        [6.1659e-06, 1.0365e-06, 9.9972e-01, 2.6906e-04],\n",
      "        [5.5932e-06, 3.6542e-06, 9.9995e-01, 4.1021e-05],\n",
      "        [9.3749e-06, 4.1691e-06, 9.9974e-01, 2.4634e-04],\n",
      "        [1.9980e-05, 7.2860e-06, 9.9972e-01, 2.5291e-04],\n",
      "        [8.3160e-06, 3.2841e-06, 9.9992e-01, 6.9452e-05],\n",
      "        [1.8171e-05, 1.2266e-06, 9.9985e-01, 1.2925e-04],\n",
      "        [7.3787e-06, 2.3682e-06, 9.9968e-01, 3.0539e-04],\n",
      "        [1.5900e-05, 4.6320e-06, 9.9985e-01, 1.2650e-04],\n",
      "        [6.9001e-06, 2.4506e-06, 9.9991e-01, 7.9832e-05],\n",
      "        [6.3919e-06, 8.3017e-07, 9.9992e-01, 7.3290e-05],\n",
      "        [1.3939e-05, 8.7769e-06, 9.9986e-01, 1.1694e-04],\n",
      "        [1.0697e-05, 2.6557e-06, 9.9990e-01, 8.3604e-05],\n",
      "        [8.3375e-06, 2.1139e-06, 9.9994e-01, 4.5615e-05],\n",
      "        [2.3864e-05, 6.0655e-06, 9.9991e-01, 5.5859e-05],\n",
      "        [1.5982e-05, 9.6519e-06, 9.9959e-01, 3.8224e-04],\n",
      "        [4.5056e-06, 9.9599e-07, 9.9978e-01, 2.1372e-04],\n",
      "        [1.5481e-05, 2.5958e-06, 9.9982e-01, 1.6195e-04],\n",
      "        [1.2633e-05, 4.7449e-06, 9.9970e-01, 2.7837e-04],\n",
      "        [1.1820e-05, 6.1675e-06, 9.9987e-01, 1.1666e-04],\n",
      "        [1.7864e-05, 6.2468e-06, 9.9984e-01, 1.3871e-04],\n",
      "        [2.7586e-06, 3.1044e-07, 9.9980e-01, 1.9223e-04],\n",
      "        [1.7696e-05, 1.0448e-06, 9.9988e-01, 9.8283e-05],\n",
      "        [4.1765e-06, 1.4967e-06, 9.9995e-01, 3.9785e-05],\n",
      "        [5.9087e-06, 7.7869e-07, 9.9983e-01, 1.6132e-04],\n",
      "        [4.4206e-05, 4.8227e-06, 9.9976e-01, 1.8852e-04],\n",
      "        [2.4470e-05, 6.7772e-06, 9.9905e-01, 9.1463e-04],\n",
      "        [1.6341e-05, 3.5573e-06, 9.9975e-01, 2.3409e-04],\n",
      "        [1.1344e-05, 2.0940e-06, 9.9986e-01, 1.3144e-04],\n",
      "        [7.5119e-06, 9.3827e-06, 9.9944e-01, 5.4657e-04],\n",
      "        [1.4779e-05, 1.2904e-06, 9.9972e-01, 2.6476e-04],\n",
      "        [2.3919e-05, 4.3981e-06, 9.9995e-01, 2.5799e-05],\n",
      "        [2.2723e-05, 1.6049e-06, 9.9979e-01, 1.8393e-04],\n",
      "        [5.7607e-06, 3.1149e-06, 9.9994e-01, 5.4478e-05],\n",
      "        [2.3423e-05, 2.3061e-06, 9.9994e-01, 3.6997e-05],\n",
      "        [3.5974e-06, 2.9987e-06, 9.9983e-01, 1.6549e-04],\n",
      "        [1.5371e-05, 1.4588e-06, 9.9991e-01, 7.2779e-05],\n",
      "        [1.9438e-06, 4.0610e-07, 9.9999e-01, 1.1223e-05],\n",
      "        [3.5684e-06, 1.3365e-06, 9.9993e-01, 6.3604e-05],\n",
      "        [9.6347e-06, 1.5264e-06, 9.9993e-01, 5.6566e-05],\n",
      "        [2.3445e-05, 4.2279e-06, 9.9964e-01, 3.3245e-04],\n",
      "        [1.2486e-05, 1.6665e-06, 9.9950e-01, 4.8172e-04],\n",
      "        [1.8456e-05, 1.9400e-06, 9.9995e-01, 3.4262e-05],\n",
      "        [3.5533e-05, 2.5672e-06, 9.9981e-01, 1.4995e-04],\n",
      "        [5.2244e-06, 2.8464e-06, 9.9977e-01, 2.2425e-04],\n",
      "        [4.8336e-06, 1.4651e-06, 9.9982e-01, 1.7281e-04],\n",
      "        [1.9146e-05, 1.0072e-06, 9.9989e-01, 8.8658e-05],\n",
      "        [2.9150e-05, 1.5811e-05, 9.9790e-01, 2.0596e-03],\n",
      "        [1.8310e-06, 5.7882e-07, 9.9998e-01, 1.6728e-05],\n",
      "        [2.0368e-05, 4.6886e-06, 9.9983e-01, 1.4741e-04],\n",
      "        [1.0867e-05, 7.6114e-07, 9.9987e-01, 1.1578e-04],\n",
      "        [6.6970e-05, 3.5895e-06, 9.9981e-01, 1.1586e-04],\n",
      "        [4.5175e-05, 5.5182e-06, 9.9955e-01, 4.0398e-04],\n",
      "        [4.5198e-06, 1.8287e-06, 9.9944e-01, 5.5448e-04],\n",
      "        [8.7065e-06, 2.8871e-06, 9.9990e-01, 9.1296e-05],\n",
      "        [3.6702e-06, 1.6434e-06, 9.9996e-01, 3.6072e-05],\n",
      "        [6.0931e-05, 3.4626e-06, 9.9986e-01, 7.9880e-05],\n",
      "        [9.8909e-06, 6.5203e-07, 9.9993e-01, 5.5592e-05],\n",
      "        [3.8750e-06, 6.3058e-07, 9.9989e-01, 1.0153e-04],\n",
      "        [9.4860e-06, 1.6690e-06, 9.9989e-01, 1.0204e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.9196e-07, 3.8404e-07, 3.2169e-03, 9.9678e-01],\n",
      "        [1.3963e-07, 5.3486e-08, 3.0740e-05, 9.9997e-01],\n",
      "        [2.9911e-08, 4.5074e-08, 4.4666e-05, 9.9996e-01],\n",
      "        [4.5941e-07, 9.8671e-08, 3.1839e-04, 9.9968e-01],\n",
      "        [7.9561e-08, 7.0771e-08, 6.3206e-05, 9.9994e-01],\n",
      "        [9.7174e-08, 1.0771e-07, 1.0757e-04, 9.9989e-01],\n",
      "        [5.6077e-08, 2.5855e-08, 9.0016e-05, 9.9991e-01],\n",
      "        [7.5020e-08, 1.6500e-07, 1.9158e-04, 9.9981e-01],\n",
      "        [1.4091e-08, 1.2841e-08, 7.3010e-05, 9.9993e-01],\n",
      "        [3.3287e-08, 1.4151e-08, 1.7848e-05, 9.9998e-01],\n",
      "        [3.1079e-08, 3.3279e-08, 4.4546e-05, 9.9996e-01],\n",
      "        [3.3351e-08, 1.3287e-08, 8.1162e-05, 9.9992e-01],\n",
      "        [1.1710e-08, 1.4256e-08, 1.3834e-05, 9.9999e-01],\n",
      "        [2.2749e-07, 9.8147e-08, 1.6924e-04, 9.9983e-01],\n",
      "        [4.5662e-08, 8.5567e-08, 2.1188e-04, 9.9979e-01],\n",
      "        [2.2564e-08, 2.6733e-08, 1.5095e-04, 9.9985e-01],\n",
      "        [1.2782e-08, 2.3949e-08, 2.5733e-05, 9.9997e-01],\n",
      "        [4.8708e-08, 5.0257e-08, 1.9206e-05, 9.9998e-01],\n",
      "        [2.7466e-08, 1.3088e-08, 5.1747e-05, 9.9995e-01],\n",
      "        [6.2826e-08, 1.7446e-08, 5.7352e-05, 9.9994e-01],\n",
      "        [1.8140e-07, 6.6677e-08, 1.8361e-04, 9.9982e-01],\n",
      "        [4.4389e-08, 2.1584e-08, 1.1331e-04, 9.9989e-01],\n",
      "        [4.2628e-08, 3.8830e-08, 3.1230e-05, 9.9997e-01],\n",
      "        [7.6943e-08, 8.5449e-08, 2.7344e-04, 9.9973e-01],\n",
      "        [1.1290e-07, 9.9969e-08, 2.8405e-04, 9.9972e-01],\n",
      "        [2.8989e-08, 3.7197e-08, 3.7428e-05, 9.9996e-01],\n",
      "        [2.4940e-08, 1.1929e-08, 2.4103e-05, 9.9998e-01],\n",
      "        [1.5399e-08, 6.1550e-08, 2.5124e-05, 9.9997e-01],\n",
      "        [1.1991e-07, 5.2881e-08, 9.6541e-05, 9.9990e-01],\n",
      "        [7.3381e-08, 3.3457e-08, 6.0171e-04, 9.9940e-01],\n",
      "        [4.1448e-08, 2.2243e-08, 2.4615e-05, 9.9998e-01],\n",
      "        [6.7892e-08, 7.0353e-08, 7.2944e-04, 9.9927e-01],\n",
      "        [2.2321e-08, 3.1047e-08, 2.9951e-04, 9.9970e-01],\n",
      "        [6.3928e-07, 5.0494e-08, 8.7976e-04, 9.9912e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(94.6727) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[8.0131e-05, 9.9984e-01, 2.3154e-05, 5.4013e-05],\n",
      "        [8.3484e-05, 9.9983e-01, 8.8944e-06, 7.7343e-05],\n",
      "        [3.8499e-05, 9.9984e-01, 2.4131e-05, 9.7428e-05],\n",
      "        [4.2779e-05, 9.9991e-01, 1.2459e-05, 3.2432e-05],\n",
      "        [2.2105e-04, 9.9972e-01, 3.0290e-05, 2.3752e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9990e-01, 4.6313e-05, 4.1720e-05, 7.4885e-06],\n",
      "        [9.9992e-01, 2.8538e-05, 3.6417e-05, 1.9057e-05],\n",
      "        [9.9952e-01, 3.9029e-04, 7.3037e-05, 1.3059e-05],\n",
      "        [9.9981e-01, 8.3785e-05, 9.8717e-05, 4.0879e-06],\n",
      "        [9.9997e-01, 1.8063e-05, 8.5872e-06, 4.4256e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.1665e-06, 6.6144e-06, 9.9990e-01, 9.4455e-05],\n",
      "        [9.6647e-07, 7.9271e-06, 9.9989e-01, 1.0370e-04],\n",
      "        [2.5614e-06, 1.1495e-05, 9.9981e-01, 1.7547e-04],\n",
      "        [4.0345e-06, 3.1067e-05, 9.9984e-01, 1.2316e-04],\n",
      "        [7.4377e-07, 8.6674e-06, 9.9995e-01, 4.0909e-05],\n",
      "        [1.2124e-06, 5.8055e-06, 9.9998e-01, 1.3628e-05],\n",
      "        [3.0344e-06, 8.6954e-06, 9.9996e-01, 3.1821e-05],\n",
      "        [1.2737e-06, 7.3813e-06, 9.9995e-01, 4.6121e-05],\n",
      "        [1.1321e-06, 6.8216e-06, 9.9996e-01, 2.7685e-05],\n",
      "        [8.9991e-07, 6.2118e-06, 9.9997e-01, 2.1744e-05],\n",
      "        [7.8423e-07, 9.0337e-06, 9.9994e-01, 4.9472e-05],\n",
      "        [1.6746e-06, 3.6334e-06, 9.9997e-01, 2.6761e-05],\n",
      "        [5.0813e-07, 4.2122e-06, 9.9993e-01, 6.9383e-05],\n",
      "        [2.4508e-06, 7.7651e-06, 9.9993e-01, 5.5073e-05],\n",
      "        [1.8229e-06, 9.9388e-06, 9.9991e-01, 7.4688e-05],\n",
      "        [3.4779e-07, 4.4971e-06, 9.9995e-01, 4.8454e-05],\n",
      "        [1.3936e-06, 9.8181e-06, 9.9991e-01, 8.3287e-05],\n",
      "        [3.9746e-06, 2.6197e-05, 9.9977e-01, 1.9611e-04],\n",
      "        [8.1598e-06, 4.7339e-05, 9.9961e-01, 3.3747e-04],\n",
      "        [2.3732e-06, 1.0436e-05, 9.9987e-01, 1.1307e-04],\n",
      "        [1.9601e-06, 7.9739e-06, 9.9991e-01, 8.1975e-05],\n",
      "        [5.7031e-07, 4.1386e-06, 9.9987e-01, 1.2780e-04],\n",
      "        [1.4622e-06, 1.4834e-05, 9.9991e-01, 6.9328e-05],\n",
      "        [6.4622e-06, 2.3792e-05, 9.9993e-01, 3.9463e-05],\n",
      "        [4.3301e-07, 3.1742e-06, 9.9994e-01, 5.1418e-05],\n",
      "        [3.1849e-06, 1.1164e-05, 9.9995e-01, 3.1294e-05],\n",
      "        [8.7527e-07, 1.0049e-05, 9.9993e-01, 5.5944e-05],\n",
      "        [2.4496e-07, 6.3587e-06, 9.9990e-01, 8.9621e-05],\n",
      "        [4.9658e-07, 2.3033e-05, 9.9987e-01, 1.1016e-04],\n",
      "        [3.2651e-06, 2.0062e-05, 9.9993e-01, 4.4096e-05],\n",
      "        [4.4048e-06, 1.5183e-05, 9.9993e-01, 5.3440e-05],\n",
      "        [6.7980e-06, 1.6659e-05, 9.9986e-01, 1.1811e-04],\n",
      "        [3.3306e-06, 5.6708e-05, 9.9982e-01, 1.1548e-04],\n",
      "        [1.0429e-06, 3.2876e-06, 9.9994e-01, 5.3740e-05],\n",
      "        [1.7172e-06, 1.2224e-05, 9.9990e-01, 8.5176e-05],\n",
      "        [4.1393e-07, 2.2138e-06, 9.9998e-01, 1.4470e-05],\n",
      "        [9.5500e-07, 1.9030e-05, 9.9994e-01, 4.2383e-05],\n",
      "        [9.8200e-07, 1.3540e-05, 9.9985e-01, 1.3364e-04],\n",
      "        [3.5776e-07, 3.0159e-06, 9.9998e-01, 1.4098e-05],\n",
      "        [4.1948e-07, 1.6736e-05, 9.9992e-01, 6.5460e-05],\n",
      "        [3.6658e-07, 2.9216e-06, 9.9996e-01, 3.2003e-05],\n",
      "        [7.2111e-07, 1.0728e-05, 9.9997e-01, 1.4478e-05],\n",
      "        [1.6421e-06, 2.9250e-06, 9.9991e-01, 8.7463e-05],\n",
      "        [7.4112e-06, 6.7524e-05, 9.9967e-01, 2.5835e-04],\n",
      "        [1.3672e-06, 3.1624e-05, 9.9973e-01, 2.3908e-04],\n",
      "        [9.2689e-07, 1.1889e-05, 9.9987e-01, 1.2185e-04],\n",
      "        [2.0197e-06, 9.9917e-06, 9.9993e-01, 5.6573e-05],\n",
      "        [1.2163e-06, 9.7407e-06, 9.9998e-01, 1.3992e-05],\n",
      "        [2.8848e-06, 1.5366e-05, 9.9992e-01, 5.8988e-05],\n",
      "        [1.4882e-06, 1.0788e-05, 9.9998e-01, 1.0983e-05],\n",
      "        [1.0414e-06, 3.0630e-05, 9.9990e-01, 6.4779e-05],\n",
      "        [2.9077e-06, 1.0098e-05, 9.9982e-01, 1.6850e-04],\n",
      "        [3.7772e-06, 3.1991e-05, 9.9959e-01, 3.7859e-04],\n",
      "        [7.6456e-07, 1.0424e-05, 9.9996e-01, 2.5939e-05],\n",
      "        [5.8090e-07, 3.0287e-05, 9.9988e-01, 8.7594e-05],\n",
      "        [4.5929e-06, 3.0609e-05, 9.9970e-01, 2.6899e-04],\n",
      "        [7.7535e-07, 4.5248e-06, 9.9996e-01, 3.0526e-05],\n",
      "        [3.2578e-06, 5.9551e-05, 9.9982e-01, 1.1579e-04],\n",
      "        [2.1405e-06, 3.2563e-05, 9.9989e-01, 7.1584e-05],\n",
      "        [6.0396e-07, 5.9388e-06, 9.9992e-01, 7.1374e-05],\n",
      "        [1.3912e-06, 4.3046e-06, 9.9994e-01, 5.3358e-05],\n",
      "        [3.4388e-06, 6.2643e-06, 9.9938e-01, 6.0759e-04],\n",
      "        [6.9346e-07, 1.9751e-06, 9.9999e-01, 6.3747e-06],\n",
      "        [2.2672e-06, 2.0123e-05, 9.9992e-01, 5.8185e-05],\n",
      "        [1.2543e-06, 3.9279e-06, 9.9991e-01, 8.4012e-05],\n",
      "        [5.7538e-06, 2.7952e-05, 9.9950e-01, 4.6179e-04],\n",
      "        [1.1809e-06, 1.3160e-05, 9.9978e-01, 2.0690e-04],\n",
      "        [1.6190e-06, 1.0450e-05, 9.9994e-01, 5.2523e-05],\n",
      "        [1.1054e-05, 5.7585e-05, 9.9953e-01, 3.9796e-04],\n",
      "        [4.4143e-06, 2.6751e-05, 9.9989e-01, 7.4477e-05],\n",
      "        [3.0485e-06, 2.6487e-05, 9.9988e-01, 8.9524e-05],\n",
      "        [1.5000e-06, 2.8673e-05, 9.9990e-01, 7.2686e-05],\n",
      "        [8.6090e-07, 1.4244e-05, 9.9979e-01, 1.9248e-04],\n",
      "        [2.0077e-06, 2.0057e-05, 9.9983e-01, 1.5030e-04],\n",
      "        [3.9676e-07, 2.3825e-06, 9.9998e-01, 1.6056e-05],\n",
      "        [4.1132e-06, 1.1545e-05, 9.9997e-01, 1.4165e-05],\n",
      "        [4.6098e-06, 5.4225e-05, 9.9968e-01, 2.5889e-04],\n",
      "        [3.3503e-06, 2.3300e-05, 9.9967e-01, 2.9886e-04],\n",
      "        [2.2852e-06, 5.7344e-06, 9.9996e-01, 2.9396e-05],\n",
      "        [5.2722e-07, 5.2159e-06, 9.9998e-01, 1.1748e-05],\n",
      "        [4.0258e-06, 6.4560e-06, 9.9993e-01, 5.5386e-05],\n",
      "        [4.1738e-07, 7.3446e-06, 9.9997e-01, 2.0004e-05],\n",
      "        [1.9819e-06, 1.0075e-05, 9.9983e-01, 1.5888e-04],\n",
      "        [8.9192e-07, 1.0423e-05, 9.9993e-01, 5.8096e-05],\n",
      "        [1.5359e-06, 2.0204e-05, 9.9986e-01, 1.1563e-04],\n",
      "        [5.3496e-07, 5.6909e-06, 9.9997e-01, 2.5074e-05],\n",
      "        [3.0926e-07, 2.8377e-06, 9.9986e-01, 1.3788e-04],\n",
      "        [1.5477e-06, 1.4058e-05, 9.9996e-01, 2.8366e-05],\n",
      "        [8.8995e-06, 1.2762e-04, 9.9954e-01, 3.2160e-04],\n",
      "        [1.7381e-06, 5.5942e-05, 9.9943e-01, 5.1068e-04],\n",
      "        [6.0062e-07, 1.1378e-05, 9.9993e-01, 5.6368e-05],\n",
      "        [1.1510e-06, 2.5181e-06, 9.9998e-01, 1.2683e-05],\n",
      "        [2.5790e-06, 5.5384e-05, 9.9976e-01, 1.7772e-04],\n",
      "        [3.1527e-06, 3.6460e-05, 9.9968e-01, 2.8365e-04],\n",
      "        [3.0664e-06, 1.7451e-05, 9.9996e-01, 2.1494e-05],\n",
      "        [1.7603e-06, 1.0119e-05, 9.9997e-01, 1.9306e-05],\n",
      "        [3.7131e-06, 9.9777e-05, 9.9871e-01, 1.1845e-03],\n",
      "        [8.6533e-07, 4.1234e-06, 9.9997e-01, 2.0445e-05],\n",
      "        [7.2605e-06, 3.2879e-05, 9.9990e-01, 5.4988e-05],\n",
      "        [2.4327e-06, 5.9167e-06, 9.9996e-01, 3.5969e-05],\n",
      "        [7.8564e-07, 1.5459e-05, 9.9997e-01, 1.1802e-05],\n",
      "        [2.1407e-06, 1.6892e-05, 9.9989e-01, 8.8618e-05],\n",
      "        [1.9147e-06, 2.0229e-05, 9.9978e-01, 1.9436e-04],\n",
      "        [1.5014e-06, 5.6753e-06, 9.9997e-01, 2.6599e-05],\n",
      "        [4.7769e-07, 1.8303e-05, 9.9991e-01, 6.6781e-05],\n",
      "        [1.0174e-06, 3.6707e-06, 9.9997e-01, 2.6131e-05],\n",
      "        [1.8147e-06, 1.7662e-05, 9.9983e-01, 1.5216e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[8.0010e-09, 3.4866e-08, 1.0586e-05, 9.9999e-01],\n",
      "        [4.8213e-09, 3.3275e-08, 5.2741e-06, 9.9999e-01],\n",
      "        [1.4299e-08, 6.5608e-08, 1.6053e-05, 9.9998e-01],\n",
      "        [3.1827e-09, 1.6681e-08, 1.2349e-06, 1.0000e+00],\n",
      "        [5.1684e-09, 4.7045e-08, 1.0085e-05, 9.9999e-01],\n",
      "        [1.1735e-08, 3.3314e-08, 5.1177e-06, 9.9999e-01],\n",
      "        [6.1309e-09, 1.7447e-08, 4.0373e-05, 9.9996e-01],\n",
      "        [1.7596e-08, 1.0989e-07, 4.3274e-05, 9.9996e-01],\n",
      "        [1.9191e-08, 8.0454e-08, 1.2295e-05, 9.9999e-01],\n",
      "        [1.3883e-08, 1.7227e-07, 1.0651e-05, 9.9999e-01],\n",
      "        [4.1359e-08, 1.2782e-07, 2.0677e-05, 9.9998e-01],\n",
      "        [2.1745e-09, 3.0458e-08, 1.4060e-06, 1.0000e+00],\n",
      "        [4.7634e-09, 2.6972e-08, 4.2310e-06, 1.0000e+00],\n",
      "        [2.6512e-09, 2.1009e-08, 1.2907e-05, 9.9999e-01],\n",
      "        [4.4598e-09, 2.3496e-08, 1.2148e-05, 9.9999e-01],\n",
      "        [7.9210e-09, 9.4563e-08, 2.5894e-06, 1.0000e+00],\n",
      "        [9.3294e-09, 2.6534e-08, 4.9882e-05, 9.9995e-01],\n",
      "        [4.1709e-09, 3.5362e-08, 1.4335e-05, 9.9999e-01],\n",
      "        [2.1703e-08, 5.0853e-08, 2.2789e-05, 9.9998e-01],\n",
      "        [2.5182e-09, 8.2885e-08, 1.5165e-05, 9.9998e-01],\n",
      "        [7.8238e-09, 2.6285e-08, 1.0475e-05, 9.9999e-01],\n",
      "        [4.8729e-09, 2.3533e-08, 4.7356e-06, 1.0000e+00],\n",
      "        [1.5960e-09, 2.8881e-08, 5.4915e-06, 9.9999e-01],\n",
      "        [1.4544e-08, 1.3285e-07, 3.3156e-05, 9.9997e-01],\n",
      "        [1.8641e-08, 7.2217e-08, 4.7180e-05, 9.9995e-01],\n",
      "        [1.3805e-08, 6.5069e-08, 2.4920e-05, 9.9997e-01],\n",
      "        [1.3362e-08, 2.7708e-08, 6.5766e-06, 9.9999e-01],\n",
      "        [9.2658e-09, 4.0693e-08, 9.3041e-06, 9.9999e-01],\n",
      "        [6.1963e-09, 3.3250e-08, 7.4106e-06, 9.9999e-01],\n",
      "        [1.0539e-09, 1.4052e-08, 4.1945e-06, 1.0000e+00],\n",
      "        [9.3635e-09, 1.5554e-08, 4.5287e-06, 1.0000e+00],\n",
      "        [1.1397e-08, 2.3887e-08, 1.6863e-05, 9.9998e-01],\n",
      "        [5.1324e-09, 3.3990e-08, 2.2621e-05, 9.9998e-01],\n",
      "        [3.1483e-08, 2.8768e-08, 5.0874e-05, 9.9995e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(95.3584) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.0235e-04, 9.9945e-01, 3.7827e-04, 7.3121e-05],\n",
      "        [9.2489e-02, 8.8341e-01, 2.3455e-02, 6.4541e-04],\n",
      "        [9.0804e-05, 9.9953e-01, 3.1867e-04, 6.0670e-05],\n",
      "        [2.6708e-04, 9.9934e-01, 3.0951e-04, 7.8703e-05],\n",
      "        [1.0956e-04, 9.9951e-01, 3.2253e-04, 6.1272e-05],\n",
      "        [2.6686e-04, 9.9923e-01, 4.4016e-04, 6.2015e-05],\n",
      "        [7.7094e-05, 9.9952e-01, 3.6163e-04, 4.4779e-05],\n",
      "        [1.4650e-04, 9.9930e-01, 4.4826e-04, 1.0725e-04],\n",
      "        [1.4181e-03, 9.9714e-01, 1.3391e-03, 9.8950e-05],\n",
      "        [3.4081e-03, 9.9313e-01, 3.1747e-03, 2.8449e-04],\n",
      "        [7.1761e-05, 9.9964e-01, 2.4238e-04, 4.5506e-05],\n",
      "        [1.0434e-04, 9.9940e-01, 3.8524e-04, 1.0988e-04],\n",
      "        [6.9610e-05, 9.9961e-01, 2.8266e-04, 3.3631e-05],\n",
      "        [1.9633e-04, 9.9840e-01, 1.3587e-03, 4.8622e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[2.9606e-01, 2.6424e-02, 6.7595e-01, 1.5634e-03],\n",
      "        [1.5506e-01, 3.2942e-02, 8.0886e-01, 3.1358e-03],\n",
      "        [5.1846e-01, 5.9450e-02, 4.1939e-01, 2.6987e-03],\n",
      "        [8.0496e-01, 1.3266e-02, 1.8090e-01, 8.6790e-04],\n",
      "        [1.6433e-01, 9.2462e-02, 7.4142e-01, 1.7890e-03],\n",
      "        [4.6588e-01, 1.1990e-01, 4.1273e-01, 1.4821e-03],\n",
      "        [9.3970e-01, 1.0375e-02, 4.9481e-02, 4.4506e-04],\n",
      "        [7.7145e-01, 1.0036e-02, 2.1793e-01, 5.8341e-04],\n",
      "        [4.3475e-01, 1.9729e-02, 5.4454e-01, 9.8159e-04],\n",
      "        [5.3194e-01, 8.2374e-02, 3.8375e-01, 1.9316e-03],\n",
      "        [2.8759e-01, 4.8175e-02, 6.6249e-01, 1.7437e-03],\n",
      "        [7.9129e-01, 4.1679e-02, 1.6358e-01, 3.4509e-03],\n",
      "        [6.0408e-01, 7.9149e-02, 3.1243e-01, 4.3343e-03],\n",
      "        [3.0498e-01, 1.3867e-01, 5.5061e-01, 5.7440e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.2608e-03, 3.4516e-02, 9.6284e-01, 1.3810e-03],\n",
      "        [1.3074e-03, 4.6254e-03, 9.9330e-01, 7.6483e-04],\n",
      "        [3.4329e-03, 7.6282e-02, 9.1520e-01, 5.0898e-03],\n",
      "        [1.7730e-03, 2.5419e-02, 9.7100e-01, 1.8052e-03],\n",
      "        [4.3100e-04, 7.3966e-03, 9.9144e-01, 7.3449e-04],\n",
      "        [1.7374e-03, 1.6949e-02, 9.7860e-01, 2.7183e-03],\n",
      "        [1.9888e-03, 1.3533e-02, 9.8342e-01, 1.0568e-03],\n",
      "        [6.4012e-04, 1.3468e-02, 9.8508e-01, 8.0760e-04],\n",
      "        [5.2856e-04, 6.3868e-03, 9.9269e-01, 3.9558e-04],\n",
      "        [1.3540e-03, 3.7761e-02, 9.5932e-01, 1.5689e-03],\n",
      "        [2.3556e-03, 5.7196e-02, 9.3704e-01, 3.4065e-03],\n",
      "        [8.2036e-04, 1.4526e-02, 9.8339e-01, 1.2609e-03],\n",
      "        [8.6973e-04, 6.7613e-03, 9.9050e-01, 1.8730e-03],\n",
      "        [4.1280e-03, 2.3185e-02, 9.7046e-01, 2.2227e-03],\n",
      "        [3.4096e-03, 1.0243e-02, 9.8559e-01, 7.5771e-04],\n",
      "        [1.2142e-03, 1.3947e-02, 9.8394e-01, 8.9730e-04],\n",
      "        [2.1515e-03, 3.0606e-02, 9.6452e-01, 2.7221e-03],\n",
      "        [1.2613e-03, 1.8865e-02, 9.7885e-01, 1.0237e-03],\n",
      "        [1.2587e-03, 1.4719e-02, 9.8021e-01, 3.8153e-03],\n",
      "        [3.1074e-03, 1.6344e-02, 9.7948e-01, 1.0672e-03],\n",
      "        [1.9730e-03, 2.4556e-02, 9.7039e-01, 3.0842e-03],\n",
      "        [2.5968e-03, 1.3962e-02, 9.7956e-01, 3.8825e-03],\n",
      "        [2.1934e-03, 1.0938e-02, 9.8534e-01, 1.5244e-03],\n",
      "        [1.0102e-03, 2.6514e-02, 9.6999e-01, 2.4908e-03],\n",
      "        [9.5121e-04, 9.2801e-03, 9.8717e-01, 2.6017e-03],\n",
      "        [2.4578e-03, 1.8389e-02, 9.7800e-01, 1.1520e-03],\n",
      "        [3.1270e-04, 6.2052e-03, 9.9296e-01, 5.1788e-04],\n",
      "        [2.0701e-03, 1.5827e-02, 9.8128e-01, 8.1994e-04],\n",
      "        [2.6485e-03, 2.6725e-02, 9.6978e-01, 8.4607e-04],\n",
      "        [1.9452e-03, 3.3723e-02, 9.6195e-01, 2.3786e-03],\n",
      "        [1.7721e-03, 9.8072e-03, 9.8666e-01, 1.7649e-03],\n",
      "        [1.0944e-03, 1.4675e-02, 9.8287e-01, 1.3571e-03],\n",
      "        [1.0157e-03, 2.5940e-02, 9.7085e-01, 2.1906e-03],\n",
      "        [2.3031e-03, 1.6799e-02, 9.7912e-01, 1.7741e-03],\n",
      "        [9.1075e-04, 1.2290e-02, 9.8486e-01, 1.9420e-03],\n",
      "        [1.5798e-03, 3.2429e-02, 9.6528e-01, 7.1050e-04],\n",
      "        [2.5831e-03, 1.8981e-02, 9.7684e-01, 1.6009e-03],\n",
      "        [1.8017e-03, 1.8036e-02, 9.7894e-01, 1.2177e-03],\n",
      "        [2.6282e-03, 3.4595e-02, 9.5796e-01, 4.8198e-03],\n",
      "        [1.6405e-03, 2.5794e-02, 9.6967e-01, 2.8931e-03],\n",
      "        [2.3749e-03, 1.6091e-02, 9.8024e-01, 1.2951e-03],\n",
      "        [8.6899e-04, 1.7541e-02, 9.8011e-01, 1.4781e-03],\n",
      "        [5.3176e-04, 1.5939e-02, 9.8202e-01, 1.5055e-03],\n",
      "        [1.6323e-03, 1.0084e-02, 9.8671e-01, 1.5738e-03],\n",
      "        [1.2274e-03, 1.3113e-02, 9.8374e-01, 1.9211e-03],\n",
      "        [2.3403e-03, 2.0231e-02, 9.7629e-01, 1.1414e-03],\n",
      "        [1.0161e-03, 7.4069e-03, 9.9066e-01, 9.1860e-04],\n",
      "        [7.8775e-04, 7.1430e-03, 9.9094e-01, 1.1284e-03],\n",
      "        [2.0894e-03, 2.1179e-02, 9.7355e-01, 3.1837e-03],\n",
      "        [2.0595e-03, 3.6483e-02, 9.5818e-01, 3.2779e-03],\n",
      "        [9.7607e-04, 2.5625e-02, 9.7135e-01, 2.0442e-03],\n",
      "        [7.6219e-04, 1.0040e-02, 9.8879e-01, 4.0692e-04],\n",
      "        [2.3874e-03, 1.8363e-02, 9.7848e-01, 7.6803e-04],\n",
      "        [1.0644e-03, 1.0099e-02, 9.8825e-01, 5.8514e-04],\n",
      "        [1.3727e-03, 1.1316e-02, 9.8592e-01, 1.3868e-03],\n",
      "        [2.9689e-03, 6.7585e-02, 9.2522e-01, 4.2228e-03],\n",
      "        [1.2227e-03, 1.1821e-02, 9.8573e-01, 1.2287e-03],\n",
      "        [1.5837e-03, 3.9185e-02, 9.5535e-01, 3.8775e-03],\n",
      "        [1.4902e-03, 2.0323e-02, 9.7752e-01, 6.6396e-04],\n",
      "        [1.5932e-03, 8.2667e-03, 9.8794e-01, 2.2020e-03],\n",
      "        [5.1063e-03, 3.9180e-02, 9.4978e-01, 5.9295e-03],\n",
      "        [6.0428e-04, 5.2797e-03, 9.9383e-01, 2.8723e-04],\n",
      "        [9.2531e-04, 5.2298e-03, 9.9315e-01, 6.9515e-04],\n",
      "        [1.5395e-03, 1.5774e-02, 9.8073e-01, 1.9605e-03],\n",
      "        [2.7104e-03, 3.4824e-02, 9.5540e-01, 7.0705e-03],\n",
      "        [1.6446e-03, 2.3228e-02, 9.7377e-01, 1.3604e-03],\n",
      "        [2.6137e-03, 1.8058e-02, 9.7681e-01, 2.5215e-03],\n",
      "        [1.1957e-03, 1.7271e-02, 9.8006e-01, 1.4775e-03],\n",
      "        [9.3492e-04, 7.3041e-03, 9.8969e-01, 2.0712e-03],\n",
      "        [5.0879e-04, 1.3118e-02, 9.8528e-01, 1.0906e-03],\n",
      "        [1.4032e-03, 1.2259e-02, 9.8493e-01, 1.4119e-03],\n",
      "        [2.7782e-03, 8.5860e-03, 9.8417e-01, 4.4608e-03],\n",
      "        [1.5466e-03, 3.9520e-02, 9.5618e-01, 2.7554e-03],\n",
      "        [2.2677e-03, 1.5884e-02, 9.8021e-01, 1.6353e-03],\n",
      "        [1.4808e-03, 1.6405e-02, 9.7853e-01, 3.5848e-03],\n",
      "        [8.7159e-04, 2.2766e-02, 9.7408e-01, 2.2863e-03],\n",
      "        [1.0052e-03, 2.8342e-02, 9.6837e-01, 2.2841e-03],\n",
      "        [1.2530e-03, 1.1786e-02, 9.8522e-01, 1.7395e-03],\n",
      "        [1.0359e-03, 1.2733e-02, 9.8316e-01, 3.0686e-03],\n",
      "        [1.0050e-03, 1.5680e-02, 9.8247e-01, 8.4266e-04],\n",
      "        [2.0624e-03, 1.8766e-02, 9.7762e-01, 1.5539e-03],\n",
      "        [2.2207e-03, 8.7832e-03, 9.8775e-01, 1.2491e-03],\n",
      "        [1.5578e-03, 2.4427e-02, 9.7047e-01, 3.5458e-03],\n",
      "        [2.9867e-03, 3.5009e-02, 9.5831e-01, 3.6908e-03],\n",
      "        [6.0863e-04, 7.6660e-03, 9.9115e-01, 5.7416e-04],\n",
      "        [1.4251e-03, 2.8877e-02, 9.6847e-01, 1.2282e-03],\n",
      "        [8.3129e-04, 1.1968e-02, 9.8602e-01, 1.1779e-03],\n",
      "        [7.0582e-04, 6.8583e-03, 9.9125e-01, 1.1814e-03],\n",
      "        [1.4644e-03, 2.4776e-02, 9.7287e-01, 8.9167e-04],\n",
      "        [7.7242e-04, 8.4960e-03, 9.9003e-01, 7.0145e-04],\n",
      "        [8.1436e-04, 8.8496e-03, 9.8980e-01, 5.3254e-04],\n",
      "        [9.0267e-04, 6.9047e-03, 9.9040e-01, 1.7967e-03],\n",
      "        [1.0269e-03, 1.8640e-02, 9.7919e-01, 1.1479e-03],\n",
      "        [1.1511e-03, 1.3271e-02, 9.8470e-01, 8.7838e-04],\n",
      "        [5.8957e-04, 2.0954e-02, 9.7405e-01, 4.4096e-03],\n",
      "        [9.8049e-04, 1.0302e-02, 9.8716e-01, 1.5529e-03],\n",
      "        [1.5301e-03, 2.2247e-02, 9.7505e-01, 1.1677e-03],\n",
      "        [6.3540e-04, 8.1100e-03, 9.9054e-01, 7.1094e-04],\n",
      "        [7.6838e-04, 6.3663e-03, 9.9181e-01, 1.0566e-03],\n",
      "        [2.0908e-03, 1.7710e-02, 9.7680e-01, 3.3976e-03],\n",
      "        [1.2563e-03, 1.3037e-02, 9.8402e-01, 1.6897e-03],\n",
      "        [2.1853e-03, 1.1922e-02, 9.8470e-01, 1.1973e-03],\n",
      "        [1.0698e-03, 9.9878e-03, 9.8762e-01, 1.3250e-03]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.9262e-05, 5.6600e-05, 2.2582e-03, 9.9767e-01],\n",
      "        [4.1262e-06, 4.6880e-05, 8.5916e-04, 9.9909e-01],\n",
      "        [1.3835e-05, 7.6900e-05, 1.7842e-03, 9.9813e-01],\n",
      "        [3.1140e-06, 2.0138e-05, 1.0631e-03, 9.9891e-01],\n",
      "        [8.8735e-06, 1.8676e-05, 6.1797e-04, 9.9935e-01],\n",
      "        [1.9568e-06, 2.0762e-05, 1.5718e-03, 9.9841e-01],\n",
      "        [3.7631e-05, 1.1518e-04, 2.7218e-03, 9.9713e-01],\n",
      "        [8.2073e-06, 4.3495e-05, 1.4295e-03, 9.9852e-01],\n",
      "        [2.2499e-05, 1.4745e-04, 3.9929e-03, 9.9584e-01],\n",
      "        [1.4177e-04, 5.1062e-04, 7.3327e-03, 9.9201e-01],\n",
      "        [1.1648e-05, 3.0206e-05, 1.6989e-03, 9.9826e-01],\n",
      "        [7.8387e-06, 4.6335e-05, 1.0932e-03, 9.9885e-01],\n",
      "        [3.9606e-06, 3.7432e-05, 4.9954e-04, 9.9946e-01],\n",
      "        [2.5371e-06, 3.0375e-05, 4.2872e-04, 9.9954e-01],\n",
      "        [8.3738e-06, 3.7993e-05, 1.2443e-03, 9.9871e-01],\n",
      "        [2.6943e-05, 2.8823e-04, 7.7257e-03, 9.9196e-01],\n",
      "        [7.4919e-06, 6.4906e-05, 8.9437e-04, 9.9903e-01],\n",
      "        [1.2446e-05, 1.1977e-04, 5.8143e-04, 9.9929e-01],\n",
      "        [6.8736e-06, 2.4870e-05, 9.7484e-04, 9.9899e-01],\n",
      "        [1.9114e-06, 1.4268e-05, 9.3772e-04, 9.9905e-01],\n",
      "        [8.6160e-06, 6.1635e-05, 1.4134e-03, 9.9852e-01],\n",
      "        [5.8608e-06, 3.2493e-05, 3.6357e-04, 9.9960e-01],\n",
      "        [5.6490e-06, 3.0779e-05, 4.6012e-04, 9.9950e-01],\n",
      "        [4.5122e-05, 2.6698e-04, 5.1584e-03, 9.9453e-01],\n",
      "        [4.6034e-05, 3.2484e-04, 2.0721e-03, 9.9756e-01],\n",
      "        [5.9343e-06, 6.9649e-05, 3.4878e-04, 9.9958e-01],\n",
      "        [9.2122e-06, 3.5194e-05, 1.2801e-03, 9.9868e-01],\n",
      "        [3.3906e-06, 1.6392e-05, 1.6205e-04, 9.9982e-01],\n",
      "        [2.5222e-05, 9.8173e-05, 4.1466e-03, 9.9573e-01],\n",
      "        [4.9621e-06, 2.8734e-05, 1.7944e-03, 9.9817e-01],\n",
      "        [4.6033e-06, 3.1152e-05, 9.2593e-04, 9.9904e-01],\n",
      "        [3.6647e-06, 1.2852e-05, 1.4959e-03, 9.9849e-01],\n",
      "        [5.0941e-06, 6.1879e-05, 2.2785e-03, 9.9765e-01],\n",
      "        [2.5348e-06, 1.7803e-05, 3.7237e-04, 9.9961e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(94.0944) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[3.2665e-04, 9.8780e-01, 1.1856e-02, 1.4691e-05],\n",
      "        [5.0781e-05, 9.9747e-01, 2.4541e-03, 2.1400e-05],\n",
      "        [1.4214e-04, 9.9495e-01, 4.8469e-03, 6.3793e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9980e-01, 6.3059e-05, 1.3606e-04, 2.3529e-06],\n",
      "        [9.9928e-01, 4.5348e-04, 2.5757e-04, 6.5669e-06],\n",
      "        [9.9947e-01, 2.3437e-04, 2.9157e-04, 7.2892e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.5455e-04, 1.1626e-02, 9.8811e-01, 5.6157e-06],\n",
      "        [1.8026e-04, 4.5069e-03, 9.9531e-01, 1.8855e-06],\n",
      "        [1.5744e-04, 5.3350e-03, 9.9450e-01, 2.6146e-06],\n",
      "        [3.1654e-04, 7.3339e-03, 9.9234e-01, 4.5928e-06],\n",
      "        [4.1083e-04, 4.8340e-03, 9.9475e-01, 1.0832e-06],\n",
      "        [9.3084e-05, 5.3872e-03, 9.9452e-01, 3.6405e-06],\n",
      "        [5.4245e-04, 6.3624e-03, 9.9309e-01, 4.0740e-06],\n",
      "        [6.1791e-04, 2.0303e-02, 9.7907e-01, 5.2004e-06],\n",
      "        [8.1883e-04, 1.3866e-02, 9.8530e-01, 1.0566e-05],\n",
      "        [1.3489e-04, 4.3346e-03, 9.9553e-01, 2.2600e-06],\n",
      "        [4.4861e-04, 1.5509e-02, 9.8404e-01, 4.2401e-06],\n",
      "        [6.5857e-04, 1.0540e-02, 9.8880e-01, 3.7902e-06],\n",
      "        [1.1152e-04, 4.7014e-03, 9.9519e-01, 1.9706e-06],\n",
      "        [6.3137e-04, 4.2204e-03, 9.9515e-01, 1.8814e-06],\n",
      "        [3.1660e-04, 9.3108e-03, 9.9037e-01, 2.7630e-06],\n",
      "        [1.9057e-04, 3.3514e-03, 9.9646e-01, 1.0903e-06],\n",
      "        [5.5945e-04, 2.7147e-02, 9.7229e-01, 6.8123e-06],\n",
      "        [2.9513e-04, 3.6747e-03, 9.9603e-01, 3.2209e-06],\n",
      "        [1.4254e-04, 4.6909e-03, 9.9516e-01, 2.2712e-06],\n",
      "        [2.1668e-04, 3.8819e-03, 9.9590e-01, 5.8148e-06],\n",
      "        [1.5834e-04, 6.8920e-03, 9.9295e-01, 4.3814e-06],\n",
      "        [2.6765e-04, 6.1236e-03, 9.9361e-01, 1.2627e-06],\n",
      "        [2.6897e-04, 9.0078e-03, 9.9072e-01, 1.8582e-06],\n",
      "        [4.7351e-04, 5.9663e-03, 9.9356e-01, 2.7562e-06],\n",
      "        [1.3127e-04, 7.5111e-03, 9.9235e-01, 3.4657e-06],\n",
      "        [2.0619e-04, 8.0078e-03, 9.9178e-01, 1.8882e-06],\n",
      "        [9.6917e-05, 4.1141e-03, 9.9579e-01, 3.8381e-06],\n",
      "        [1.7804e-04, 2.6061e-03, 9.9721e-01, 2.5279e-06],\n",
      "        [1.8612e-04, 3.4257e-03, 9.9639e-01, 2.3029e-06],\n",
      "        [3.0644e-04, 9.9183e-03, 9.8977e-01, 2.3055e-06],\n",
      "        [8.0177e-04, 1.9608e-02, 9.7958e-01, 7.8600e-06],\n",
      "        [3.7470e-04, 1.7189e-02, 9.8243e-01, 3.3265e-06],\n",
      "        [1.7406e-04, 7.4523e-03, 9.9237e-01, 3.9915e-06],\n",
      "        [2.9366e-04, 9.7065e-03, 9.8999e-01, 5.6793e-06],\n",
      "        [2.6172e-04, 4.8405e-03, 9.9490e-01, 1.7322e-06],\n",
      "        [3.4450e-04, 1.2270e-02, 9.8738e-01, 1.7223e-06],\n",
      "        [5.1196e-04, 1.3933e-02, 9.8555e-01, 5.1619e-06],\n",
      "        [9.2762e-05, 1.0283e-02, 9.8962e-01, 5.5797e-06],\n",
      "        [3.9750e-04, 3.0566e-03, 9.9654e-01, 1.8517e-06],\n",
      "        [4.6827e-04, 9.0528e-03, 9.9048e-01, 1.5934e-06],\n",
      "        [1.8327e-04, 6.8074e-03, 9.9301e-01, 3.2037e-06],\n",
      "        [6.3543e-04, 4.0546e-03, 9.9530e-01, 7.6144e-06],\n",
      "        [1.3604e-04, 8.3498e-03, 9.9151e-01, 3.0638e-06],\n",
      "        [2.2014e-04, 9.3292e-03, 9.9045e-01, 5.4194e-06],\n",
      "        [8.8818e-04, 1.0966e-02, 9.8814e-01, 5.0341e-06],\n",
      "        [9.7764e-05, 2.1932e-03, 9.9771e-01, 7.8196e-07],\n",
      "        [1.7686e-04, 6.5200e-03, 9.9330e-01, 4.8220e-06],\n",
      "        [8.1637e-05, 4.0643e-03, 9.9585e-01, 1.4665e-06],\n",
      "        [1.3609e-04, 7.4255e-03, 9.9244e-01, 2.5411e-06],\n",
      "        [1.9394e-04, 3.8375e-03, 9.9597e-01, 3.3034e-06],\n",
      "        [9.9203e-05, 4.0148e-03, 9.9588e-01, 1.6267e-06],\n",
      "        [3.3794e-04, 7.6538e-03, 9.9200e-01, 6.7038e-06],\n",
      "        [1.7077e-04, 2.7322e-03, 9.9709e-01, 3.2033e-06],\n",
      "        [9.2285e-04, 1.8791e-02, 9.8028e-01, 2.8963e-06],\n",
      "        [1.3611e-04, 6.8847e-03, 9.9297e-01, 4.5651e-06],\n",
      "        [1.2476e-04, 3.6123e-03, 9.9626e-01, 1.0080e-06],\n",
      "        [5.8452e-04, 7.6681e-03, 9.9174e-01, 2.8345e-06],\n",
      "        [2.1032e-04, 3.2694e-03, 9.9652e-01, 2.6479e-06],\n",
      "        [1.4332e-04, 3.8154e-03, 9.9604e-01, 1.3012e-06],\n",
      "        [2.9008e-04, 1.0055e-02, 9.8965e-01, 2.5136e-06],\n",
      "        [1.0457e-04, 1.2722e-02, 9.8716e-01, 8.3526e-06],\n",
      "        [2.1492e-04, 1.4942e-02, 9.8484e-01, 4.6695e-06],\n",
      "        [2.3806e-04, 6.7504e-03, 9.9300e-01, 6.6924e-06],\n",
      "        [2.5568e-04, 2.7296e-02, 9.7244e-01, 6.9747e-06],\n",
      "        [4.9791e-04, 7.1976e-03, 9.9230e-01, 1.9946e-06],\n",
      "        [4.8476e-04, 1.4837e-02, 9.8467e-01, 3.8596e-06],\n",
      "        [7.9672e-04, 1.9721e-02, 9.7948e-01, 3.9546e-06],\n",
      "        [4.5838e-04, 3.3011e-02, 9.6652e-01, 5.9527e-06],\n",
      "        [4.8264e-05, 2.6875e-03, 9.9726e-01, 1.8575e-06],\n",
      "        [3.6662e-04, 1.0171e-02, 9.8946e-01, 2.6363e-06],\n",
      "        [1.1214e-04, 5.4534e-03, 9.9443e-01, 2.4535e-06],\n",
      "        [7.9924e-05, 3.2440e-03, 9.9667e-01, 2.7306e-06],\n",
      "        [1.9531e-04, 5.4764e-03, 9.9433e-01, 1.8850e-06],\n",
      "        [1.6784e-04, 6.2355e-03, 9.9359e-01, 3.6314e-06],\n",
      "        [2.4263e-04, 5.1659e-03, 9.9459e-01, 1.3189e-06],\n",
      "        [4.1388e-04, 6.3586e-03, 9.9322e-01, 3.5105e-06],\n",
      "        [2.7791e-04, 6.1863e-03, 9.9353e-01, 3.8136e-06],\n",
      "        [7.0147e-04, 1.3382e-02, 9.8591e-01, 7.4281e-06],\n",
      "        [1.4961e-04, 5.8965e-03, 9.9395e-01, 2.6495e-06],\n",
      "        [2.2647e-04, 4.8958e-03, 9.9487e-01, 2.9273e-06],\n",
      "        [2.9274e-04, 4.4381e-03, 9.9527e-01, 3.6957e-06],\n",
      "        [1.9736e-04, 5.0050e-03, 9.9480e-01, 1.2825e-06],\n",
      "        [2.0875e-04, 5.2083e-03, 9.9458e-01, 2.0652e-06],\n",
      "        [4.3863e-04, 1.4700e-02, 9.8485e-01, 1.0992e-05],\n",
      "        [3.6264e-04, 3.4415e-03, 9.9619e-01, 2.7549e-06],\n",
      "        [3.2923e-04, 1.1006e-02, 9.8866e-01, 2.1998e-06],\n",
      "        [7.1433e-04, 9.1804e-03, 9.9010e-01, 4.7138e-06],\n",
      "        [1.3732e-04, 7.1011e-03, 9.9276e-01, 4.1350e-06],\n",
      "        [5.6664e-04, 7.6572e-03, 9.9177e-01, 2.9308e-06],\n",
      "        [5.3199e-04, 2.8695e-03, 9.9660e-01, 2.4340e-06],\n",
      "        [2.1760e-04, 4.5463e-03, 9.9523e-01, 3.5479e-06],\n",
      "        [3.5529e-04, 1.7486e-02, 9.8215e-01, 5.7306e-06],\n",
      "        [1.8056e-04, 6.6715e-03, 9.9315e-01, 2.3944e-06],\n",
      "        [2.2686e-04, 7.3321e-03, 9.9244e-01, 2.8613e-06],\n",
      "        [4.1721e-04, 6.3980e-03, 9.9318e-01, 3.8726e-06],\n",
      "        [4.1049e-04, 5.3334e-03, 9.9425e-01, 5.5066e-06],\n",
      "        [1.9385e-04, 8.4323e-03, 9.9136e-01, 9.3199e-06],\n",
      "        [3.1255e-04, 4.7434e-03, 9.9494e-01, 1.8738e-06],\n",
      "        [3.3139e-04, 1.0153e-02, 9.8951e-01, 3.6045e-06],\n",
      "        [3.8030e-04, 1.3046e-02, 9.8657e-01, 5.6104e-06],\n",
      "        [3.7345e-04, 9.6356e-03, 9.8999e-01, 4.9705e-06],\n",
      "        [8.0988e-04, 1.2382e-02, 9.8681e-01, 2.8798e-06],\n",
      "        [6.0636e-04, 1.1049e-02, 9.8834e-01, 3.5330e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.2618e-07, 7.3537e-06, 4.7884e-04, 9.9951e-01],\n",
      "        [8.3086e-07, 2.5927e-06, 3.3411e-04, 9.9966e-01],\n",
      "        [1.2270e-06, 3.7471e-05, 1.6121e-03, 9.9835e-01],\n",
      "        [9.0201e-07, 1.9375e-06, 1.3254e-04, 9.9986e-01],\n",
      "        [8.1505e-07, 7.9639e-06, 4.7397e-04, 9.9952e-01],\n",
      "        [4.0813e-07, 1.4664e-06, 3.1465e-04, 9.9968e-01],\n",
      "        [2.2437e-07, 3.0053e-06, 5.1493e-04, 9.9948e-01],\n",
      "        [1.2231e-06, 2.2146e-05, 9.5846e-04, 9.9902e-01],\n",
      "        [7.8708e-08, 1.0422e-06, 1.0463e-04, 9.9989e-01],\n",
      "        [3.5806e-06, 1.3908e-05, 2.3355e-03, 9.9765e-01],\n",
      "        [1.1458e-06, 1.1037e-05, 4.2448e-03, 9.9574e-01],\n",
      "        [2.8342e-07, 7.9642e-06, 6.1287e-04, 9.9938e-01],\n",
      "        [6.3191e-06, 6.9228e-05, 3.0577e-03, 9.9687e-01],\n",
      "        [1.0608e-06, 8.4065e-06, 3.4029e-04, 9.9965e-01],\n",
      "        [2.7305e-07, 1.6148e-05, 8.4193e-04, 9.9914e-01],\n",
      "        [1.0591e-07, 7.2648e-07, 8.0640e-05, 9.9992e-01],\n",
      "        [2.1785e-06, 2.3068e-05, 1.4518e-03, 9.9852e-01],\n",
      "        [4.0015e-07, 1.1506e-05, 3.5563e-04, 9.9963e-01],\n",
      "        [6.6621e-07, 2.5776e-06, 4.3068e-04, 9.9957e-01],\n",
      "        [1.3130e-07, 1.0274e-06, 6.9370e-05, 9.9993e-01],\n",
      "        [3.8573e-08, 1.6498e-06, 5.3452e-05, 9.9994e-01],\n",
      "        [2.4818e-06, 4.6822e-05, 1.2927e-03, 9.9866e-01],\n",
      "        [6.8151e-07, 9.2289e-06, 7.2875e-04, 9.9926e-01],\n",
      "        [2.3997e-06, 1.1354e-05, 6.8341e-04, 9.9930e-01],\n",
      "        [7.1811e-07, 1.6387e-05, 1.8917e-03, 9.9809e-01],\n",
      "        [7.1813e-07, 8.0228e-06, 2.8092e-04, 9.9971e-01],\n",
      "        [6.9455e-07, 3.9236e-06, 2.1935e-04, 9.9978e-01],\n",
      "        [4.8201e-07, 3.6894e-06, 3.1779e-04, 9.9968e-01],\n",
      "        [1.0606e-07, 2.1935e-06, 6.9481e-05, 9.9993e-01],\n",
      "        [2.6868e-07, 4.7920e-06, 6.6066e-04, 9.9933e-01],\n",
      "        [2.2194e-07, 3.1102e-06, 7.4116e-05, 9.9992e-01],\n",
      "        [1.5898e-06, 2.0220e-05, 1.4696e-03, 9.9851e-01],\n",
      "        [6.4255e-06, 3.6296e-05, 1.6188e-03, 9.9834e-01],\n",
      "        [2.0082e-07, 2.7830e-06, 2.4799e-04, 9.9975e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(95.9067) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[8.8754e-05, 9.9926e-01, 6.3136e-04, 1.6790e-05],\n",
      "        [1.6664e-02, 9.2210e-01, 6.1191e-02, 4.0887e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9982e-01, 1.5174e-04, 2.6991e-05, 2.8573e-06],\n",
      "        [9.9998e-01, 1.0116e-05, 5.0966e-06, 3.5866e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.9960e-03, 2.0067e-02, 9.7794e-01, 1.5127e-06],\n",
      "        [1.0486e-03, 4.7924e-02, 9.5101e-01, 1.2431e-05],\n",
      "        [3.1374e-04, 2.2705e-03, 9.9741e-01, 2.6030e-06],\n",
      "        [5.3736e-04, 2.0897e-03, 9.9737e-01, 1.6368e-06],\n",
      "        [6.8449e-04, 7.0457e-03, 9.9226e-01, 6.0276e-06],\n",
      "        [1.7386e-03, 5.4300e-03, 9.9283e-01, 5.5648e-06],\n",
      "        [2.5309e-04, 6.3836e-03, 9.9336e-01, 3.6683e-06],\n",
      "        [1.3328e-04, 3.3783e-03, 9.9649e-01, 1.3847e-06],\n",
      "        [1.9257e-04, 3.5635e-03, 9.9624e-01, 1.7235e-06],\n",
      "        [6.7069e-04, 8.0162e-03, 9.9131e-01, 3.7203e-06],\n",
      "        [5.2586e-04, 5.6269e-03, 9.9384e-01, 3.0224e-06],\n",
      "        [2.1627e-03, 1.0378e-02, 9.8746e-01, 3.7017e-06],\n",
      "        [7.8776e-04, 1.2942e-02, 9.8626e-01, 7.9553e-06],\n",
      "        [5.8567e-04, 6.6577e-03, 9.9275e-01, 2.4050e-06],\n",
      "        [2.9230e-04, 2.4655e-03, 9.9724e-01, 3.9504e-06],\n",
      "        [7.0641e-04, 8.7934e-03, 9.9050e-01, 2.4512e-06],\n",
      "        [7.3491e-04, 2.6867e-03, 9.9658e-01, 2.6200e-06],\n",
      "        [7.1015e-04, 4.6289e-03, 9.9466e-01, 3.3113e-06],\n",
      "        [1.1146e-03, 3.8394e-03, 9.9504e-01, 3.1413e-06],\n",
      "        [2.0220e-04, 2.7414e-03, 9.9706e-01, 1.2876e-06],\n",
      "        [7.4226e-04, 1.2187e-02, 9.8707e-01, 5.2579e-06],\n",
      "        [6.6505e-04, 7.9836e-03, 9.9135e-01, 2.2460e-06],\n",
      "        [3.8343e-04, 4.1049e-03, 9.9551e-01, 1.9848e-06],\n",
      "        [6.5059e-04, 9.5936e-03, 9.8975e-01, 2.0593e-06],\n",
      "        [4.1313e-04, 2.0789e-03, 9.9751e-01, 1.9685e-06],\n",
      "        [3.1603e-04, 5.9793e-03, 9.9370e-01, 1.6574e-06],\n",
      "        [3.2300e-04, 2.0989e-03, 9.9758e-01, 2.3753e-06],\n",
      "        [3.2009e-04, 3.2785e-03, 9.9640e-01, 2.6463e-06],\n",
      "        [6.5852e-04, 2.4464e-02, 9.7488e-01, 2.2357e-06],\n",
      "        [3.8560e-04, 3.2435e-03, 9.9637e-01, 2.9470e-06],\n",
      "        [9.1187e-04, 8.0631e-03, 9.9102e-01, 1.8738e-06],\n",
      "        [1.2091e-03, 6.3751e-03, 9.9241e-01, 3.4499e-06],\n",
      "        [8.6130e-04, 6.1318e-03, 9.9300e-01, 3.5554e-06],\n",
      "        [2.3930e-04, 2.4924e-03, 9.9727e-01, 3.1123e-06],\n",
      "        [2.3347e-03, 1.9167e-02, 9.7848e-01, 1.6457e-05],\n",
      "        [4.5406e-04, 2.6312e-03, 9.9691e-01, 1.2924e-06],\n",
      "        [1.1309e-03, 7.4316e-03, 9.9143e-01, 2.5859e-06],\n",
      "        [8.4066e-04, 8.2592e-03, 9.9090e-01, 1.7753e-06],\n",
      "        [8.2082e-04, 4.0369e-03, 9.9514e-01, 2.3923e-06],\n",
      "        [1.0048e-03, 3.0116e-02, 9.6887e-01, 4.2944e-06],\n",
      "        [4.6916e-04, 2.5986e-03, 9.9693e-01, 1.3733e-06],\n",
      "        [2.8377e-04, 3.7547e-03, 9.9596e-01, 2.5726e-06],\n",
      "        [2.3392e-04, 3.3087e-03, 9.9646e-01, 1.7475e-06],\n",
      "        [5.4175e-04, 1.7817e-02, 9.8163e-01, 7.5668e-06],\n",
      "        [4.7752e-04, 1.8535e-03, 9.9767e-01, 1.7615e-06],\n",
      "        [1.0405e-03, 5.4897e-03, 9.9347e-01, 2.0497e-06],\n",
      "        [8.1803e-04, 4.3966e-03, 9.9478e-01, 2.5658e-06],\n",
      "        [4.6105e-04, 3.2450e-03, 9.9629e-01, 4.3183e-06],\n",
      "        [3.7125e-04, 3.6155e-03, 9.9601e-01, 1.7423e-06],\n",
      "        [5.4261e-04, 5.1318e-03, 9.9432e-01, 3.4332e-06],\n",
      "        [7.2917e-04, 4.4914e-03, 9.9478e-01, 1.1259e-06],\n",
      "        [6.8710e-04, 1.7774e-03, 9.9753e-01, 1.6370e-06],\n",
      "        [6.3212e-04, 8.6512e-03, 9.9071e-01, 4.1751e-06],\n",
      "        [3.0766e-04, 2.5795e-03, 9.9711e-01, 3.5301e-06],\n",
      "        [3.4004e-04, 3.6432e-03, 9.9601e-01, 2.7757e-06],\n",
      "        [6.8605e-04, 4.8751e-03, 9.9444e-01, 2.2575e-06],\n",
      "        [4.7850e-04, 9.1983e-03, 9.9032e-01, 2.2281e-06],\n",
      "        [5.1835e-04, 2.6665e-03, 9.9681e-01, 1.6609e-06],\n",
      "        [5.0954e-04, 3.8012e-03, 9.9569e-01, 1.8464e-06],\n",
      "        [9.6095e-04, 9.0081e-03, 9.9003e-01, 5.3866e-06],\n",
      "        [1.0902e-04, 8.9995e-04, 9.9899e-01, 7.4634e-07],\n",
      "        [6.4974e-04, 3.8007e-03, 9.9555e-01, 1.8435e-06],\n",
      "        [4.4445e-04, 1.5052e-02, 9.8450e-01, 5.9733e-06],\n",
      "        [2.8156e-04, 2.4695e-03, 9.9725e-01, 1.6933e-06],\n",
      "        [1.7766e-03, 6.1309e-03, 9.9209e-01, 5.3998e-06],\n",
      "        [5.1205e-04, 3.4080e-03, 9.9607e-01, 7.3636e-06],\n",
      "        [3.6533e-03, 1.2226e-02, 9.8412e-01, 5.0240e-06],\n",
      "        [3.1949e-04, 8.9094e-03, 9.9077e-01, 5.7355e-06],\n",
      "        [6.5770e-04, 6.7422e-03, 9.9260e-01, 3.0519e-06],\n",
      "        [2.3970e-04, 3.5605e-03, 9.9620e-01, 3.7486e-06],\n",
      "        [2.2530e-03, 3.4372e-02, 9.6336e-01, 1.3678e-05],\n",
      "        [5.8108e-04, 3.9273e-03, 9.9549e-01, 5.1742e-06],\n",
      "        [4.2595e-04, 5.0382e-03, 9.9453e-01, 2.8953e-06],\n",
      "        [2.4893e-04, 3.1054e-03, 9.9664e-01, 2.2341e-06],\n",
      "        [5.9744e-04, 4.7658e-03, 9.9464e-01, 1.4805e-06],\n",
      "        [4.9925e-04, 4.2477e-03, 9.9525e-01, 4.1849e-06],\n",
      "        [2.1825e-04, 1.2848e-03, 9.9850e-01, 1.0946e-06],\n",
      "        [8.1830e-04, 3.6320e-03, 9.9555e-01, 3.5707e-06],\n",
      "        [1.0655e-03, 4.9175e-03, 9.9401e-01, 2.5898e-06],\n",
      "        [4.4217e-04, 2.2990e-03, 9.9726e-01, 1.6015e-06],\n",
      "        [1.1521e-03, 4.2709e-03, 9.9457e-01, 2.4913e-06],\n",
      "        [1.2088e-03, 3.6342e-03, 9.9515e-01, 2.5299e-06],\n",
      "        [2.1190e-04, 1.9136e-03, 9.9787e-01, 1.2253e-06],\n",
      "        [1.5080e-04, 3.8482e-03, 9.9600e-01, 1.6655e-06],\n",
      "        [3.8900e-04, 3.5100e-03, 9.9610e-01, 1.9506e-06],\n",
      "        [7.0381e-04, 6.1409e-03, 9.9315e-01, 5.4123e-06],\n",
      "        [6.6153e-04, 4.0502e-03, 9.9529e-01, 2.7905e-06],\n",
      "        [6.5546e-04, 7.0159e-03, 9.9233e-01, 1.6986e-06],\n",
      "        [2.3986e-04, 7.2289e-03, 9.9253e-01, 2.1207e-06],\n",
      "        [7.4064e-03, 1.6961e-02, 9.7563e-01, 6.9126e-06],\n",
      "        [5.3599e-04, 5.3333e-03, 9.9413e-01, 4.2868e-06],\n",
      "        [1.5378e-03, 4.6252e-03, 9.9383e-01, 2.1143e-06],\n",
      "        [7.2054e-04, 7.6164e-03, 9.9166e-01, 2.5112e-06],\n",
      "        [3.1642e-04, 4.5371e-03, 9.9514e-01, 3.0299e-06],\n",
      "        [4.6537e-04, 5.4518e-03, 9.9408e-01, 3.5047e-06],\n",
      "        [3.0831e-03, 2.2390e-02, 9.7452e-01, 7.8902e-06],\n",
      "        [4.6897e-04, 5.5678e-03, 9.9396e-01, 4.6230e-06],\n",
      "        [5.3194e-04, 2.5482e-03, 9.9692e-01, 1.2341e-06],\n",
      "        [2.9910e-04, 5.5071e-03, 9.9419e-01, 2.7153e-06],\n",
      "        [1.0459e-03, 1.4414e-02, 9.8454e-01, 4.7497e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[3.4381e-07, 3.6502e-06, 2.6019e-04, 9.9974e-01],\n",
      "        [1.9026e-07, 2.4498e-06, 1.2261e-04, 9.9987e-01],\n",
      "        [1.3086e-07, 2.0505e-06, 1.4855e-04, 9.9985e-01],\n",
      "        [6.1547e-07, 3.1773e-06, 3.2423e-04, 9.9967e-01],\n",
      "        [1.2550e-07, 7.3626e-07, 6.5887e-05, 9.9993e-01],\n",
      "        [1.7007e-07, 2.0378e-06, 1.1096e-04, 9.9989e-01],\n",
      "        [1.0813e-07, 1.1959e-06, 1.3509e-04, 9.9986e-01],\n",
      "        [1.8319e-07, 4.3631e-07, 1.8447e-05, 9.9998e-01],\n",
      "        [6.9234e-07, 7.4165e-06, 8.1010e-04, 9.9918e-01],\n",
      "        [2.3062e-07, 5.0035e-06, 2.7386e-04, 9.9972e-01],\n",
      "        [6.8499e-07, 2.9997e-06, 8.3293e-04, 9.9916e-01],\n",
      "        [7.4204e-07, 1.7546e-06, 1.5513e-04, 9.9984e-01],\n",
      "        [1.7821e-07, 2.2613e-06, 2.2489e-04, 9.9977e-01],\n",
      "        [1.1157e-06, 1.3814e-05, 3.2260e-04, 9.9966e-01],\n",
      "        [1.2356e-07, 7.1956e-07, 2.1556e-05, 9.9998e-01],\n",
      "        [6.9678e-07, 9.0792e-06, 5.4550e-04, 9.9944e-01],\n",
      "        [1.1248e-07, 1.4346e-06, 4.4622e-05, 9.9995e-01],\n",
      "        [5.0310e-07, 8.4869e-06, 4.2677e-04, 9.9956e-01],\n",
      "        [3.7196e-07, 1.2017e-06, 7.1938e-05, 9.9993e-01],\n",
      "        [1.0695e-06, 1.6194e-05, 2.2896e-03, 9.9769e-01],\n",
      "        [2.3738e-08, 4.7710e-07, 7.6979e-06, 9.9999e-01],\n",
      "        [4.8729e-07, 6.3348e-06, 3.8670e-04, 9.9961e-01],\n",
      "        [3.9700e-07, 3.2539e-06, 4.7380e-04, 9.9952e-01],\n",
      "        [1.4006e-06, 8.2382e-06, 4.7333e-04, 9.9952e-01],\n",
      "        [1.5780e-07, 1.2290e-06, 1.0006e-04, 9.9990e-01],\n",
      "        [4.5153e-08, 2.3570e-07, 6.6736e-06, 9.9999e-01],\n",
      "        [2.3349e-07, 1.7587e-06, 8.1633e-05, 9.9992e-01],\n",
      "        [6.8754e-07, 6.4085e-06, 3.2129e-04, 9.9967e-01],\n",
      "        [1.1903e-07, 4.9077e-06, 2.3515e-04, 9.9976e-01],\n",
      "        [8.1069e-08, 1.6004e-06, 8.9946e-05, 9.9991e-01],\n",
      "        [3.6799e-07, 2.2368e-06, 1.9378e-04, 9.9980e-01],\n",
      "        [9.8471e-07, 5.5805e-06, 1.2166e-03, 9.9878e-01],\n",
      "        [1.4870e-06, 2.7101e-06, 9.9841e-04, 9.9900e-01],\n",
      "        [8.6148e-08, 1.3814e-06, 4.8687e-05, 9.9995e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(95.9440) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[6.4538e-05, 9.8852e-01, 1.1363e-02, 5.1498e-05],\n",
      "        [2.3053e-05, 9.9758e-01, 2.3484e-03, 4.7679e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9283e-01, 4.1740e-03, 2.8997e-03, 9.2759e-05],\n",
      "        [9.9784e-01, 6.3445e-04, 1.4956e-03, 2.8303e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[5.4524e-05, 2.0499e-03, 9.9788e-01, 1.2580e-05],\n",
      "        [6.1470e-05, 3.6017e-03, 9.9632e-01, 1.6899e-05],\n",
      "        [9.3371e-05, 5.3131e-03, 9.9458e-01, 1.3508e-05],\n",
      "        [3.6928e-05, 3.1683e-03, 9.9678e-01, 1.3124e-05],\n",
      "        [8.8590e-05, 4.0654e-03, 9.9583e-01, 1.7334e-05],\n",
      "        [6.0706e-05, 3.3451e-03, 9.9657e-01, 2.1481e-05],\n",
      "        [5.1308e-05, 2.2273e-03, 9.9771e-01, 8.2739e-06],\n",
      "        [1.0209e-04, 5.0046e-03, 9.9487e-01, 2.2230e-05],\n",
      "        [2.7516e-04, 1.0327e-02, 9.8938e-01, 1.3409e-05],\n",
      "        [5.7953e-05, 3.1594e-03, 9.9677e-01, 1.4317e-05],\n",
      "        [6.7466e-05, 3.2586e-03, 9.9666e-01, 1.6793e-05],\n",
      "        [4.4206e-05, 3.0623e-03, 9.9689e-01, 8.2214e-06],\n",
      "        [1.3373e-04, 5.0137e-03, 9.9484e-01, 1.7318e-05],\n",
      "        [3.8103e-05, 2.0262e-03, 9.9793e-01, 5.3805e-06],\n",
      "        [1.5140e-04, 4.3762e-03, 9.9546e-01, 1.7256e-05],\n",
      "        [1.3043e-05, 8.5648e-04, 9.9912e-01, 6.3329e-06],\n",
      "        [9.9629e-05, 1.6558e-03, 9.9824e-01, 4.9693e-06],\n",
      "        [4.4442e-05, 1.8789e-03, 9.9807e-01, 5.7479e-06],\n",
      "        [4.1110e-05, 3.5361e-03, 9.9641e-01, 8.0137e-06],\n",
      "        [2.3392e-05, 8.1664e-04, 9.9915e-01, 6.4177e-06],\n",
      "        [4.5596e-05, 3.3922e-03, 9.9655e-01, 1.2977e-05],\n",
      "        [1.0538e-04, 3.4212e-03, 9.9646e-01, 1.1957e-05],\n",
      "        [1.2808e-04, 2.1271e-03, 9.9774e-01, 8.2699e-06],\n",
      "        [6.5961e-05, 3.1831e-03, 9.9674e-01, 1.1136e-05],\n",
      "        [4.9239e-05, 1.8770e-03, 9.9807e-01, 3.5469e-06],\n",
      "        [4.9125e-05, 2.7189e-03, 9.9722e-01, 9.9281e-06],\n",
      "        [6.5464e-05, 5.7219e-03, 9.9419e-01, 1.8575e-05],\n",
      "        [6.0672e-05, 2.4316e-03, 9.9750e-01, 4.2727e-06],\n",
      "        [9.2984e-05, 2.1414e-03, 9.9775e-01, 1.2030e-05],\n",
      "        [1.0844e-04, 5.8080e-03, 9.9407e-01, 1.6841e-05],\n",
      "        [3.2047e-05, 1.6462e-03, 9.9831e-01, 1.0387e-05],\n",
      "        [6.3443e-05, 1.0009e-03, 9.9893e-01, 9.2892e-06],\n",
      "        [6.6301e-05, 2.5096e-03, 9.9742e-01, 7.0433e-06],\n",
      "        [6.8556e-05, 2.4042e-03, 9.9751e-01, 2.1416e-05],\n",
      "        [1.0881e-04, 9.3870e-03, 9.9049e-01, 1.2569e-05],\n",
      "        [6.0845e-05, 2.1570e-03, 9.9778e-01, 4.4677e-06],\n",
      "        [8.6150e-05, 2.7171e-03, 9.9719e-01, 5.5756e-06],\n",
      "        [1.0373e-04, 2.3207e-03, 9.9757e-01, 6.2810e-06],\n",
      "        [6.4698e-05, 3.4229e-03, 9.9651e-01, 5.4561e-06],\n",
      "        [1.2219e-04, 3.8038e-03, 9.9606e-01, 1.8439e-05],\n",
      "        [9.9100e-05, 2.9874e-03, 9.9689e-01, 2.2533e-05],\n",
      "        [5.4575e-05, 2.2312e-03, 9.9771e-01, 5.7319e-06],\n",
      "        [1.2578e-04, 2.8439e-03, 9.9702e-01, 7.5847e-06],\n",
      "        [5.4418e-05, 1.8626e-03, 9.9808e-01, 7.2655e-06],\n",
      "        [7.6118e-05, 3.1303e-03, 9.9678e-01, 9.2753e-06],\n",
      "        [5.8928e-05, 1.6009e-03, 9.9832e-01, 2.0743e-05],\n",
      "        [5.3002e-05, 1.7463e-03, 9.9820e-01, 5.2753e-06],\n",
      "        [6.4786e-05, 4.4309e-03, 9.9549e-01, 1.1743e-05],\n",
      "        [5.9329e-05, 2.9212e-03, 9.9701e-01, 9.5569e-06],\n",
      "        [8.4792e-05, 4.6938e-03, 9.9521e-01, 1.1331e-05],\n",
      "        [1.1302e-04, 6.0844e-03, 9.9379e-01, 8.5293e-06],\n",
      "        [1.7273e-04, 4.2481e-03, 9.9555e-01, 3.4092e-05],\n",
      "        [3.0948e-05, 5.5034e-03, 9.9444e-01, 2.8483e-05],\n",
      "        [4.2915e-05, 2.8565e-03, 9.9709e-01, 1.0061e-05],\n",
      "        [1.1703e-04, 4.6485e-03, 9.9521e-01, 1.9786e-05],\n",
      "        [5.7856e-05, 2.0128e-03, 9.9792e-01, 7.6731e-06],\n",
      "        [7.7372e-05, 3.1915e-03, 9.9672e-01, 1.5081e-05],\n",
      "        [2.2519e-05, 2.2813e-03, 9.9769e-01, 8.5202e-06],\n",
      "        [7.3738e-05, 3.9797e-03, 9.9591e-01, 3.3674e-05],\n",
      "        [4.5656e-05, 4.2511e-04, 9.9952e-01, 1.1131e-05],\n",
      "        [9.6424e-05, 2.8780e-03, 9.9702e-01, 9.0411e-06],\n",
      "        [9.3034e-05, 1.0487e-03, 9.9885e-01, 7.6299e-06],\n",
      "        [4.6091e-05, 1.2373e-03, 9.9871e-01, 2.6829e-06],\n",
      "        [8.6748e-05, 5.3193e-03, 9.9458e-01, 1.7950e-05],\n",
      "        [4.6467e-05, 1.1956e-03, 9.9875e-01, 2.9608e-06],\n",
      "        [1.6939e-04, 4.2797e-03, 9.9552e-01, 3.3477e-05],\n",
      "        [1.1417e-04, 1.1825e-03, 9.9869e-01, 9.6398e-06],\n",
      "        [8.8798e-05, 2.0839e-03, 9.9782e-01, 5.3798e-06],\n",
      "        [2.9082e-05, 1.6313e-03, 9.9834e-01, 3.8464e-06],\n",
      "        [5.9464e-05, 3.0505e-03, 9.9688e-01, 6.6785e-06],\n",
      "        [1.0995e-04, 2.4176e-03, 9.9746e-01, 1.4049e-05],\n",
      "        [1.0696e-04, 1.2939e-03, 9.9859e-01, 1.2615e-05],\n",
      "        [4.0829e-05, 1.3646e-03, 9.9859e-01, 2.6410e-06],\n",
      "        [1.5298e-04, 3.7665e-03, 9.9604e-01, 4.0716e-05],\n",
      "        [4.7476e-05, 1.2606e-03, 9.9868e-01, 7.9113e-06],\n",
      "        [2.3311e-04, 8.9677e-03, 9.9075e-01, 5.3492e-05],\n",
      "        [5.1534e-05, 4.0965e-03, 9.9585e-01, 6.4532e-06],\n",
      "        [5.1653e-05, 3.2350e-03, 9.9670e-01, 1.5307e-05],\n",
      "        [2.8898e-05, 1.0372e-03, 9.9893e-01, 5.3069e-06],\n",
      "        [4.3001e-05, 4.8168e-03, 9.9512e-01, 1.9590e-05],\n",
      "        [4.5287e-05, 2.2251e-03, 9.9772e-01, 7.7460e-06],\n",
      "        [4.3234e-05, 2.1931e-03, 9.9775e-01, 1.0437e-05],\n",
      "        [3.1630e-05, 1.1699e-03, 9.9879e-01, 5.7765e-06],\n",
      "        [1.1035e-04, 3.3362e-03, 9.9654e-01, 9.6412e-06],\n",
      "        [2.1240e-04, 1.1441e-02, 9.8832e-01, 2.9838e-05],\n",
      "        [7.7782e-05, 2.9863e-03, 9.9693e-01, 4.8398e-06],\n",
      "        [6.1021e-05, 1.7986e-03, 9.9813e-01, 8.4784e-06],\n",
      "        [8.5373e-05, 2.0572e-03, 9.9785e-01, 4.8461e-06],\n",
      "        [1.0696e-04, 8.8597e-03, 9.9101e-01, 1.8626e-05],\n",
      "        [3.4529e-05, 2.3134e-03, 9.9764e-01, 7.8323e-06],\n",
      "        [4.6479e-05, 1.6162e-03, 9.9833e-01, 9.8807e-06],\n",
      "        [8.1238e-05, 1.9879e-03, 9.9792e-01, 8.9631e-06],\n",
      "        [8.9218e-05, 6.3675e-03, 9.9353e-01, 1.6712e-05],\n",
      "        [4.5018e-05, 2.6451e-03, 9.9729e-01, 1.6108e-05],\n",
      "        [1.0210e-04, 3.5351e-03, 9.9635e-01, 1.5105e-05],\n",
      "        [1.1743e-04, 6.5961e-03, 9.9327e-01, 1.9509e-05],\n",
      "        [2.0371e-04, 7.4204e-03, 9.9233e-01, 4.1404e-05],\n",
      "        [2.4844e-04, 3.1846e-03, 9.9655e-01, 1.8367e-05],\n",
      "        [5.9624e-05, 2.9030e-03, 9.9703e-01, 9.0486e-06],\n",
      "        [6.2843e-05, 4.5050e-03, 9.9542e-01, 1.2209e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.3356e-08, 1.4994e-06, 7.0114e-05, 9.9993e-01],\n",
      "        [3.1602e-08, 5.4097e-07, 1.8661e-05, 9.9998e-01],\n",
      "        [2.5761e-07, 6.2833e-06, 2.2636e-04, 9.9977e-01],\n",
      "        [1.2092e-07, 8.9166e-07, 1.0370e-04, 9.9990e-01],\n",
      "        [3.5428e-07, 2.7575e-06, 1.8892e-04, 9.9981e-01],\n",
      "        [8.7935e-08, 1.8952e-06, 1.0490e-04, 9.9989e-01],\n",
      "        [1.6896e-08, 3.7322e-07, 7.2092e-06, 9.9999e-01],\n",
      "        [7.7221e-08, 4.2203e-06, 7.8370e-05, 9.9992e-01],\n",
      "        [7.8298e-08, 6.7947e-06, 3.9466e-04, 9.9960e-01],\n",
      "        [1.0019e-06, 2.9010e-06, 1.9252e-04, 9.9980e-01],\n",
      "        [1.6296e-08, 1.9574e-07, 1.2129e-05, 9.9999e-01],\n",
      "        [4.3693e-08, 1.0743e-06, 7.8005e-05, 9.9992e-01],\n",
      "        [4.8011e-08, 1.9824e-06, 1.1679e-04, 9.9988e-01],\n",
      "        [3.3073e-07, 7.1768e-06, 2.9775e-04, 9.9969e-01],\n",
      "        [4.9098e-08, 1.7508e-06, 3.9261e-05, 9.9996e-01],\n",
      "        [6.1907e-08, 4.1203e-07, 2.1951e-05, 9.9998e-01],\n",
      "        [1.9474e-08, 3.7450e-07, 1.9175e-05, 9.9998e-01],\n",
      "        [1.7093e-07, 3.0410e-06, 8.1409e-05, 9.9992e-01],\n",
      "        [4.3555e-08, 9.3064e-07, 6.0789e-05, 9.9994e-01],\n",
      "        [2.0178e-07, 1.8762e-06, 1.1355e-04, 9.9988e-01],\n",
      "        [1.1761e-07, 1.4479e-06, 1.5988e-05, 9.9998e-01],\n",
      "        [2.1925e-08, 4.7786e-07, 1.4151e-05, 9.9999e-01],\n",
      "        [9.4863e-08, 1.3201e-06, 1.8559e-05, 9.9998e-01],\n",
      "        [4.7793e-08, 1.2661e-06, 6.4055e-05, 9.9993e-01],\n",
      "        [1.7016e-07, 6.3517e-06, 7.4285e-04, 9.9925e-01],\n",
      "        [1.0134e-07, 5.4333e-06, 4.7112e-04, 9.9952e-01],\n",
      "        [4.3750e-08, 3.0071e-07, 2.8199e-05, 9.9997e-01],\n",
      "        [2.9892e-08, 8.5746e-07, 1.5390e-05, 9.9998e-01],\n",
      "        [4.2764e-08, 3.1418e-06, 1.7062e-04, 9.9983e-01],\n",
      "        [5.3056e-08, 2.7024e-07, 9.4498e-06, 9.9999e-01],\n",
      "        [6.9606e-08, 7.8830e-07, 1.0181e-04, 9.9990e-01],\n",
      "        [3.0287e-07, 5.6495e-06, 5.2573e-04, 9.9947e-01],\n",
      "        [8.1442e-08, 3.9741e-06, 9.7440e-05, 9.9990e-01],\n",
      "        [1.0433e-07, 7.6100e-06, 2.2306e-04, 9.9977e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(96.0370) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.7255e-05, 9.9985e-01, 1.2292e-04, 8.7108e-06],\n",
      "        [2.6791e-05, 9.9982e-01, 1.3474e-04, 1.4509e-05],\n",
      "        [6.2786e-06, 9.9989e-01, 9.8377e-05, 5.6315e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9693e-01, 2.8804e-03, 1.6760e-04, 1.9360e-05],\n",
      "        [9.9998e-01, 9.7069e-06, 6.0002e-06, 8.5913e-07],\n",
      "        [9.9985e-01, 1.1477e-04, 3.5163e-05, 2.4407e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.4890e-04, 3.1085e-02, 9.6864e-01, 2.7091e-05],\n",
      "        [4.6396e-04, 6.7390e-02, 9.3209e-01, 5.3129e-05],\n",
      "        [6.2900e-04, 1.0598e-01, 8.9336e-01, 3.4448e-05],\n",
      "        [1.5077e-03, 5.0288e-02, 9.4817e-01, 3.7251e-05],\n",
      "        [6.6407e-04, 4.4876e-02, 9.5441e-01, 4.6185e-05],\n",
      "        [4.2804e-04, 5.3241e-02, 9.4628e-01, 4.9259e-05],\n",
      "        [7.8068e-04, 1.0518e-01, 8.9394e-01, 9.3995e-05],\n",
      "        [8.2511e-04, 5.5545e-02, 9.4360e-01, 3.4110e-05],\n",
      "        [3.6573e-04, 4.6737e-02, 9.5278e-01, 1.1651e-04],\n",
      "        [4.3353e-04, 6.1362e-02, 9.3818e-01, 2.2171e-05],\n",
      "        [6.0461e-04, 4.3028e-02, 9.5632e-01, 4.5513e-05],\n",
      "        [3.5991e-04, 2.6906e-02, 9.7271e-01, 2.5724e-05],\n",
      "        [4.6192e-04, 7.5636e-02, 9.2384e-01, 5.9850e-05],\n",
      "        [5.3724e-04, 5.1378e-02, 9.4804e-01, 4.4213e-05],\n",
      "        [2.8342e-04, 3.7350e-02, 9.6233e-01, 4.1415e-05],\n",
      "        [3.8941e-04, 5.0793e-02, 9.4881e-01, 1.1935e-05],\n",
      "        [1.4538e-03, 2.3274e-01, 7.6571e-01, 9.7251e-05],\n",
      "        [2.2364e-04, 7.7858e-02, 9.2189e-01, 2.5984e-05],\n",
      "        [3.1252e-04, 7.5055e-02, 9.2461e-01, 2.3951e-05],\n",
      "        [3.0032e-04, 3.2442e-02, 9.6720e-01, 5.6391e-05],\n",
      "        [1.4131e-03, 9.8190e-02, 9.0031e-01, 9.1148e-05],\n",
      "        [2.6911e-03, 8.7268e-02, 9.1001e-01, 2.9720e-05],\n",
      "        [6.4110e-04, 4.3825e-02, 9.5551e-01, 2.6545e-05],\n",
      "        [3.1213e-04, 3.5627e-02, 9.6403e-01, 2.7336e-05],\n",
      "        [4.2451e-04, 3.7847e-02, 9.6169e-01, 4.2258e-05],\n",
      "        [5.1947e-04, 2.7284e-02, 9.7215e-01, 4.4484e-05],\n",
      "        [1.2106e-03, 1.2961e-01, 8.6893e-01, 2.5154e-04],\n",
      "        [1.0900e-03, 1.4877e-01, 8.5008e-01, 6.4861e-05],\n",
      "        [4.5187e-04, 2.6393e-02, 9.7314e-01, 1.5554e-05],\n",
      "        [5.3219e-04, 1.2404e-01, 8.7540e-01, 2.5619e-05],\n",
      "        [4.1962e-04, 8.6141e-02, 9.1337e-01, 6.4875e-05],\n",
      "        [9.1141e-04, 9.0932e-02, 9.0811e-01, 4.6630e-05],\n",
      "        [1.4319e-03, 1.3099e-01, 8.6756e-01, 2.5894e-05],\n",
      "        [8.5565e-04, 6.3836e-02, 9.3527e-01, 4.0766e-05],\n",
      "        [6.5983e-04, 6.3274e-02, 9.3598e-01, 8.9657e-05],\n",
      "        [3.3834e-04, 3.1833e-02, 9.6779e-01, 3.9929e-05],\n",
      "        [1.6506e-03, 2.1059e-01, 7.8766e-01, 9.5406e-05],\n",
      "        [3.0889e-04, 1.4335e-01, 8.5629e-01, 5.2951e-05],\n",
      "        [3.8268e-04, 5.2601e-02, 9.4699e-01, 2.7638e-05],\n",
      "        [4.5642e-04, 1.0960e-01, 8.8987e-01, 7.3997e-05],\n",
      "        [6.6649e-04, 6.6810e-02, 9.3248e-01, 4.3673e-05],\n",
      "        [5.6692e-04, 4.4430e-02, 9.5499e-01, 1.7028e-05],\n",
      "        [9.8257e-04, 4.6154e-02, 9.5285e-01, 1.1742e-05],\n",
      "        [1.3699e-03, 7.2210e-02, 9.2634e-01, 7.6173e-05],\n",
      "        [6.4813e-04, 4.9590e-02, 9.4972e-01, 4.2947e-05],\n",
      "        [4.8194e-04, 3.4606e-02, 9.6489e-01, 1.9412e-05],\n",
      "        [1.4488e-03, 9.0827e-02, 9.0768e-01, 4.8136e-05],\n",
      "        [9.2624e-04, 1.0427e-01, 8.9478e-01, 2.5503e-05],\n",
      "        [5.7038e-05, 9.6889e-03, 9.9024e-01, 1.0937e-05],\n",
      "        [4.5440e-04, 6.0660e-02, 9.3884e-01, 4.1583e-05],\n",
      "        [2.8274e-04, 5.7764e-02, 9.4193e-01, 2.4639e-05],\n",
      "        [2.0481e-04, 2.5071e-02, 9.7468e-01, 3.9723e-05],\n",
      "        [2.6029e-04, 2.7526e-02, 9.7219e-01, 2.3194e-05],\n",
      "        [2.4154e-04, 1.4515e-02, 9.8523e-01, 1.4221e-05],\n",
      "        [9.4755e-04, 7.1583e-02, 9.2743e-01, 3.6420e-05],\n",
      "        [5.4392e-04, 1.3771e-02, 9.8566e-01, 2.5612e-05],\n",
      "        [3.9296e-04, 2.9366e-02, 9.7021e-01, 3.2969e-05],\n",
      "        [1.6146e-04, 1.5652e-02, 9.8416e-01, 2.9272e-05],\n",
      "        [1.0363e-03, 5.3841e-02, 9.4510e-01, 2.5445e-05],\n",
      "        [1.6826e-03, 5.6784e-02, 9.4147e-01, 6.3620e-05],\n",
      "        [2.3284e-03, 1.3663e-01, 8.6099e-01, 5.5067e-05],\n",
      "        [5.0628e-04, 3.9665e-02, 9.5978e-01, 4.6859e-05],\n",
      "        [2.9780e-04, 2.7114e-02, 9.7257e-01, 2.2818e-05],\n",
      "        [5.8645e-04, 3.5644e-02, 9.6374e-01, 2.4597e-05],\n",
      "        [8.8359e-04, 7.1930e-02, 9.2717e-01, 1.7749e-05],\n",
      "        [9.9851e-04, 2.4831e-01, 7.5062e-01, 7.1646e-05],\n",
      "        [2.6685e-04, 5.8565e-02, 9.4115e-01, 1.6975e-05],\n",
      "        [6.6897e-04, 4.2431e-02, 9.5687e-01, 3.3697e-05],\n",
      "        [2.8670e-04, 3.0424e-02, 9.6926e-01, 2.7878e-05],\n",
      "        [3.1046e-04, 4.5203e-02, 9.5445e-01, 4.0791e-05],\n",
      "        [1.0774e-03, 8.3941e-02, 9.1492e-01, 6.2715e-05],\n",
      "        [2.7616e-04, 3.9815e-02, 9.5988e-01, 2.5247e-05],\n",
      "        [2.8855e-04, 4.6573e-02, 9.5309e-01, 4.4953e-05],\n",
      "        [1.0701e-03, 6.3070e-02, 9.3582e-01, 3.6939e-05],\n",
      "        [1.1449e-03, 2.0159e-01, 7.9722e-01, 4.6284e-05],\n",
      "        [4.3342e-04, 4.1705e-02, 9.5785e-01, 1.3009e-05],\n",
      "        [4.6865e-04, 6.3788e-02, 9.3570e-01, 4.6874e-05],\n",
      "        [5.9259e-04, 1.2777e-01, 8.7161e-01, 2.1313e-05],\n",
      "        [1.0465e-03, 5.2809e-02, 9.4611e-01, 3.8367e-05],\n",
      "        [1.1796e-03, 7.0402e-02, 9.2837e-01, 5.2903e-05],\n",
      "        [4.1575e-04, 5.9096e-02, 9.4046e-01, 3.0703e-05],\n",
      "        [1.6206e-04, 2.7693e-02, 9.7212e-01, 2.2859e-05],\n",
      "        [4.6551e-04, 3.7580e-02, 9.6192e-01, 3.2745e-05],\n",
      "        [1.0365e-03, 1.1490e-01, 8.8401e-01, 4.9200e-05],\n",
      "        [3.6545e-04, 4.1050e-02, 9.5857e-01, 1.8812e-05],\n",
      "        [1.3133e-04, 5.4535e-02, 9.4529e-01, 4.5652e-05],\n",
      "        [4.8129e-04, 4.6499e-02, 9.5298e-01, 4.3448e-05],\n",
      "        [5.2589e-04, 3.3869e-02, 9.6558e-01, 2.3611e-05],\n",
      "        [3.5831e-04, 1.8228e-02, 9.8140e-01, 1.5805e-05],\n",
      "        [5.6362e-04, 6.8492e-02, 9.3092e-01, 2.1949e-05],\n",
      "        [1.1198e-03, 2.4008e-02, 9.7481e-01, 6.6243e-05],\n",
      "        [4.4741e-04, 3.1065e-02, 9.6840e-01, 8.6422e-05],\n",
      "        [3.5540e-04, 5.4071e-02, 9.4555e-01, 2.3403e-05],\n",
      "        [2.5089e-04, 7.4174e-02, 9.2555e-01, 2.7886e-05],\n",
      "        [1.0077e-03, 9.8011e-02, 9.0093e-01, 4.7072e-05],\n",
      "        [7.9705e-04, 4.0756e-02, 9.5843e-01, 1.6813e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.5946e-07, 7.9770e-06, 3.5384e-05, 9.9996e-01],\n",
      "        [4.7424e-08, 1.6505e-06, 1.1468e-05, 9.9999e-01],\n",
      "        [4.0904e-08, 1.0111e-06, 1.0661e-05, 9.9999e-01],\n",
      "        [2.4452e-08, 8.2147e-07, 5.8782e-06, 9.9999e-01],\n",
      "        [1.7883e-07, 2.8079e-06, 1.7013e-05, 9.9998e-01],\n",
      "        [8.2549e-09, 3.2713e-07, 3.1510e-06, 1.0000e+00],\n",
      "        [3.9320e-08, 1.2058e-06, 1.0424e-05, 9.9999e-01],\n",
      "        [1.4734e-08, 2.9055e-07, 3.7510e-06, 1.0000e+00],\n",
      "        [1.6802e-08, 1.2405e-06, 1.2696e-05, 9.9999e-01],\n",
      "        [3.4191e-08, 6.1190e-07, 1.4952e-05, 9.9998e-01],\n",
      "        [8.8794e-08, 6.8825e-07, 2.4000e-05, 9.9998e-01],\n",
      "        [4.0937e-08, 8.0616e-07, 3.4848e-06, 1.0000e+00],\n",
      "        [4.6729e-08, 1.6300e-06, 1.1265e-05, 9.9999e-01],\n",
      "        [8.0780e-09, 3.6673e-07, 5.6067e-06, 9.9999e-01],\n",
      "        [1.8963e-08, 2.1684e-07, 6.4281e-06, 9.9999e-01],\n",
      "        [1.6180e-08, 3.8948e-07, 3.1797e-06, 1.0000e+00],\n",
      "        [1.4528e-07, 4.6737e-06, 3.4891e-05, 9.9996e-01],\n",
      "        [5.9406e-08, 2.0647e-06, 1.7174e-05, 9.9998e-01],\n",
      "        [3.0562e-08, 4.6599e-07, 3.7943e-06, 1.0000e+00],\n",
      "        [5.6178e-08, 2.4093e-06, 9.3860e-06, 9.9999e-01],\n",
      "        [1.0312e-07, 7.1102e-06, 3.3366e-05, 9.9996e-01],\n",
      "        [3.9056e-08, 7.2173e-07, 3.8456e-06, 1.0000e+00],\n",
      "        [3.4050e-08, 8.1961e-07, 9.2174e-06, 9.9999e-01],\n",
      "        [7.7565e-09, 1.3679e-07, 4.4894e-06, 1.0000e+00],\n",
      "        [3.9332e-08, 1.4116e-06, 5.3043e-06, 9.9999e-01],\n",
      "        [3.6942e-08, 1.4124e-06, 2.9951e-05, 9.9997e-01],\n",
      "        [3.1625e-08, 9.9814e-07, 2.7158e-05, 9.9997e-01],\n",
      "        [2.5514e-08, 5.3932e-07, 1.3787e-05, 9.9999e-01],\n",
      "        [1.8767e-07, 4.2003e-06, 2.9865e-05, 9.9997e-01],\n",
      "        [1.5022e-08, 1.4645e-06, 5.5338e-06, 9.9999e-01],\n",
      "        [1.3029e-08, 4.0697e-07, 4.3256e-06, 1.0000e+00],\n",
      "        [2.8385e-08, 9.2698e-07, 8.5659e-06, 9.9999e-01],\n",
      "        [1.2939e-08, 1.0386e-06, 8.3141e-06, 9.9999e-01],\n",
      "        [7.4125e-08, 7.7339e-07, 9.5760e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(95.9365) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[2.1230e-05, 9.9946e-01, 4.9798e-04, 2.4694e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9945e-01, 2.2030e-04, 3.1502e-04, 1.2041e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[4.1817e-05, 9.4396e-04, 9.9901e-01, 4.0407e-06],\n",
      "        [9.0291e-05, 1.7644e-03, 9.9814e-01, 7.0391e-06],\n",
      "        [7.2960e-05, 6.6672e-04, 9.9925e-01, 8.3302e-06],\n",
      "        [2.2490e-05, 5.8183e-04, 9.9939e-01, 4.4881e-06],\n",
      "        [1.6668e-04, 2.4513e-03, 9.9736e-01, 1.8237e-05],\n",
      "        [1.0221e-03, 1.1869e-02, 9.8706e-01, 5.0106e-05],\n",
      "        [6.2861e-05, 5.5386e-04, 9.9938e-01, 7.0760e-06],\n",
      "        [4.4427e-05, 1.2533e-03, 9.9870e-01, 2.7996e-06],\n",
      "        [1.0767e-04, 9.5783e-04, 9.9893e-01, 9.3561e-06],\n",
      "        [7.9823e-05, 6.9873e-04, 9.9922e-01, 4.1478e-06],\n",
      "        [5.2405e-05, 3.2021e-04, 9.9962e-01, 2.7588e-06],\n",
      "        [4.3437e-05, 3.1259e-03, 9.9682e-01, 1.1478e-05],\n",
      "        [8.9369e-05, 8.5655e-04, 9.9905e-01, 7.0031e-06],\n",
      "        [1.8521e-04, 1.4378e-03, 9.9836e-01, 1.7566e-05],\n",
      "        [2.2496e-04, 9.3351e-04, 9.9883e-01, 6.9624e-06],\n",
      "        [2.2961e-04, 6.8051e-03, 9.9295e-01, 1.0832e-05],\n",
      "        [2.4398e-04, 2.1978e-03, 9.9752e-01, 4.1610e-05],\n",
      "        [1.7612e-04, 6.3482e-04, 9.9918e-01, 4.9122e-06],\n",
      "        [2.0896e-04, 1.6858e-03, 9.9810e-01, 8.1067e-06],\n",
      "        [9.3282e-05, 1.4541e-03, 9.9845e-01, 3.8554e-06],\n",
      "        [9.2834e-05, 1.0295e-03, 9.9887e-01, 9.4765e-06],\n",
      "        [5.9870e-05, 4.4317e-04, 9.9949e-01, 5.5545e-06],\n",
      "        [1.3200e-04, 1.2291e-03, 9.9863e-01, 9.6327e-06],\n",
      "        [7.2980e-05, 5.6660e-04, 9.9935e-01, 7.7802e-06],\n",
      "        [6.8637e-05, 9.2641e-04, 9.9900e-01, 7.0949e-06],\n",
      "        [1.6945e-04, 4.7521e-03, 9.9507e-01, 9.5931e-06],\n",
      "        [8.8369e-05, 1.2602e-03, 9.9865e-01, 3.4884e-06],\n",
      "        [9.8357e-05, 1.0912e-03, 9.9880e-01, 1.0856e-05],\n",
      "        [7.1025e-05, 1.7118e-03, 9.9820e-01, 1.3835e-05],\n",
      "        [4.8603e-05, 8.7632e-04, 9.9907e-01, 3.0593e-06],\n",
      "        [5.7400e-05, 8.8324e-04, 9.9905e-01, 1.0112e-05],\n",
      "        [6.1771e-05, 4.3269e-04, 9.9950e-01, 3.0799e-06],\n",
      "        [7.7942e-05, 9.1977e-04, 9.9900e-01, 5.7835e-06],\n",
      "        [1.2392e-04, 4.8229e-04, 9.9939e-01, 1.7667e-06],\n",
      "        [1.4455e-04, 2.6444e-03, 9.9720e-01, 8.7081e-06],\n",
      "        [1.0062e-04, 1.2746e-03, 9.9862e-01, 8.0116e-06],\n",
      "        [1.4774e-04, 1.0889e-03, 9.9875e-01, 9.0444e-06],\n",
      "        [2.8224e-05, 4.4417e-04, 9.9952e-01, 4.9729e-06],\n",
      "        [9.4240e-05, 1.8110e-03, 9.9809e-01, 6.7123e-06],\n",
      "        [7.6491e-05, 8.7545e-04, 9.9904e-01, 5.8855e-06],\n",
      "        [1.2756e-05, 4.9600e-04, 9.9949e-01, 2.1779e-06],\n",
      "        [1.0171e-04, 6.3926e-04, 9.9925e-01, 6.6215e-06],\n",
      "        [9.9190e-05, 1.5735e-03, 9.9832e-01, 6.6823e-06],\n",
      "        [3.6870e-04, 1.3676e-03, 9.9826e-01, 5.0991e-06],\n",
      "        [1.8572e-04, 1.1841e-03, 9.9863e-01, 4.2554e-06],\n",
      "        [1.0148e-04, 1.2731e-03, 9.9862e-01, 4.9565e-06],\n",
      "        [5.3266e-05, 1.5260e-03, 9.9841e-01, 7.1026e-06],\n",
      "        [1.3793e-04, 1.3047e-03, 9.9855e-01, 1.0493e-05],\n",
      "        [2.4268e-04, 1.2771e-03, 9.9847e-01, 7.4393e-06],\n",
      "        [4.5688e-05, 8.2100e-04, 9.9913e-01, 3.9144e-06],\n",
      "        [5.2189e-05, 3.6107e-04, 9.9958e-01, 7.3649e-06],\n",
      "        [5.3208e-05, 4.8565e-04, 9.9946e-01, 2.0758e-06],\n",
      "        [1.2365e-04, 2.1086e-03, 9.9776e-01, 1.1039e-05],\n",
      "        [2.3923e-04, 2.3183e-03, 9.9744e-01, 5.9467e-06],\n",
      "        [1.5376e-04, 1.7428e-03, 9.9809e-01, 8.7068e-06],\n",
      "        [1.0149e-04, 5.7508e-04, 9.9932e-01, 8.3211e-06],\n",
      "        [2.1105e-04, 1.3679e-03, 9.9841e-01, 6.1900e-06],\n",
      "        [1.3861e-04, 1.1994e-03, 9.9866e-01, 3.0969e-06],\n",
      "        [1.2578e-04, 1.1988e-03, 9.9867e-01, 9.2395e-06],\n",
      "        [4.5491e-05, 6.9759e-04, 9.9925e-01, 5.6243e-06],\n",
      "        [3.2791e-05, 2.2472e-04, 9.9973e-01, 9.9113e-06],\n",
      "        [6.4019e-05, 2.1165e-03, 9.9781e-01, 5.3848e-06],\n",
      "        [7.2785e-05, 5.5078e-04, 9.9937e-01, 9.4543e-06],\n",
      "        [4.6323e-05, 5.8923e-04, 9.9936e-01, 8.2708e-06],\n",
      "        [1.8819e-04, 1.4557e-03, 9.9834e-01, 1.2367e-05],\n",
      "        [8.5250e-05, 8.2820e-04, 9.9908e-01, 2.3346e-06],\n",
      "        [7.4101e-05, 1.0262e-03, 9.9889e-01, 6.6534e-06],\n",
      "        [1.2139e-04, 1.9069e-03, 9.9796e-01, 1.0206e-05],\n",
      "        [1.2592e-04, 9.7450e-04, 9.9889e-01, 1.0019e-05],\n",
      "        [1.0908e-04, 1.5391e-03, 9.9833e-01, 2.3641e-05],\n",
      "        [2.1233e-04, 8.0307e-04, 9.9898e-01, 6.0453e-06],\n",
      "        [3.6446e-05, 6.0038e-04, 9.9936e-01, 3.8121e-06],\n",
      "        [1.0662e-04, 2.3736e-03, 9.9752e-01, 3.8748e-06],\n",
      "        [8.2543e-05, 1.1284e-03, 9.9878e-01, 1.2518e-05],\n",
      "        [2.2113e-04, 8.7750e-04, 9.9890e-01, 3.7733e-06],\n",
      "        [1.9867e-04, 9.4960e-04, 9.9884e-01, 9.6122e-06],\n",
      "        [8.4709e-05, 1.0466e-03, 9.9886e-01, 6.9287e-06],\n",
      "        [5.9433e-05, 8.4914e-04, 9.9908e-01, 8.0297e-06],\n",
      "        [7.5325e-05, 4.4206e-04, 9.9948e-01, 3.0217e-06],\n",
      "        [3.8217e-04, 1.5223e-03, 9.9807e-01, 2.4770e-05],\n",
      "        [1.3813e-04, 7.9842e-04, 9.9905e-01, 1.4304e-05],\n",
      "        [1.0841e-04, 2.0464e-03, 9.9784e-01, 7.7774e-06],\n",
      "        [7.8390e-05, 1.0525e-03, 9.9886e-01, 9.1152e-06],\n",
      "        [3.8993e-05, 1.1421e-03, 9.9881e-01, 5.1150e-06],\n",
      "        [1.2959e-04, 2.1250e-03, 9.9774e-01, 4.2766e-06],\n",
      "        [8.9290e-05, 9.3223e-04, 9.9897e-01, 3.9129e-06],\n",
      "        [9.6335e-05, 6.2216e-04, 9.9928e-01, 1.7836e-06],\n",
      "        [1.8034e-04, 1.7286e-03, 9.9808e-01, 8.5357e-06],\n",
      "        [4.7422e-04, 2.6685e-03, 9.9684e-01, 1.9035e-05],\n",
      "        [1.2940e-04, 1.6205e-03, 9.9825e-01, 2.4786e-06],\n",
      "        [3.7180e-04, 1.2850e-03, 9.9834e-01, 7.3887e-06],\n",
      "        [5.2116e-05, 2.9137e-04, 9.9965e-01, 2.2268e-06],\n",
      "        [7.8900e-04, 1.1999e-03, 9.9800e-01, 9.3476e-06],\n",
      "        [7.5265e-05, 3.5013e-04, 9.9957e-01, 4.9984e-06],\n",
      "        [1.0852e-04, 1.6410e-03, 9.9824e-01, 7.1517e-06],\n",
      "        [2.0079e-04, 1.1353e-03, 9.9865e-01, 1.7839e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.8530e-08, 3.6685e-07, 1.0840e-04, 9.9989e-01],\n",
      "        [9.2481e-08, 1.6637e-07, 7.4808e-05, 9.9993e-01],\n",
      "        [6.8203e-08, 5.5621e-07, 2.9966e-04, 9.9970e-01],\n",
      "        [3.0396e-07, 1.9336e-06, 1.1739e-03, 9.9882e-01],\n",
      "        [1.4323e-07, 2.4273e-06, 9.5468e-04, 9.9904e-01],\n",
      "        [7.4667e-08, 1.0176e-06, 2.2494e-04, 9.9977e-01],\n",
      "        [8.3389e-08, 3.2407e-07, 1.7878e-04, 9.9982e-01],\n",
      "        [1.8481e-08, 1.8890e-07, 3.8994e-05, 9.9996e-01],\n",
      "        [1.6770e-07, 1.3752e-06, 8.9564e-04, 9.9910e-01],\n",
      "        [4.3927e-08, 1.4285e-06, 3.4473e-04, 9.9965e-01],\n",
      "        [9.0947e-08, 3.1952e-07, 6.0635e-05, 9.9994e-01],\n",
      "        [1.1530e-07, 8.1130e-07, 1.8384e-04, 9.9982e-01],\n",
      "        [1.2274e-07, 8.8610e-07, 2.1264e-04, 9.9979e-01],\n",
      "        [1.5711e-07, 4.5567e-06, 4.8844e-04, 9.9951e-01],\n",
      "        [4.6894e-08, 3.6272e-07, 5.1738e-05, 9.9995e-01],\n",
      "        [1.4204e-07, 1.0994e-06, 1.5411e-04, 9.9984e-01],\n",
      "        [1.1231e-07, 7.5216e-07, 1.9104e-04, 9.9981e-01],\n",
      "        [4.1949e-08, 1.3408e-07, 3.1937e-05, 9.9997e-01],\n",
      "        [5.1659e-07, 2.3634e-06, 5.6114e-04, 9.9944e-01],\n",
      "        [1.7865e-07, 1.3556e-06, 2.3095e-04, 9.9977e-01],\n",
      "        [2.5028e-08, 1.9707e-07, 3.6384e-05, 9.9996e-01],\n",
      "        [4.7268e-08, 1.2105e-06, 1.0351e-04, 9.9990e-01],\n",
      "        [3.0820e-07, 3.3496e-06, 1.7720e-03, 9.9822e-01],\n",
      "        [1.9704e-07, 8.2878e-07, 1.9803e-04, 9.9980e-01],\n",
      "        [1.7181e-07, 1.6820e-06, 1.3895e-04, 9.9986e-01],\n",
      "        [1.0643e-07, 5.9504e-07, 1.5879e-04, 9.9984e-01],\n",
      "        [1.5521e-07, 1.2231e-06, 1.3436e-04, 9.9986e-01],\n",
      "        [9.5039e-08, 2.2264e-06, 1.2566e-04, 9.9987e-01],\n",
      "        [5.3467e-08, 1.8069e-07, 2.5986e-05, 9.9997e-01],\n",
      "        [9.3905e-08, 7.7038e-07, 1.5162e-04, 9.9985e-01],\n",
      "        [2.2547e-07, 9.5012e-07, 5.1414e-04, 9.9948e-01],\n",
      "        [3.2614e-07, 1.2514e-06, 5.0453e-04, 9.9949e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(96.8978) tokens processed per second.\n",
      "Discriminator loss: tensor([[2.5714e-05, 9.9988e-01, 8.4606e-05, 1.0429e-05],\n",
      "        [1.8748e-05, 9.9989e-01, 8.2614e-05, 7.8561e-06],\n",
      "        [3.0794e-05, 9.9988e-01, 8.7660e-05, 3.4838e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 5.8111e-07, 1.5519e-06, 1.9095e-07],\n",
      "        [9.9996e-01, 8.0626e-06, 2.9384e-05, 1.0465e-06],\n",
      "        [9.9998e-01, 3.0050e-06, 1.4894e-05, 1.2229e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.2105e-04, 1.5116e-03, 9.9836e-01, 5.1889e-06],\n",
      "        [1.9232e-04, 2.0428e-03, 9.9775e-01, 1.1550e-05],\n",
      "        [3.7503e-05, 3.7872e-04, 9.9958e-01, 2.4882e-06],\n",
      "        [4.4566e-05, 3.6629e-04, 9.9959e-01, 2.6730e-06],\n",
      "        [5.7222e-05, 8.6664e-04, 9.9907e-01, 5.3221e-06],\n",
      "        [1.2149e-04, 1.9471e-03, 9.9792e-01, 1.1340e-05],\n",
      "        [1.4643e-04, 4.7809e-04, 9.9937e-01, 4.5736e-06],\n",
      "        [6.5812e-05, 3.6859e-04, 9.9955e-01, 1.0713e-05],\n",
      "        [9.6092e-05, 1.3150e-03, 9.9858e-01, 4.2827e-06],\n",
      "        [5.0654e-05, 1.1521e-03, 9.9879e-01, 5.0315e-06],\n",
      "        [3.3173e-05, 4.8013e-04, 9.9948e-01, 2.5486e-06],\n",
      "        [4.8394e-05, 6.5052e-04, 9.9929e-01, 9.5831e-06],\n",
      "        [1.6079e-04, 1.9336e-03, 9.9790e-01, 8.8840e-06],\n",
      "        [3.8337e-05, 5.4763e-04, 9.9941e-01, 5.7176e-06],\n",
      "        [9.1435e-05, 8.4448e-04, 9.9906e-01, 5.0803e-06],\n",
      "        [1.7775e-04, 1.3778e-03, 9.9843e-01, 1.4539e-05],\n",
      "        [2.2383e-04, 2.0507e-03, 9.9772e-01, 5.9577e-06],\n",
      "        [4.7891e-05, 1.1461e-03, 9.9880e-01, 4.1365e-06],\n",
      "        [1.8159e-04, 8.2287e-04, 9.9899e-01, 4.0593e-06],\n",
      "        [8.4510e-05, 3.4553e-03, 9.9645e-01, 1.2160e-05],\n",
      "        [4.8044e-05, 1.9321e-04, 9.9976e-01, 3.1741e-06],\n",
      "        [4.4691e-05, 6.7500e-04, 9.9926e-01, 2.0767e-05],\n",
      "        [3.2509e-05, 5.0448e-04, 9.9946e-01, 2.9284e-06],\n",
      "        [2.5535e-05, 6.5036e-04, 9.9932e-01, 4.2756e-06],\n",
      "        [5.1761e-05, 1.0019e-03, 9.9894e-01, 4.2368e-06],\n",
      "        [7.5110e-05, 6.8953e-04, 9.9923e-01, 4.3937e-06],\n",
      "        [1.9268e-04, 1.8346e-03, 9.9796e-01, 1.2639e-05],\n",
      "        [6.3167e-05, 9.8122e-04, 9.9895e-01, 6.5583e-06],\n",
      "        [1.9424e-04, 1.6450e-03, 9.9815e-01, 1.1410e-05],\n",
      "        [6.7543e-05, 1.3108e-03, 9.9861e-01, 8.0454e-06],\n",
      "        [1.9085e-04, 2.1129e-03, 9.9768e-01, 1.3592e-05],\n",
      "        [3.8126e-05, 1.3116e-03, 9.9864e-01, 1.1805e-05],\n",
      "        [4.6869e-05, 6.3751e-04, 9.9931e-01, 3.1218e-06],\n",
      "        [1.2467e-04, 8.4465e-04, 9.9902e-01, 1.1371e-05],\n",
      "        [4.8945e-05, 6.3809e-04, 9.9931e-01, 5.9302e-06],\n",
      "        [1.4963e-04, 1.7401e-03, 9.9810e-01, 1.0002e-05],\n",
      "        [1.2534e-04, 1.5693e-03, 9.9829e-01, 1.5996e-05],\n",
      "        [7.7096e-05, 1.6026e-03, 9.9831e-01, 9.4981e-06],\n",
      "        [3.2850e-04, 1.7543e-03, 9.9790e-01, 1.5618e-05],\n",
      "        [8.6529e-05, 1.0223e-03, 9.9888e-01, 1.2693e-05],\n",
      "        [1.4051e-04, 2.7631e-03, 9.9708e-01, 1.1502e-05],\n",
      "        [6.5824e-05, 7.5821e-04, 9.9917e-01, 4.1235e-06],\n",
      "        [1.2593e-04, 1.5291e-03, 9.9834e-01, 3.7469e-06],\n",
      "        [9.6131e-05, 1.3952e-03, 9.9850e-01, 7.7004e-06],\n",
      "        [6.9212e-05, 6.8910e-04, 9.9924e-01, 5.3528e-06],\n",
      "        [3.6443e-05, 3.1415e-04, 9.9965e-01, 3.2043e-06],\n",
      "        [7.3091e-05, 8.7594e-04, 9.9904e-01, 6.9818e-06],\n",
      "        [2.1493e-04, 2.8551e-03, 9.9692e-01, 8.2616e-06],\n",
      "        [6.5046e-05, 3.8691e-03, 9.9604e-01, 2.5109e-05],\n",
      "        [1.6078e-04, 6.3094e-04, 9.9920e-01, 3.4493e-06],\n",
      "        [1.2228e-04, 2.1411e-03, 9.9772e-01, 1.3574e-05],\n",
      "        [1.5554e-05, 2.9743e-04, 9.9968e-01, 3.1069e-06],\n",
      "        [7.5810e-05, 7.4121e-04, 9.9918e-01, 7.5383e-06],\n",
      "        [2.6948e-05, 7.2317e-04, 9.9925e-01, 3.0754e-06],\n",
      "        [5.1202e-05, 2.9004e-04, 9.9966e-01, 1.7501e-06],\n",
      "        [3.6907e-05, 1.0028e-03, 9.9896e-01, 4.1731e-06],\n",
      "        [7.7867e-05, 9.4147e-04, 9.9897e-01, 9.3856e-06],\n",
      "        [1.0841e-04, 7.0777e-04, 9.9918e-01, 2.7804e-06],\n",
      "        [1.0643e-04, 1.1936e-03, 9.9870e-01, 4.0342e-06],\n",
      "        [3.1863e-05, 1.0586e-03, 9.9890e-01, 4.6809e-06],\n",
      "        [1.1040e-04, 5.1307e-04, 9.9937e-01, 6.0741e-06],\n",
      "        [7.0055e-05, 1.9537e-03, 9.9797e-01, 3.3048e-06],\n",
      "        [4.1636e-05, 5.2902e-04, 9.9942e-01, 8.0980e-06],\n",
      "        [6.6888e-05, 7.6450e-04, 9.9916e-01, 6.3457e-06],\n",
      "        [3.0374e-05, 9.6380e-04, 9.9900e-01, 3.1858e-06],\n",
      "        [3.2959e-05, 3.1791e-04, 9.9965e-01, 3.1529e-06],\n",
      "        [9.7202e-05, 1.8024e-03, 9.9810e-01, 3.6328e-06],\n",
      "        [2.0726e-04, 3.2697e-03, 9.9652e-01, 5.5302e-06],\n",
      "        [7.8220e-05, 5.8856e-04, 9.9933e-01, 6.4382e-06],\n",
      "        [3.8700e-05, 2.6889e-04, 9.9969e-01, 6.6849e-06],\n",
      "        [2.4199e-04, 4.6446e-03, 9.9510e-01, 1.2148e-05],\n",
      "        [1.3142e-04, 1.5353e-03, 9.9833e-01, 3.9356e-06],\n",
      "        [5.5632e-05, 6.1430e-04, 9.9932e-01, 9.6124e-06],\n",
      "        [1.3195e-04, 1.0366e-03, 9.9882e-01, 8.0896e-06],\n",
      "        [1.2037e-04, 1.4324e-03, 9.9844e-01, 5.3470e-06],\n",
      "        [2.6736e-04, 1.8622e-03, 9.9786e-01, 9.5857e-06],\n",
      "        [1.7609e-04, 1.1532e-03, 9.9866e-01, 7.4843e-06],\n",
      "        [4.5043e-05, 4.3062e-04, 9.9952e-01, 3.1208e-06],\n",
      "        [7.8230e-05, 7.9541e-04, 9.9912e-01, 9.4081e-06],\n",
      "        [1.2568e-04, 8.5293e-04, 9.9902e-01, 5.0604e-06],\n",
      "        [3.1072e-05, 4.7737e-04, 9.9948e-01, 6.6214e-06],\n",
      "        [9.7428e-05, 8.0901e-04, 9.9909e-01, 4.5819e-06],\n",
      "        [2.8978e-05, 1.0013e-03, 9.9896e-01, 9.2783e-06],\n",
      "        [7.6909e-05, 7.1021e-04, 9.9921e-01, 6.7814e-06],\n",
      "        [3.5471e-05, 3.6312e-04, 9.9960e-01, 4.0616e-06],\n",
      "        [9.7399e-05, 1.4929e-03, 9.9839e-01, 1.6911e-05],\n",
      "        [8.1746e-05, 5.1832e-04, 9.9940e-01, 3.7990e-06],\n",
      "        [5.5497e-05, 3.5220e-04, 9.9959e-01, 4.3795e-06],\n",
      "        [6.2332e-05, 1.5196e-03, 9.9841e-01, 8.4834e-06],\n",
      "        [8.9781e-05, 1.3311e-03, 9.9858e-01, 3.5244e-06],\n",
      "        [7.2544e-05, 6.4886e-04, 9.9927e-01, 5.4064e-06],\n",
      "        [1.5354e-05, 5.7769e-04, 9.9940e-01, 2.2636e-06],\n",
      "        [1.5649e-04, 2.4524e-03, 9.9737e-01, 2.0978e-05],\n",
      "        [3.0486e-05, 5.3888e-04, 9.9943e-01, 2.2474e-06],\n",
      "        [7.3340e-05, 1.4402e-03, 9.9848e-01, 8.0266e-06],\n",
      "        [1.3741e-04, 1.3948e-03, 9.9846e-01, 5.4401e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.8112e-08, 6.0661e-07, 7.9077e-05, 9.9992e-01],\n",
      "        [4.7339e-08, 3.0497e-07, 1.8078e-04, 9.9982e-01],\n",
      "        [6.6136e-08, 4.2064e-07, 1.0807e-04, 9.9989e-01],\n",
      "        [1.5515e-07, 4.1928e-07, 3.9185e-05, 9.9996e-01],\n",
      "        [8.1588e-08, 9.9425e-07, 2.3960e-04, 9.9976e-01],\n",
      "        [5.4412e-08, 3.1965e-07, 1.1287e-04, 9.9989e-01],\n",
      "        [4.8232e-08, 5.4899e-07, 1.9307e-04, 9.9981e-01],\n",
      "        [3.1327e-07, 4.5779e-06, 2.4813e-03, 9.9751e-01],\n",
      "        [2.7574e-08, 2.9394e-07, 4.9985e-05, 9.9995e-01],\n",
      "        [8.2913e-09, 1.5983e-07, 1.7556e-05, 9.9998e-01],\n",
      "        [4.1331e-08, 2.8829e-07, 6.7164e-05, 9.9993e-01],\n",
      "        [1.0058e-08, 1.5503e-07, 1.2820e-05, 9.9999e-01],\n",
      "        [2.8007e-08, 4.1137e-07, 7.2758e-05, 9.9993e-01],\n",
      "        [2.1357e-08, 9.1768e-07, 1.4201e-04, 9.9986e-01],\n",
      "        [1.4383e-07, 5.4541e-07, 5.3025e-05, 9.9995e-01],\n",
      "        [1.5571e-08, 1.4875e-07, 7.5694e-06, 9.9999e-01],\n",
      "        [1.9380e-08, 1.7149e-07, 9.6212e-06, 9.9999e-01],\n",
      "        [3.8632e-07, 7.6471e-07, 1.0802e-04, 9.9989e-01],\n",
      "        [2.3523e-07, 5.8804e-07, 3.1168e-05, 9.9997e-01],\n",
      "        [5.3081e-08, 3.4293e-07, 9.0138e-05, 9.9991e-01],\n",
      "        [3.6338e-08, 4.8027e-07, 7.0635e-05, 9.9993e-01],\n",
      "        [1.3628e-07, 1.6386e-06, 2.1639e-04, 9.9978e-01],\n",
      "        [6.4441e-08, 2.9270e-07, 7.7014e-05, 9.9992e-01],\n",
      "        [1.2341e-07, 7.1794e-07, 5.0063e-05, 9.9995e-01],\n",
      "        [4.0944e-08, 4.6666e-07, 2.0487e-05, 9.9998e-01],\n",
      "        [2.2631e-08, 3.0254e-07, 5.5987e-05, 9.9994e-01],\n",
      "        [6.5198e-08, 3.8811e-07, 8.2777e-05, 9.9992e-01],\n",
      "        [1.1470e-08, 1.6369e-07, 4.7964e-05, 9.9995e-01],\n",
      "        [3.0841e-09, 2.1470e-08, 3.4623e-06, 1.0000e+00],\n",
      "        [1.3829e-08, 1.2130e-07, 7.9430e-06, 9.9999e-01],\n",
      "        [5.4752e-08, 2.2037e-07, 1.3138e-05, 9.9999e-01],\n",
      "        [6.1220e-08, 4.7613e-07, 6.3655e-05, 9.9994e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(97.9162) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.0710e-04, 9.9777e-01, 2.1065e-03, 2.0326e-05],\n",
      "        [1.6091e-03, 9.9414e-01, 4.1959e-03, 5.6335e-05],\n",
      "        [1.2293e-04, 9.9948e-01, 3.7221e-04, 2.2172e-05],\n",
      "        [6.3568e-06, 9.9985e-01, 1.3095e-04, 1.0665e-05],\n",
      "        [1.0307e-03, 9.9292e-01, 6.0184e-03, 3.5143e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9997e-01, 1.2505e-05, 2.1698e-05, 7.5990e-07],\n",
      "        [9.9988e-01, 5.0848e-05, 6.8126e-05, 1.6052e-06],\n",
      "        [9.9980e-01, 9.4572e-05, 9.9772e-05, 2.4230e-06],\n",
      "        [9.9998e-01, 2.5891e-06, 1.4590e-05, 3.0503e-07],\n",
      "        [9.9994e-01, 2.4362e-05, 3.9740e-05, 8.1328e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.0433e-04, 8.2304e-04, 9.9907e-01, 2.3021e-06],\n",
      "        [9.7541e-05, 1.6629e-03, 9.9823e-01, 1.0758e-05],\n",
      "        [1.6425e-04, 1.0699e-03, 9.9876e-01, 9.6005e-06],\n",
      "        [6.8501e-05, 1.2752e-03, 9.9865e-01, 4.2170e-06],\n",
      "        [2.5657e-04, 3.1439e-03, 9.9658e-01, 1.9944e-05],\n",
      "        [6.0796e-05, 4.7165e-04, 9.9946e-01, 3.0108e-06],\n",
      "        [6.9939e-06, 1.8191e-04, 9.9981e-01, 8.8529e-07],\n",
      "        [1.3855e-04, 5.6340e-04, 9.9929e-01, 6.7533e-06],\n",
      "        [1.1523e-04, 1.4231e-03, 9.9846e-01, 6.5591e-06],\n",
      "        [2.8568e-04, 1.4132e-03, 9.9829e-01, 1.5706e-05],\n",
      "        [4.6737e-05, 5.2201e-04, 9.9943e-01, 2.4186e-06],\n",
      "        [5.0475e-05, 7.2577e-04, 9.9920e-01, 2.5195e-05],\n",
      "        [1.4252e-04, 7.7443e-04, 9.9908e-01, 4.1688e-06],\n",
      "        [1.1099e-04, 1.3857e-03, 9.9849e-01, 8.9676e-06],\n",
      "        [1.0678e-04, 1.2555e-03, 9.9863e-01, 4.9719e-06],\n",
      "        [2.7815e-04, 2.3275e-03, 9.9739e-01, 7.7863e-06],\n",
      "        [4.9734e-05, 7.0825e-04, 9.9923e-01, 1.0187e-05],\n",
      "        [7.4390e-05, 6.0123e-04, 9.9932e-01, 3.3710e-06],\n",
      "        [5.3827e-05, 5.2403e-04, 9.9941e-01, 8.5099e-06],\n",
      "        [1.8217e-04, 1.0498e-03, 9.9875e-01, 2.0598e-05],\n",
      "        [5.2251e-05, 7.3550e-04, 9.9921e-01, 3.2671e-06],\n",
      "        [4.5119e-05, 4.6778e-04, 9.9948e-01, 3.4693e-06],\n",
      "        [6.5171e-05, 3.0114e-04, 9.9963e-01, 2.3824e-06],\n",
      "        [1.1490e-04, 1.2554e-03, 9.9862e-01, 7.6785e-06],\n",
      "        [4.0795e-05, 3.3069e-04, 9.9962e-01, 3.5776e-06],\n",
      "        [4.9739e-05, 1.0859e-03, 9.9886e-01, 2.7433e-06],\n",
      "        [1.4852e-04, 8.5663e-04, 9.9899e-01, 4.8853e-06],\n",
      "        [5.2681e-05, 3.8301e-04, 9.9956e-01, 1.3528e-06],\n",
      "        [1.5872e-05, 1.3231e-04, 9.9985e-01, 1.8825e-06],\n",
      "        [1.6603e-04, 1.2024e-03, 9.9862e-01, 7.7086e-06],\n",
      "        [7.1978e-05, 8.2282e-04, 9.9910e-01, 3.5217e-06],\n",
      "        [4.1366e-05, 1.0046e-03, 9.9895e-01, 5.5721e-06],\n",
      "        [9.0949e-05, 5.2339e-04, 9.9938e-01, 4.4323e-06],\n",
      "        [2.6225e-04, 3.7296e-03, 9.9600e-01, 1.0086e-05],\n",
      "        [1.3496e-04, 5.4091e-04, 9.9931e-01, 9.6301e-06],\n",
      "        [3.2566e-04, 2.8127e-03, 9.9686e-01, 5.5859e-06],\n",
      "        [1.2772e-04, 1.6440e-03, 9.9822e-01, 8.7226e-06],\n",
      "        [2.2386e-04, 1.0305e-03, 9.9874e-01, 1.0208e-05],\n",
      "        [1.0257e-04, 7.1660e-04, 9.9917e-01, 8.9573e-06],\n",
      "        [3.2196e-05, 2.0533e-04, 9.9976e-01, 5.2142e-06],\n",
      "        [1.2522e-04, 6.5630e-04, 9.9921e-01, 8.6823e-06],\n",
      "        [5.1882e-05, 6.0943e-04, 9.9933e-01, 4.5786e-06],\n",
      "        [4.4037e-05, 8.6470e-04, 9.9909e-01, 3.9051e-06],\n",
      "        [1.8671e-04, 1.5511e-03, 9.9825e-01, 7.6502e-06],\n",
      "        [1.1816e-04, 7.0026e-04, 9.9917e-01, 8.1986e-06],\n",
      "        [1.2694e-04, 5.7724e-04, 9.9929e-01, 9.5528e-06],\n",
      "        [4.4495e-05, 7.9192e-04, 9.9916e-01, 3.8313e-06],\n",
      "        [5.3583e-05, 4.5932e-04, 9.9948e-01, 3.2792e-06],\n",
      "        [6.3697e-05, 1.0564e-03, 9.9887e-01, 7.7168e-06],\n",
      "        [1.8428e-04, 1.2442e-03, 9.9856e-01, 1.2434e-05],\n",
      "        [4.0209e-04, 3.8273e-03, 9.9575e-01, 1.7099e-05],\n",
      "        [2.3401e-05, 1.9109e-04, 9.9978e-01, 3.0072e-06],\n",
      "        [6.8212e-05, 4.4927e-04, 9.9948e-01, 4.5281e-06],\n",
      "        [1.4459e-04, 1.7493e-03, 9.9810e-01, 1.0779e-05],\n",
      "        [8.6594e-05, 7.7752e-04, 9.9913e-01, 6.3158e-06],\n",
      "        [7.3020e-05, 7.6586e-04, 9.9915e-01, 8.1630e-06],\n",
      "        [1.4514e-04, 1.0145e-03, 9.9884e-01, 4.8832e-06],\n",
      "        [3.7966e-05, 3.8117e-04, 9.9958e-01, 4.0067e-06],\n",
      "        [3.1498e-05, 4.8624e-04, 9.9947e-01, 1.7113e-05],\n",
      "        [5.9597e-05, 1.3081e-03, 9.9863e-01, 6.1259e-06],\n",
      "        [1.5968e-04, 1.7728e-03, 9.9806e-01, 9.0146e-06],\n",
      "        [4.1470e-05, 7.1734e-04, 9.9923e-01, 9.7576e-06],\n",
      "        [6.1485e-05, 1.8374e-03, 9.9810e-01, 4.5588e-06],\n",
      "        [2.2836e-05, 1.7261e-04, 9.9980e-01, 1.4562e-06],\n",
      "        [5.2259e-05, 4.0183e-04, 9.9954e-01, 5.5897e-06],\n",
      "        [4.9886e-05, 2.9807e-04, 9.9965e-01, 4.0793e-06],\n",
      "        [5.4867e-05, 5.6392e-04, 9.9938e-01, 4.0356e-06],\n",
      "        [1.3198e-04, 1.3923e-03, 9.9847e-01, 5.7417e-06],\n",
      "        [8.6414e-05, 1.9301e-03, 9.9798e-01, 5.0598e-06],\n",
      "        [2.3523e-04, 1.2600e-03, 9.9850e-01, 6.8007e-06],\n",
      "        [4.5698e-05, 1.2000e-03, 9.9875e-01, 5.9933e-06],\n",
      "        [1.8822e-04, 6.5262e-04, 9.9915e-01, 1.0006e-05],\n",
      "        [1.8034e-04, 2.6021e-03, 9.9721e-01, 1.0109e-05],\n",
      "        [7.5690e-05, 9.0321e-04, 9.9901e-01, 6.1228e-06],\n",
      "        [8.9231e-05, 5.5890e-04, 9.9935e-01, 5.5213e-06],\n",
      "        [2.2184e-04, 5.0527e-04, 9.9927e-01, 4.8634e-06],\n",
      "        [3.3797e-05, 3.8021e-04, 9.9958e-01, 2.4471e-06],\n",
      "        [3.0688e-04, 7.8640e-04, 9.9890e-01, 8.0421e-06],\n",
      "        [1.3322e-04, 1.0453e-03, 9.9882e-01, 6.0687e-06],\n",
      "        [1.1801e-04, 3.8422e-03, 9.9603e-01, 1.1314e-05],\n",
      "        [4.6923e-05, 6.1463e-04, 9.9934e-01, 3.0752e-06],\n",
      "        [1.2037e-04, 1.7563e-03, 9.9811e-01, 1.1908e-05],\n",
      "        [1.5952e-04, 1.2316e-03, 9.9860e-01, 4.0219e-06],\n",
      "        [1.1861e-04, 5.4019e-04, 9.9933e-01, 7.8252e-06],\n",
      "        [5.2014e-05, 1.3080e-03, 9.9863e-01, 5.5808e-06],\n",
      "        [3.0030e-04, 7.1319e-03, 9.9254e-01, 2.9150e-05],\n",
      "        [4.2854e-05, 3.2814e-04, 9.9963e-01, 2.5195e-06],\n",
      "        [2.1025e-04, 7.3969e-04, 9.9904e-01, 8.1019e-06],\n",
      "        [4.1568e-05, 5.8489e-04, 9.9937e-01, 7.1738e-06],\n",
      "        [9.9365e-05, 6.6002e-04, 9.9923e-01, 9.2136e-06],\n",
      "        [8.9733e-05, 6.8296e-04, 9.9922e-01, 3.9119e-06],\n",
      "        [3.2473e-05, 7.8461e-04, 9.9918e-01, 4.3036e-06],\n",
      "        [3.4127e-05, 5.7784e-04, 9.9938e-01, 4.5523e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.1131e-08, 8.4724e-07, 4.6464e-05, 9.9995e-01],\n",
      "        [5.5857e-08, 1.6969e-07, 1.0131e-04, 9.9990e-01],\n",
      "        [1.8801e-07, 9.8660e-07, 1.1583e-03, 9.9884e-01],\n",
      "        [5.2422e-08, 1.4113e-07, 3.3352e-05, 9.9997e-01],\n",
      "        [3.8876e-09, 5.6633e-08, 7.5285e-06, 9.9999e-01],\n",
      "        [5.0155e-08, 8.9003e-07, 2.7106e-04, 9.9973e-01],\n",
      "        [2.9362e-07, 5.9135e-07, 2.8496e-04, 9.9971e-01],\n",
      "        [1.8000e-08, 1.4080e-07, 3.3893e-05, 9.9997e-01],\n",
      "        [2.2412e-08, 6.8938e-08, 1.9157e-05, 9.9998e-01],\n",
      "        [5.6292e-08, 9.9644e-08, 6.4371e-05, 9.9994e-01],\n",
      "        [2.5170e-08, 9.5648e-08, 2.4808e-05, 9.9998e-01],\n",
      "        [3.1524e-08, 9.7361e-08, 6.8114e-05, 9.9993e-01],\n",
      "        [4.3102e-08, 2.2628e-07, 8.3159e-05, 9.9992e-01],\n",
      "        [3.4631e-08, 1.2015e-07, 1.2105e-04, 9.9988e-01],\n",
      "        [4.5805e-08, 3.5317e-07, 2.3645e-04, 9.9976e-01],\n",
      "        [2.9613e-08, 1.5501e-07, 4.2988e-05, 9.9996e-01],\n",
      "        [6.5488e-08, 3.0384e-07, 6.0445e-05, 9.9994e-01],\n",
      "        [4.2456e-08, 4.8502e-07, 5.7821e-04, 9.9942e-01],\n",
      "        [1.0636e-08, 2.2494e-07, 1.9239e-05, 9.9998e-01],\n",
      "        [2.0203e-07, 3.1081e-07, 8.6537e-05, 9.9991e-01],\n",
      "        [6.5413e-08, 6.9508e-07, 1.2083e-04, 9.9988e-01],\n",
      "        [3.8715e-08, 2.1324e-07, 9.2308e-05, 9.9991e-01],\n",
      "        [7.3913e-08, 1.3530e-07, 4.6481e-05, 9.9995e-01],\n",
      "        [1.2898e-08, 1.8224e-07, 2.9489e-05, 9.9997e-01],\n",
      "        [9.7109e-08, 4.4542e-07, 7.3471e-04, 9.9926e-01],\n",
      "        [4.6572e-08, 4.5606e-07, 1.3043e-04, 9.9987e-01],\n",
      "        [5.5915e-08, 4.9357e-07, 1.1564e-04, 9.9988e-01],\n",
      "        [1.8750e-08, 1.7962e-07, 5.1539e-05, 9.9995e-01],\n",
      "        [8.4267e-09, 1.3306e-07, 3.6555e-05, 9.9996e-01],\n",
      "        [2.1677e-08, 8.6559e-08, 2.1050e-05, 9.9998e-01],\n",
      "        [1.6250e-08, 4.0686e-08, 4.3940e-05, 9.9996e-01],\n",
      "        [7.4495e-08, 1.6818e-07, 1.9315e-04, 9.9981e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(98.4318) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[7.6816e-07, 1.0000e+00, 1.2029e-06, 2.0321e-06],\n",
      "        [1.8215e-06, 9.9999e-01, 5.0009e-06, 1.4495e-06],\n",
      "        [3.1903e-06, 9.9999e-01, 1.7174e-06, 1.3026e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9996e-01, 3.0809e-05, 3.3941e-06, 1.3462e-06],\n",
      "        [9.9979e-01, 2.0663e-04, 5.6928e-06, 2.2723e-06],\n",
      "        [9.9986e-01, 1.3075e-04, 1.0833e-05, 1.6257e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.0029e-04, 9.9027e-03, 9.8986e-01, 3.5619e-05],\n",
      "        [6.3349e-05, 4.9019e-03, 9.9503e-01, 5.9827e-06],\n",
      "        [4.9850e-05, 7.5146e-03, 9.9243e-01, 4.5860e-06],\n",
      "        [1.0461e-04, 2.7898e-02, 9.7198e-01, 1.6560e-05],\n",
      "        [2.8352e-05, 3.6988e-03, 9.9626e-01, 9.2986e-06],\n",
      "        [5.6330e-05, 1.1694e-02, 9.8824e-01, 7.8542e-06],\n",
      "        [1.7847e-04, 9.2696e-03, 9.9054e-01, 8.9122e-06],\n",
      "        [1.8160e-04, 2.0994e-02, 9.7880e-01, 2.2199e-05],\n",
      "        [9.4201e-05, 3.4321e-03, 9.9647e-01, 2.8122e-06],\n",
      "        [1.5103e-04, 1.3430e-02, 9.8638e-01, 3.4596e-05],\n",
      "        [1.0079e-04, 6.1510e-03, 9.9374e-01, 1.0937e-05],\n",
      "        [6.0808e-05, 6.0912e-03, 9.9383e-01, 1.8749e-05],\n",
      "        [1.5438e-04, 1.5572e-02, 9.8427e-01, 7.0652e-06],\n",
      "        [3.4262e-04, 6.2423e-02, 9.3719e-01, 4.6141e-05],\n",
      "        [3.9039e-05, 1.6007e-02, 9.8394e-01, 1.2044e-05],\n",
      "        [6.8703e-05, 7.2270e-03, 9.9269e-01, 1.3670e-05],\n",
      "        [1.9258e-05, 2.3114e-03, 9.9767e-01, 1.8738e-06],\n",
      "        [6.4940e-05, 6.6952e-03, 9.9323e-01, 5.4975e-06],\n",
      "        [5.0368e-05, 3.8840e-03, 9.9606e-01, 3.8692e-06],\n",
      "        [5.4140e-05, 6.6072e-03, 9.9333e-01, 8.6724e-06],\n",
      "        [8.8822e-05, 3.0899e-03, 9.9681e-01, 9.1046e-06],\n",
      "        [2.7364e-04, 2.0992e-02, 9.7870e-01, 3.4009e-05],\n",
      "        [9.0876e-05, 1.8127e-03, 9.9809e-01, 6.9910e-06],\n",
      "        [2.2980e-04, 1.5825e-02, 9.8394e-01, 6.9874e-06],\n",
      "        [1.4560e-05, 7.0832e-04, 9.9927e-01, 3.7703e-06],\n",
      "        [6.1027e-05, 4.8264e-03, 9.9511e-01, 6.2212e-06],\n",
      "        [9.4020e-05, 6.1718e-03, 9.9372e-01, 1.8430e-05],\n",
      "        [7.2321e-05, 3.2049e-03, 9.9672e-01, 4.3995e-06],\n",
      "        [1.5807e-04, 4.2143e-02, 9.5767e-01, 2.9294e-05],\n",
      "        [2.5756e-04, 2.7027e-02, 9.7270e-01, 1.3888e-05],\n",
      "        [9.5925e-05, 4.7571e-03, 9.9514e-01, 1.0616e-05],\n",
      "        [1.1402e-03, 2.9324e-02, 9.6949e-01, 4.6772e-05],\n",
      "        [1.9752e-04, 5.8688e-03, 9.9392e-01, 1.3907e-05],\n",
      "        [2.9857e-04, 8.3186e-03, 9.9137e-01, 1.3793e-05],\n",
      "        [1.7018e-04, 1.7298e-02, 9.8251e-01, 2.3155e-05],\n",
      "        [1.1333e-04, 1.9221e-02, 9.8065e-01, 1.5559e-05],\n",
      "        [7.1621e-04, 2.0952e-02, 9.7831e-01, 2.0842e-05],\n",
      "        [7.5996e-05, 3.7743e-03, 9.9614e-01, 8.0832e-06],\n",
      "        [4.6315e-05, 2.8136e-03, 9.9713e-01, 1.0583e-05],\n",
      "        [1.8523e-04, 3.3409e-02, 9.6636e-01, 4.9987e-05],\n",
      "        [5.6129e-05, 7.1927e-03, 9.9274e-01, 1.2393e-05],\n",
      "        [9.5911e-05, 3.5961e-03, 9.9630e-01, 6.5148e-06],\n",
      "        [4.3782e-04, 1.6298e-02, 9.8325e-01, 1.7494e-05],\n",
      "        [1.0643e-04, 8.9770e-03, 9.9091e-01, 7.1935e-06],\n",
      "        [1.2691e-04, 1.2783e-02, 9.8708e-01, 6.6625e-06],\n",
      "        [3.9794e-04, 6.7550e-02, 9.3201e-01, 4.0039e-05],\n",
      "        [2.7568e-05, 3.0957e-03, 9.9687e-01, 2.4173e-06],\n",
      "        [6.9820e-05, 3.1181e-03, 9.9679e-01, 2.0408e-05],\n",
      "        [1.4329e-05, 9.8220e-04, 9.9900e-01, 2.4430e-06],\n",
      "        [2.5990e-04, 2.6700e-02, 9.7302e-01, 1.5874e-05],\n",
      "        [2.1909e-04, 1.6419e-02, 9.8334e-01, 2.4810e-05],\n",
      "        [2.0417e-04, 1.2935e-02, 9.8686e-01, 4.8898e-06],\n",
      "        [2.2972e-04, 2.7003e-02, 9.7275e-01, 1.7324e-05],\n",
      "        [3.1916e-04, 5.0388e-02, 9.4928e-01, 1.7304e-05],\n",
      "        [8.8613e-05, 2.3681e-02, 9.7622e-01, 1.1223e-05],\n",
      "        [7.5139e-05, 1.7242e-02, 9.8267e-01, 8.4129e-06],\n",
      "        [4.0723e-05, 4.6984e-03, 9.9526e-01, 4.7297e-06],\n",
      "        [1.1223e-04, 9.2804e-03, 9.9060e-01, 7.2160e-06],\n",
      "        [4.0182e-05, 2.2258e-03, 9.9773e-01, 6.0236e-06],\n",
      "        [7.2891e-05, 8.6896e-03, 9.9122e-01, 1.4884e-05],\n",
      "        [1.0164e-04, 6.4865e-03, 9.9340e-01, 1.2067e-05],\n",
      "        [7.1329e-05, 4.8506e-03, 9.9507e-01, 1.0240e-05],\n",
      "        [1.4965e-04, 3.1287e-03, 9.9671e-01, 8.1273e-06],\n",
      "        [2.7123e-03, 1.0043e-01, 8.9679e-01, 6.7907e-05],\n",
      "        [1.9793e-04, 2.5983e-02, 9.7381e-01, 1.0806e-05],\n",
      "        [1.4275e-04, 1.0631e-02, 9.8922e-01, 8.1320e-06],\n",
      "        [3.0616e-04, 7.5691e-02, 9.2398e-01, 2.7598e-05],\n",
      "        [1.4120e-04, 1.6266e-02, 9.8358e-01, 8.8609e-06],\n",
      "        [7.5005e-05, 6.7668e-03, 9.9314e-01, 1.8105e-05],\n",
      "        [1.1775e-04, 8.1273e-03, 9.9174e-01, 1.0669e-05],\n",
      "        [1.3346e-04, 8.6109e-03, 9.9124e-01, 1.5763e-05],\n",
      "        [8.3954e-05, 1.0986e-02, 9.8892e-01, 9.3781e-06],\n",
      "        [1.1903e-04, 6.6939e-03, 9.9318e-01, 8.0435e-06],\n",
      "        [2.0877e-04, 1.0349e-02, 9.8942e-01, 2.5856e-05],\n",
      "        [2.2831e-05, 3.7895e-03, 9.9619e-01, 2.5976e-06],\n",
      "        [4.6444e-04, 1.2554e-02, 9.8696e-01, 2.4205e-05],\n",
      "        [1.4182e-04, 5.8889e-03, 9.9396e-01, 8.1237e-06],\n",
      "        [1.1132e-04, 1.0427e-02, 9.8945e-01, 1.3420e-05],\n",
      "        [1.0548e-04, 4.6840e-03, 9.9520e-01, 6.8191e-06],\n",
      "        [9.1242e-05, 1.9281e-02, 9.8062e-01, 1.0894e-05],\n",
      "        [1.1533e-04, 1.2666e-02, 9.8720e-01, 2.2890e-05],\n",
      "        [7.0991e-05, 5.2116e-03, 9.9471e-01, 1.1022e-05],\n",
      "        [4.8310e-05, 5.8282e-03, 9.9412e-01, 8.0154e-06],\n",
      "        [1.1285e-04, 2.4517e-02, 9.7534e-01, 2.5562e-05],\n",
      "        [1.7691e-04, 1.9342e-02, 9.8047e-01, 1.2025e-05],\n",
      "        [3.3471e-04, 1.9181e-02, 9.8046e-01, 2.0448e-05],\n",
      "        [3.5713e-05, 9.0433e-03, 9.9092e-01, 5.8445e-06],\n",
      "        [8.7048e-05, 2.6622e-03, 9.9724e-01, 7.7943e-06],\n",
      "        [3.5053e-05, 3.4413e-03, 9.9652e-01, 7.9789e-06],\n",
      "        [9.6808e-05, 6.6311e-03, 9.9326e-01, 9.8773e-06],\n",
      "        [2.5646e-04, 1.8174e-02, 9.8155e-01, 2.1093e-05],\n",
      "        [1.2371e-04, 3.1981e-02, 9.6786e-01, 3.0152e-05],\n",
      "        [1.7273e-04, 9.9783e-03, 9.8984e-01, 1.2872e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.8501e-09, 3.5734e-07, 1.3527e-05, 9.9999e-01],\n",
      "        [3.3770e-08, 2.4042e-07, 2.7040e-05, 9.9997e-01],\n",
      "        [9.2921e-09, 1.5151e-07, 2.7502e-05, 9.9997e-01],\n",
      "        [1.0649e-08, 2.9134e-07, 2.7349e-05, 9.9997e-01],\n",
      "        [1.6195e-08, 8.0488e-07, 7.0587e-05, 9.9993e-01],\n",
      "        [1.6263e-08, 1.3832e-07, 2.0222e-05, 9.9998e-01],\n",
      "        [8.8379e-08, 7.2775e-07, 2.5542e-04, 9.9974e-01],\n",
      "        [5.4315e-09, 1.1271e-07, 7.1424e-06, 9.9999e-01],\n",
      "        [1.3520e-08, 2.7049e-07, 2.1677e-05, 9.9998e-01],\n",
      "        [3.7789e-09, 2.3109e-07, 9.4461e-06, 9.9999e-01],\n",
      "        [1.2390e-08, 2.5937e-07, 8.0162e-05, 9.9992e-01],\n",
      "        [7.6135e-09, 1.6897e-07, 6.5617e-06, 9.9999e-01],\n",
      "        [1.6865e-08, 2.2576e-07, 2.5371e-05, 9.9997e-01],\n",
      "        [3.2856e-09, 5.9790e-08, 6.3441e-06, 9.9999e-01],\n",
      "        [4.7830e-09, 7.1731e-08, 3.8479e-06, 1.0000e+00],\n",
      "        [1.8191e-08, 3.0706e-07, 2.5822e-05, 9.9997e-01],\n",
      "        [3.4677e-08, 3.5862e-07, 1.1714e-04, 9.9988e-01],\n",
      "        [6.7008e-09, 8.7272e-08, 4.5547e-06, 1.0000e+00],\n",
      "        [2.5018e-08, 5.0437e-07, 5.9802e-05, 9.9994e-01],\n",
      "        [9.5592e-09, 2.9671e-07, 1.4310e-05, 9.9999e-01],\n",
      "        [3.1554e-08, 1.3409e-07, 3.0218e-05, 9.9997e-01],\n",
      "        [3.6871e-09, 9.7944e-08, 8.1373e-06, 9.9999e-01],\n",
      "        [5.4591e-08, 1.9832e-07, 1.0655e-04, 9.9989e-01],\n",
      "        [1.8417e-08, 1.3069e-07, 5.6818e-05, 9.9994e-01],\n",
      "        [7.4429e-09, 2.9527e-08, 6.2345e-06, 9.9999e-01],\n",
      "        [1.3477e-08, 1.6222e-07, 5.4868e-05, 9.9995e-01],\n",
      "        [9.8253e-09, 1.1810e-07, 1.1938e-04, 9.9988e-01],\n",
      "        [2.4027e-08, 1.5679e-07, 1.9183e-05, 9.9998e-01],\n",
      "        [2.0284e-08, 2.0245e-07, 9.2898e-06, 9.9999e-01],\n",
      "        [1.4475e-08, 1.0147e-07, 2.0116e-05, 9.9998e-01],\n",
      "        [6.4536e-09, 1.3204e-07, 9.3868e-06, 9.9999e-01],\n",
      "        [9.3879e-10, 1.2044e-08, 1.2208e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(98.5570) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.4972e-05, 9.9996e-01, 2.2830e-05, 4.6680e-06],\n",
      "        [1.1340e-06, 9.9999e-01, 3.7988e-06, 2.0177e-06],\n",
      "        [1.0670e-05, 9.9995e-01, 3.4899e-05, 3.7377e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9998e-01, 1.2432e-05, 2.5863e-06, 7.2939e-07],\n",
      "        [1.0000e+00, 2.9436e-06, 1.4277e-06, 5.6730e-07],\n",
      "        [9.9999e-01, 4.0336e-06, 1.5827e-06, 4.3785e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[5.0872e-05, 1.4259e-03, 9.9851e-01, 8.9674e-06],\n",
      "        [2.0737e-05, 2.0546e-04, 9.9977e-01, 2.3876e-06],\n",
      "        [2.6393e-05, 7.4488e-04, 9.9922e-01, 3.9803e-06],\n",
      "        [1.0437e-04, 3.5794e-03, 9.9631e-01, 7.3498e-06],\n",
      "        [6.7298e-05, 3.5627e-03, 9.9636e-01, 9.1729e-06],\n",
      "        [2.2441e-04, 3.3715e-03, 9.9640e-01, 7.1187e-06],\n",
      "        [6.8718e-05, 4.7254e-03, 9.9520e-01, 6.4947e-06],\n",
      "        [3.4036e-04, 6.1111e-03, 9.9353e-01, 1.4637e-05],\n",
      "        [2.7094e-05, 3.9882e-04, 9.9957e-01, 3.8179e-06],\n",
      "        [6.1524e-05, 7.8583e-04, 9.9915e-01, 4.0578e-06],\n",
      "        [1.3650e-05, 3.4369e-04, 9.9964e-01, 3.7583e-06],\n",
      "        [5.4553e-05, 6.7157e-04, 9.9927e-01, 2.7803e-06],\n",
      "        [4.6938e-05, 9.5654e-04, 9.9899e-01, 3.3337e-06],\n",
      "        [2.4203e-05, 5.5122e-04, 9.9942e-01, 1.1922e-06],\n",
      "        [1.5493e-04, 3.2676e-04, 9.9951e-01, 3.4031e-06],\n",
      "        [2.7986e-05, 2.1641e-03, 9.9781e-01, 2.6779e-06],\n",
      "        [3.7575e-04, 6.3664e-03, 9.9323e-01, 3.1003e-05],\n",
      "        [9.0575e-05, 1.1954e-03, 9.9871e-01, 4.7719e-06],\n",
      "        [5.7880e-05, 1.0688e-03, 9.9887e-01, 2.6164e-06],\n",
      "        [1.7324e-04, 3.7143e-03, 9.9611e-01, 3.4522e-06],\n",
      "        [2.6826e-05, 7.1639e-04, 9.9925e-01, 3.9899e-06],\n",
      "        [3.9418e-05, 1.7141e-03, 9.9824e-01, 3.3778e-06],\n",
      "        [3.7604e-05, 1.7875e-03, 9.9817e-01, 9.1490e-06],\n",
      "        [1.8688e-04, 7.7044e-03, 9.9208e-01, 3.3010e-05],\n",
      "        [5.3840e-05, 1.2425e-03, 9.9870e-01, 7.8799e-06],\n",
      "        [3.3606e-04, 4.8514e-03, 9.9480e-01, 1.6812e-05],\n",
      "        [1.5172e-05, 1.9933e-04, 9.9978e-01, 1.7839e-06],\n",
      "        [1.4733e-04, 1.9962e-03, 9.9785e-01, 7.1609e-06],\n",
      "        [7.7260e-05, 3.8993e-03, 9.9602e-01, 2.8843e-06],\n",
      "        [7.0263e-04, 7.0887e-03, 9.9220e-01, 7.9796e-06],\n",
      "        [3.4304e-04, 2.6858e-03, 9.9697e-01, 4.7374e-06],\n",
      "        [2.8778e-05, 6.5487e-04, 9.9931e-01, 3.1019e-06],\n",
      "        [2.2629e-05, 4.4992e-04, 9.9953e-01, 2.0962e-06],\n",
      "        [8.4183e-05, 3.9025e-03, 9.9600e-01, 8.6876e-06],\n",
      "        [1.3603e-04, 1.5492e-03, 9.9831e-01, 7.1472e-06],\n",
      "        [1.6886e-05, 2.7411e-04, 9.9971e-01, 1.6111e-06],\n",
      "        [5.6075e-05, 1.4246e-03, 9.9851e-01, 6.7723e-06],\n",
      "        [1.7256e-04, 4.4642e-03, 9.9535e-01, 1.6615e-05],\n",
      "        [9.1259e-05, 6.6540e-04, 9.9924e-01, 3.8145e-06],\n",
      "        [1.1239e-04, 8.1738e-04, 9.9907e-01, 4.6483e-06],\n",
      "        [3.6691e-05, 4.8660e-04, 9.9947e-01, 2.2550e-06],\n",
      "        [3.3471e-04, 2.9557e-03, 9.9669e-01, 1.5065e-05],\n",
      "        [1.8678e-04, 1.4968e-03, 9.9831e-01, 3.4757e-06],\n",
      "        [3.3655e-05, 5.4596e-04, 9.9942e-01, 2.2434e-06],\n",
      "        [6.8521e-05, 2.0598e-03, 9.9787e-01, 6.5901e-06],\n",
      "        [3.4246e-05, 1.3571e-03, 9.9860e-01, 7.9778e-06],\n",
      "        [7.5109e-06, 2.9593e-04, 9.9969e-01, 1.6910e-06],\n",
      "        [1.0583e-04, 2.6541e-03, 9.9723e-01, 8.0064e-06],\n",
      "        [5.3662e-05, 1.3773e-03, 9.9856e-01, 4.1074e-06],\n",
      "        [3.3172e-05, 1.1746e-03, 9.9879e-01, 3.0235e-06],\n",
      "        [4.0243e-05, 6.0008e-04, 9.9935e-01, 4.8107e-06],\n",
      "        [2.4801e-05, 8.5524e-04, 9.9911e-01, 5.0095e-06],\n",
      "        [2.9205e-05, 5.8063e-04, 9.9938e-01, 5.4504e-06],\n",
      "        [5.8938e-06, 3.5738e-04, 9.9964e-01, 1.0890e-06],\n",
      "        [4.0672e-05, 1.0648e-03, 9.9889e-01, 1.8388e-06],\n",
      "        [1.7419e-04, 3.1895e-03, 9.9663e-01, 4.8477e-06],\n",
      "        [2.3769e-05, 1.0382e-03, 9.9893e-01, 7.5629e-06],\n",
      "        [1.9263e-05, 4.3839e-04, 9.9954e-01, 7.0156e-07],\n",
      "        [1.5242e-04, 1.3402e-03, 9.9850e-01, 4.0486e-06],\n",
      "        [1.0115e-04, 1.4308e-03, 9.9846e-01, 7.9974e-06],\n",
      "        [2.5956e-05, 4.1608e-04, 9.9956e-01, 2.5823e-06],\n",
      "        [7.3061e-05, 3.1660e-03, 9.9675e-01, 7.2234e-06],\n",
      "        [4.0431e-05, 2.0284e-03, 9.9793e-01, 5.9971e-06],\n",
      "        [4.3820e-05, 4.6911e-04, 9.9948e-01, 6.2056e-06],\n",
      "        [2.9750e-04, 1.4453e-03, 9.9825e-01, 7.1749e-06],\n",
      "        [9.9572e-05, 1.0372e-03, 9.9886e-01, 3.5006e-06],\n",
      "        [3.1090e-05, 9.5675e-04, 9.9900e-01, 7.2693e-06],\n",
      "        [1.7924e-04, 8.6715e-03, 9.9114e-01, 1.0896e-05],\n",
      "        [8.9320e-05, 1.1364e-03, 9.9877e-01, 5.3168e-06],\n",
      "        [4.4726e-05, 8.6603e-04, 9.9909e-01, 2.0985e-06],\n",
      "        [8.3729e-06, 3.8068e-04, 9.9961e-01, 3.2731e-06],\n",
      "        [4.1284e-05, 1.8809e-03, 9.9807e-01, 7.7625e-06],\n",
      "        [3.6766e-05, 3.2571e-04, 9.9964e-01, 2.4058e-06],\n",
      "        [1.2770e-04, 3.9307e-03, 9.9593e-01, 9.8964e-06],\n",
      "        [2.3694e-05, 3.9975e-04, 9.9958e-01, 1.3867e-06],\n",
      "        [5.3143e-05, 1.0813e-03, 9.9886e-01, 8.2040e-06],\n",
      "        [1.7006e-04, 5.7726e-03, 9.9403e-01, 2.5626e-05],\n",
      "        [1.8627e-05, 1.4398e-03, 9.9854e-01, 1.9801e-06],\n",
      "        [4.2611e-05, 1.1046e-03, 9.9885e-01, 6.9697e-06],\n",
      "        [2.5696e-04, 5.2570e-03, 9.9447e-01, 1.6491e-05],\n",
      "        [4.3914e-05, 6.0194e-04, 9.9934e-01, 9.6715e-06],\n",
      "        [1.0512e-04, 2.1905e-03, 9.9770e-01, 5.6056e-06],\n",
      "        [2.0203e-05, 6.2168e-04, 9.9935e-01, 5.7830e-06],\n",
      "        [4.5108e-05, 7.8605e-04, 9.9917e-01, 3.1149e-06],\n",
      "        [4.7110e-05, 4.6471e-04, 9.9948e-01, 3.5536e-06],\n",
      "        [7.1851e-05, 7.5354e-04, 9.9917e-01, 3.3156e-06],\n",
      "        [6.0153e-05, 1.3575e-03, 9.9857e-01, 8.6376e-06],\n",
      "        [1.4846e-05, 3.4233e-04, 9.9964e-01, 1.0552e-06],\n",
      "        [6.7990e-05, 6.2869e-04, 9.9930e-01, 6.7648e-06],\n",
      "        [7.0024e-05, 7.2124e-04, 9.9920e-01, 7.1487e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.0803e-09, 5.6226e-08, 2.2871e-05, 9.9998e-01],\n",
      "        [8.9619e-09, 4.8079e-08, 2.0845e-05, 9.9998e-01],\n",
      "        [6.5315e-09, 9.0147e-08, 2.5753e-05, 9.9997e-01],\n",
      "        [3.8998e-09, 4.0644e-08, 5.1494e-06, 9.9999e-01],\n",
      "        [2.9546e-09, 3.7110e-08, 9.9994e-06, 9.9999e-01],\n",
      "        [2.8957e-09, 1.4373e-08, 4.8835e-06, 1.0000e+00],\n",
      "        [3.6859e-09, 4.2672e-08, 3.0805e-05, 9.9997e-01],\n",
      "        [2.4053e-08, 6.1095e-07, 6.4958e-05, 9.9993e-01],\n",
      "        [3.4125e-09, 1.7106e-08, 1.0000e-05, 9.9999e-01],\n",
      "        [4.1045e-09, 7.0001e-08, 3.6793e-06, 1.0000e+00],\n",
      "        [3.8360e-09, 2.9557e-08, 1.3471e-05, 9.9999e-01],\n",
      "        [2.7936e-09, 9.5723e-08, 9.7611e-06, 9.9999e-01],\n",
      "        [1.6766e-08, 1.4783e-07, 8.4001e-05, 9.9992e-01],\n",
      "        [2.4732e-09, 4.1645e-08, 8.9628e-06, 9.9999e-01],\n",
      "        [9.5480e-09, 1.6508e-08, 1.2667e-05, 9.9999e-01],\n",
      "        [1.0104e-08, 1.2908e-07, 2.0679e-05, 9.9998e-01],\n",
      "        [7.2457e-09, 7.9493e-08, 2.6704e-05, 9.9997e-01],\n",
      "        [2.0814e-09, 2.3404e-08, 8.1101e-06, 9.9999e-01],\n",
      "        [4.4716e-09, 4.9117e-08, 1.6288e-05, 9.9998e-01],\n",
      "        [8.5052e-09, 1.8133e-08, 8.1468e-06, 9.9999e-01],\n",
      "        [1.4138e-08, 1.1304e-07, 4.8723e-05, 9.9995e-01],\n",
      "        [7.4891e-09, 5.4395e-08, 5.3059e-05, 9.9995e-01],\n",
      "        [1.8732e-08, 3.6244e-07, 7.0741e-05, 9.9993e-01],\n",
      "        [2.3497e-09, 2.5052e-08, 1.5841e-05, 9.9998e-01],\n",
      "        [1.4507e-09, 4.9821e-08, 1.9226e-06, 1.0000e+00],\n",
      "        [6.9761e-09, 2.5751e-08, 9.0443e-07, 1.0000e+00],\n",
      "        [1.6789e-08, 1.8226e-07, 3.1961e-05, 9.9997e-01],\n",
      "        [1.4407e-09, 1.2891e-08, 5.3708e-07, 1.0000e+00],\n",
      "        [2.9230e-09, 1.0527e-08, 2.0553e-06, 1.0000e+00],\n",
      "        [2.6869e-08, 3.9598e-07, 7.5988e-05, 9.9992e-01],\n",
      "        [1.7369e-08, 8.3377e-08, 2.6583e-05, 9.9997e-01],\n",
      "        [4.2934e-09, 6.1165e-08, 4.9698e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(98.6679) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[5.9193e-07, 9.9999e-01, 5.7887e-06, 1.8960e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9939e-01, 5.8940e-04, 1.7863e-05, 5.1081e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.6123e-05, 1.1625e-04, 9.9987e-01, 9.5334e-07],\n",
      "        [7.7968e-06, 1.4843e-04, 9.9984e-01, 2.1501e-06],\n",
      "        [4.5543e-05, 2.1858e-04, 9.9973e-01, 2.7583e-06],\n",
      "        [9.4432e-06, 8.2805e-05, 9.9991e-01, 9.3591e-07],\n",
      "        [8.5256e-06, 7.6400e-05, 9.9991e-01, 1.3756e-06],\n",
      "        [1.6804e-05, 1.2457e-04, 9.9985e-01, 3.6825e-06],\n",
      "        [1.4452e-05, 2.1269e-04, 9.9977e-01, 3.5224e-06],\n",
      "        [1.0971e-04, 5.5429e-04, 9.9933e-01, 3.4869e-06],\n",
      "        [2.9323e-05, 3.2136e-04, 9.9965e-01, 2.7658e-06],\n",
      "        [1.3113e-05, 1.8336e-04, 9.9980e-01, 1.9132e-06],\n",
      "        [3.8004e-05, 1.8894e-04, 9.9977e-01, 6.5362e-06],\n",
      "        [3.7847e-05, 5.0305e-04, 9.9946e-01, 1.5277e-06],\n",
      "        [1.8183e-04, 7.6470e-04, 9.9905e-01, 3.2315e-06],\n",
      "        [1.2050e-05, 5.5276e-04, 9.9943e-01, 6.9697e-06],\n",
      "        [4.4773e-05, 2.3336e-04, 9.9972e-01, 1.9323e-06],\n",
      "        [3.5464e-05, 3.0990e-04, 9.9965e-01, 1.2272e-06],\n",
      "        [2.1460e-05, 3.2692e-04, 9.9965e-01, 1.4750e-06],\n",
      "        [4.0662e-06, 9.4208e-05, 9.9990e-01, 2.2300e-06],\n",
      "        [1.0820e-05, 5.4613e-04, 9.9944e-01, 2.2449e-06],\n",
      "        [4.0615e-05, 2.8427e-04, 9.9967e-01, 3.1117e-06],\n",
      "        [2.5477e-05, 6.1813e-04, 9.9935e-01, 5.9208e-06],\n",
      "        [6.6165e-06, 1.9861e-04, 9.9979e-01, 2.3120e-06],\n",
      "        [1.1319e-05, 1.6740e-04, 9.9982e-01, 7.6665e-07],\n",
      "        [1.0755e-05, 3.4199e-04, 9.9965e-01, 1.2774e-06],\n",
      "        [6.8189e-06, 5.6513e-05, 9.9994e-01, 9.6436e-07],\n",
      "        [1.2980e-05, 2.2001e-04, 9.9976e-01, 2.5892e-06],\n",
      "        [6.4563e-06, 2.4780e-05, 9.9997e-01, 7.4620e-07],\n",
      "        [1.4477e-05, 1.4987e-04, 9.9983e-01, 2.6262e-06],\n",
      "        [3.7846e-05, 4.4726e-04, 9.9951e-01, 4.8235e-06],\n",
      "        [3.1938e-05, 1.3070e-04, 9.9983e-01, 3.3417e-06],\n",
      "        [7.6931e-06, 4.4102e-05, 9.9995e-01, 1.0515e-06],\n",
      "        [1.7456e-04, 1.8089e-03, 9.9801e-01, 5.3270e-06],\n",
      "        [1.3733e-04, 9.0500e-04, 9.9896e-01, 2.6376e-06],\n",
      "        [2.5086e-05, 1.1467e-04, 9.9986e-01, 2.5248e-06],\n",
      "        [6.9664e-06, 1.0758e-04, 9.9988e-01, 4.5595e-06],\n",
      "        [4.7357e-06, 8.1700e-05, 9.9991e-01, 1.2331e-06],\n",
      "        [1.7879e-05, 2.3850e-04, 9.9974e-01, 1.8041e-06],\n",
      "        [3.9439e-06, 7.5059e-05, 9.9992e-01, 8.5119e-07],\n",
      "        [4.0485e-05, 3.8394e-04, 9.9957e-01, 1.6296e-06],\n",
      "        [5.3219e-05, 9.8076e-04, 9.9896e-01, 3.8866e-06],\n",
      "        [3.3118e-05, 3.8913e-04, 9.9958e-01, 1.0611e-06],\n",
      "        [1.8527e-05, 2.6783e-04, 9.9971e-01, 2.1896e-06],\n",
      "        [3.3853e-05, 3.4032e-04, 9.9962e-01, 3.5153e-06],\n",
      "        [3.1372e-05, 3.1272e-04, 9.9965e-01, 1.3253e-06],\n",
      "        [1.7626e-04, 9.1601e-04, 9.9890e-01, 5.5293e-06],\n",
      "        [1.3007e-05, 1.4680e-04, 9.9984e-01, 2.3426e-06],\n",
      "        [9.5773e-06, 8.3628e-05, 9.9991e-01, 1.6535e-06],\n",
      "        [2.1221e-05, 3.6884e-04, 9.9961e-01, 1.4940e-06],\n",
      "        [1.4837e-05, 2.9312e-04, 9.9969e-01, 4.2741e-06],\n",
      "        [5.7985e-05, 2.8384e-04, 9.9966e-01, 2.7953e-06],\n",
      "        [1.9522e-05, 2.2538e-04, 9.9975e-01, 8.0151e-07],\n",
      "        [5.4591e-05, 5.6556e-04, 9.9938e-01, 4.8631e-06],\n",
      "        [7.1835e-06, 1.9939e-04, 9.9979e-01, 2.5548e-06],\n",
      "        [3.2782e-05, 4.4602e-04, 9.9952e-01, 3.7011e-06],\n",
      "        [1.2133e-05, 1.1469e-04, 9.9987e-01, 4.2357e-06],\n",
      "        [3.3091e-05, 2.4927e-04, 9.9972e-01, 1.5042e-06],\n",
      "        [1.9572e-05, 5.0925e-05, 9.9993e-01, 1.5272e-06],\n",
      "        [2.0066e-05, 1.1507e-04, 9.9986e-01, 1.1719e-06],\n",
      "        [7.7535e-06, 1.8870e-04, 9.9980e-01, 1.4805e-06],\n",
      "        [2.1183e-05, 1.4254e-04, 9.9983e-01, 1.5263e-06],\n",
      "        [1.5032e-05, 8.7257e-05, 9.9990e-01, 1.0494e-06],\n",
      "        [1.1149e-05, 4.5652e-04, 9.9953e-01, 1.4575e-06],\n",
      "        [1.7709e-05, 1.5128e-04, 9.9982e-01, 6.0974e-06],\n",
      "        [5.6824e-05, 8.9853e-04, 9.9904e-01, 5.9251e-06],\n",
      "        [1.5235e-05, 2.1926e-04, 9.9976e-01, 2.9718e-06],\n",
      "        [2.6907e-05, 1.2696e-04, 9.9984e-01, 1.7062e-06],\n",
      "        [1.1406e-04, 9.6721e-04, 9.9891e-01, 4.1989e-06],\n",
      "        [5.0656e-05, 2.7523e-04, 9.9967e-01, 1.4240e-06],\n",
      "        [4.5548e-05, 6.1264e-04, 9.9934e-01, 3.5262e-06],\n",
      "        [6.0506e-05, 8.9931e-04, 9.9903e-01, 5.4714e-06],\n",
      "        [9.5742e-05, 5.2251e-04, 9.9938e-01, 3.4604e-06],\n",
      "        [5.8086e-05, 4.4341e-04, 9.9950e-01, 2.2393e-06],\n",
      "        [5.2827e-05, 5.2043e-04, 9.9942e-01, 4.0464e-06],\n",
      "        [5.0790e-05, 2.2217e-04, 9.9972e-01, 5.8822e-06],\n",
      "        [3.8991e-05, 2.0990e-04, 9.9975e-01, 1.0682e-06],\n",
      "        [1.7344e-05, 1.8173e-04, 9.9980e-01, 2.6106e-06],\n",
      "        [2.8447e-05, 2.2930e-04, 9.9974e-01, 3.0225e-06],\n",
      "        [3.0226e-05, 2.6876e-04, 9.9970e-01, 1.6871e-06],\n",
      "        [1.1009e-05, 9.2563e-05, 9.9989e-01, 2.4537e-06],\n",
      "        [1.0990e-05, 8.8510e-05, 9.9990e-01, 2.5984e-06],\n",
      "        [2.3738e-05, 2.4415e-04, 9.9973e-01, 1.5781e-06],\n",
      "        [3.2897e-05, 1.2957e-04, 9.9984e-01, 1.4590e-06],\n",
      "        [7.7220e-05, 3.8988e-04, 9.9953e-01, 1.2560e-06],\n",
      "        [3.7283e-05, 2.0753e-04, 9.9975e-01, 2.0879e-06],\n",
      "        [1.5558e-04, 8.0012e-04, 9.9904e-01, 7.7625e-06],\n",
      "        [1.3358e-05, 1.1234e-04, 9.9987e-01, 1.4165e-06],\n",
      "        [1.6973e-05, 2.0055e-04, 9.9978e-01, 1.0045e-06],\n",
      "        [1.4385e-05, 2.0129e-04, 9.9978e-01, 2.0076e-06],\n",
      "        [3.8733e-05, 3.4194e-04, 9.9962e-01, 3.1205e-06],\n",
      "        [2.1037e-05, 1.6152e-04, 9.9981e-01, 4.3160e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.9498e-08, 6.6220e-08, 4.1834e-05, 9.9996e-01],\n",
      "        [2.6470e-08, 1.0274e-07, 5.6806e-05, 9.9994e-01],\n",
      "        [5.1575e-09, 9.8797e-09, 8.7007e-06, 9.9999e-01],\n",
      "        [8.7176e-09, 2.6045e-08, 1.2323e-05, 9.9999e-01],\n",
      "        [3.7685e-09, 2.7896e-08, 4.9713e-06, 9.9999e-01],\n",
      "        [5.1072e-09, 3.9502e-08, 3.8912e-06, 1.0000e+00],\n",
      "        [4.6652e-09, 2.9358e-08, 3.0250e-05, 9.9997e-01],\n",
      "        [2.4236e-09, 2.2196e-08, 3.2357e-05, 9.9997e-01],\n",
      "        [9.4023e-09, 2.3571e-07, 7.8785e-05, 9.9992e-01],\n",
      "        [2.8356e-09, 1.7138e-08, 8.9131e-06, 9.9999e-01],\n",
      "        [3.4980e-09, 1.2977e-08, 1.1501e-05, 9.9999e-01],\n",
      "        [4.5153e-08, 1.8618e-07, 5.8267e-05, 9.9994e-01],\n",
      "        [5.4107e-09, 3.8894e-08, 3.0400e-05, 9.9997e-01],\n",
      "        [8.5491e-08, 2.4585e-07, 3.9196e-04, 9.9961e-01],\n",
      "        [3.9667e-09, 1.6485e-08, 2.4633e-05, 9.9998e-01],\n",
      "        [3.2006e-09, 1.9070e-08, 6.4905e-06, 9.9999e-01],\n",
      "        [7.7853e-09, 1.6239e-08, 4.7161e-06, 1.0000e+00],\n",
      "        [1.2536e-08, 1.7235e-08, 1.6576e-05, 9.9998e-01],\n",
      "        [3.1661e-09, 9.1246e-08, 7.4179e-06, 9.9999e-01],\n",
      "        [1.8571e-09, 7.7387e-09, 8.2320e-06, 9.9999e-01],\n",
      "        [6.1013e-09, 1.4078e-08, 5.1307e-05, 9.9995e-01],\n",
      "        [1.9179e-08, 1.0182e-07, 1.8349e-04, 9.9982e-01],\n",
      "        [3.2430e-09, 1.4799e-08, 2.3344e-05, 9.9998e-01],\n",
      "        [1.0279e-08, 3.6301e-08, 3.0611e-05, 9.9997e-01],\n",
      "        [2.5803e-08, 2.8181e-07, 2.0585e-04, 9.9979e-01],\n",
      "        [1.7664e-08, 2.3901e-07, 1.6340e-04, 9.9984e-01],\n",
      "        [3.2519e-09, 5.0773e-08, 5.4341e-05, 9.9995e-01],\n",
      "        [3.5991e-09, 1.6926e-08, 2.0874e-05, 9.9998e-01],\n",
      "        [3.2140e-09, 9.1611e-09, 4.9454e-06, 9.9999e-01],\n",
      "        [2.2120e-08, 5.9404e-08, 2.8052e-04, 9.9972e-01],\n",
      "        [5.9780e-09, 2.9919e-08, 1.1761e-05, 9.9999e-01],\n",
      "        [4.7885e-09, 2.7181e-07, 7.0675e-05, 9.9993e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(99.0016) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.7310e-06, 9.9997e-01, 2.7444e-05, 1.3398e-06],\n",
      "        [3.0434e-06, 9.9996e-01, 3.4060e-05, 3.5147e-06],\n",
      "        [4.3009e-06, 9.9998e-01, 9.9885e-06, 4.3119e-06],\n",
      "        [5.1919e-04, 9.9892e-01, 5.5865e-04, 4.7238e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 7.3983e-07, 9.0947e-07, 1.5954e-07],\n",
      "        [9.9996e-01, 3.4757e-05, 8.5289e-06, 9.6923e-07],\n",
      "        [9.9958e-01, 3.9027e-04, 2.4526e-05, 5.6216e-06],\n",
      "        [9.9977e-01, 2.1373e-04, 1.3051e-05, 1.0299e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.9991e-05, 1.5925e-04, 9.9981e-01, 3.9611e-06],\n",
      "        [1.1329e-05, 2.6089e-04, 9.9972e-01, 3.6314e-06],\n",
      "        [2.3421e-05, 2.8040e-04, 9.9970e-01, 1.0325e-06],\n",
      "        [7.6137e-06, 6.5331e-05, 9.9993e-01, 7.8790e-07],\n",
      "        [6.1765e-05, 5.3490e-04, 9.9940e-01, 3.2996e-06],\n",
      "        [5.9711e-05, 2.4076e-04, 9.9969e-01, 1.0634e-05],\n",
      "        [1.4485e-05, 1.4196e-04, 9.9984e-01, 1.2493e-06],\n",
      "        [2.1603e-05, 2.3632e-04, 9.9974e-01, 1.1126e-06],\n",
      "        [1.1642e-05, 1.8391e-04, 9.9980e-01, 8.8701e-07],\n",
      "        [1.6761e-05, 1.8375e-04, 9.9980e-01, 2.1826e-06],\n",
      "        [1.4099e-05, 2.4787e-04, 9.9974e-01, 2.3030e-06],\n",
      "        [2.1711e-05, 2.2276e-04, 9.9975e-01, 3.1767e-06],\n",
      "        [5.6546e-06, 9.1968e-05, 9.9990e-01, 5.6503e-07],\n",
      "        [1.4386e-05, 9.9527e-05, 9.9988e-01, 1.7186e-06],\n",
      "        [5.2523e-05, 4.2165e-04, 9.9952e-01, 5.8170e-06],\n",
      "        [5.4782e-06, 6.3653e-05, 9.9993e-01, 4.9284e-07],\n",
      "        [5.6790e-05, 4.6852e-04, 9.9947e-01, 5.5637e-06],\n",
      "        [5.7179e-06, 9.6521e-05, 9.9990e-01, 9.8697e-07],\n",
      "        [1.3580e-05, 8.8672e-05, 9.9990e-01, 1.5315e-06],\n",
      "        [9.3521e-06, 1.2501e-04, 9.9986e-01, 3.1462e-06],\n",
      "        [1.5449e-05, 8.1883e-05, 9.9990e-01, 1.8113e-06],\n",
      "        [9.7763e-06, 1.0866e-04, 9.9988e-01, 2.0130e-06],\n",
      "        [1.7021e-05, 3.1936e-04, 9.9966e-01, 2.9431e-06],\n",
      "        [4.3680e-05, 2.3742e-04, 9.9972e-01, 2.7504e-06],\n",
      "        [8.0653e-06, 2.1743e-04, 9.9977e-01, 3.0458e-06],\n",
      "        [2.5413e-05, 2.2473e-04, 9.9975e-01, 2.0210e-06],\n",
      "        [7.5291e-06, 9.4003e-05, 9.9990e-01, 8.6714e-07],\n",
      "        [1.2171e-05, 2.3510e-04, 9.9975e-01, 1.6248e-06],\n",
      "        [1.3295e-05, 6.3752e-05, 9.9992e-01, 8.2414e-07],\n",
      "        [3.0862e-06, 5.8725e-05, 9.9994e-01, 7.9415e-07],\n",
      "        [2.0494e-05, 1.6858e-04, 9.9981e-01, 3.3210e-06],\n",
      "        [2.7349e-05, 1.7048e-04, 9.9980e-01, 2.8568e-06],\n",
      "        [3.5487e-05, 3.8263e-04, 9.9957e-01, 7.3505e-06],\n",
      "        [5.9822e-05, 2.4122e-04, 9.9970e-01, 3.2712e-06],\n",
      "        [1.0588e-05, 3.0101e-04, 9.9968e-01, 5.0053e-06],\n",
      "        [4.4932e-06, 6.9682e-05, 9.9992e-01, 1.2548e-06],\n",
      "        [6.6849e-05, 4.7200e-04, 9.9946e-01, 2.0957e-06],\n",
      "        [1.0073e-05, 9.0729e-05, 9.9990e-01, 5.9725e-07],\n",
      "        [3.2213e-05, 3.7423e-04, 9.9959e-01, 6.4351e-06],\n",
      "        [9.7154e-06, 1.5632e-04, 9.9983e-01, 1.1230e-06],\n",
      "        [4.0568e-05, 2.6589e-04, 9.9969e-01, 2.6861e-06],\n",
      "        [1.0501e-05, 6.5761e-05, 9.9992e-01, 7.5777e-07],\n",
      "        [5.4815e-06, 3.4970e-05, 9.9996e-01, 1.1674e-06],\n",
      "        [1.2013e-04, 6.8221e-04, 9.9919e-01, 5.2367e-06],\n",
      "        [2.4744e-05, 1.7699e-04, 9.9980e-01, 1.2012e-06],\n",
      "        [3.3053e-05, 1.6407e-04, 9.9980e-01, 1.2716e-06],\n",
      "        [2.1064e-05, 2.2790e-04, 9.9975e-01, 2.4093e-06],\n",
      "        [5.0630e-06, 6.2572e-05, 9.9993e-01, 6.5533e-07],\n",
      "        [1.5752e-04, 1.6427e-03, 9.9820e-01, 4.1328e-06],\n",
      "        [1.1590e-05, 9.3196e-05, 9.9989e-01, 7.5959e-07],\n",
      "        [2.7641e-05, 1.6780e-04, 9.9980e-01, 1.7437e-06],\n",
      "        [5.2985e-05, 2.9762e-04, 9.9965e-01, 2.3828e-06],\n",
      "        [2.8764e-04, 1.1281e-03, 9.9857e-01, 1.2909e-05],\n",
      "        [9.2967e-06, 6.4070e-05, 9.9992e-01, 2.5246e-06],\n",
      "        [3.1478e-05, 9.3610e-05, 9.9987e-01, 3.4247e-06],\n",
      "        [9.2032e-06, 1.2533e-04, 9.9986e-01, 9.9448e-07],\n",
      "        [9.9269e-06, 8.6393e-05, 9.9990e-01, 8.1326e-07],\n",
      "        [3.8433e-05, 5.7674e-04, 9.9938e-01, 5.9830e-06],\n",
      "        [5.2295e-05, 3.1004e-04, 9.9963e-01, 2.7664e-06],\n",
      "        [1.9432e-05, 1.2938e-04, 9.9985e-01, 2.1365e-06],\n",
      "        [9.6965e-05, 1.0386e-03, 9.9886e-01, 5.5384e-06],\n",
      "        [6.5532e-06, 1.8657e-04, 9.9981e-01, 8.4756e-07],\n",
      "        [3.7826e-06, 4.1590e-05, 9.9995e-01, 1.1147e-06],\n",
      "        [4.0539e-05, 2.2200e-04, 9.9974e-01, 1.9790e-06],\n",
      "        [1.1840e-05, 8.4493e-05, 9.9990e-01, 8.8914e-07],\n",
      "        [3.5433e-05, 3.1976e-04, 9.9964e-01, 4.4778e-06],\n",
      "        [1.4724e-04, 1.1501e-03, 9.9870e-01, 5.4980e-06],\n",
      "        [1.4725e-05, 1.0176e-04, 9.9988e-01, 1.9421e-06],\n",
      "        [2.0840e-05, 1.1144e-04, 9.9987e-01, 1.8181e-06],\n",
      "        [1.8115e-05, 2.7838e-04, 9.9970e-01, 5.8224e-07],\n",
      "        [3.8474e-06, 3.5030e-05, 9.9996e-01, 6.2905e-07],\n",
      "        [7.7873e-06, 5.9328e-05, 9.9993e-01, 9.5561e-07],\n",
      "        [9.9423e-06, 8.6799e-05, 9.9990e-01, 4.1958e-06],\n",
      "        [2.5507e-06, 3.7681e-05, 9.9996e-01, 4.9687e-07],\n",
      "        [2.8564e-05, 5.2461e-04, 9.9944e-01, 3.5880e-06],\n",
      "        [6.8278e-05, 3.7196e-04, 9.9956e-01, 3.7481e-06],\n",
      "        [1.6190e-05, 1.0926e-04, 9.9987e-01, 9.7381e-07],\n",
      "        [4.3340e-05, 3.0720e-04, 9.9965e-01, 2.6394e-06],\n",
      "        [1.8399e-05, 1.7441e-04, 9.9981e-01, 1.6106e-06],\n",
      "        [1.6962e-05, 1.1128e-04, 9.9987e-01, 1.8485e-06],\n",
      "        [1.2538e-05, 7.1383e-05, 9.9992e-01, 9.8279e-07],\n",
      "        [5.3949e-06, 1.8359e-04, 9.9981e-01, 1.2263e-06],\n",
      "        [3.4181e-05, 3.6758e-04, 9.9959e-01, 4.8269e-06],\n",
      "        [4.4441e-05, 3.4961e-04, 9.9960e-01, 2.2384e-06],\n",
      "        [4.0818e-05, 3.9749e-04, 9.9956e-01, 2.8100e-06],\n",
      "        [3.8020e-06, 7.0279e-05, 9.9993e-01, 5.7851e-07],\n",
      "        [1.1607e-05, 2.9984e-04, 9.9968e-01, 4.3553e-06],\n",
      "        [3.3113e-05, 7.6293e-04, 9.9920e-01, 3.7521e-06],\n",
      "        [5.4911e-05, 3.9892e-04, 9.9954e-01, 4.4443e-06],\n",
      "        [5.8826e-06, 4.4221e-05, 9.9995e-01, 1.9606e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.0891e-09, 5.2755e-08, 8.2259e-05, 9.9992e-01],\n",
      "        [6.2390e-09, 1.1033e-07, 7.6693e-06, 9.9999e-01],\n",
      "        [3.3401e-09, 1.3742e-08, 1.3475e-05, 9.9999e-01],\n",
      "        [2.3395e-09, 2.6974e-08, 2.1117e-05, 9.9998e-01],\n",
      "        [1.7498e-09, 1.8009e-08, 3.5206e-06, 1.0000e+00],\n",
      "        [3.2610e-09, 4.8216e-08, 5.9125e-06, 9.9999e-01],\n",
      "        [1.3427e-08, 7.3441e-08, 3.1349e-05, 9.9997e-01],\n",
      "        [3.6044e-09, 2.4322e-08, 3.6916e-05, 9.9996e-01],\n",
      "        [3.2338e-09, 9.4427e-09, 3.6467e-06, 1.0000e+00],\n",
      "        [9.1862e-09, 7.3958e-08, 1.3806e-05, 9.9999e-01],\n",
      "        [3.0042e-08, 3.5766e-08, 1.2591e-05, 9.9999e-01],\n",
      "        [8.7091e-10, 2.2743e-09, 1.9315e-06, 1.0000e+00],\n",
      "        [2.5031e-09, 2.2724e-08, 9.1143e-06, 9.9999e-01],\n",
      "        [1.9641e-08, 6.7797e-08, 1.1728e-05, 9.9999e-01],\n",
      "        [1.5892e-08, 5.6645e-08, 2.0889e-06, 1.0000e+00],\n",
      "        [2.3759e-09, 2.3820e-08, 2.0195e-06, 1.0000e+00],\n",
      "        [2.6567e-09, 8.1832e-09, 2.3604e-06, 1.0000e+00],\n",
      "        [3.7672e-09, 2.5528e-08, 2.0732e-05, 9.9998e-01],\n",
      "        [1.0541e-08, 4.1532e-08, 1.0812e-05, 9.9999e-01],\n",
      "        [2.8940e-09, 1.4416e-08, 8.8239e-06, 9.9999e-01],\n",
      "        [1.0041e-08, 3.0477e-08, 4.5210e-05, 9.9995e-01],\n",
      "        [1.9794e-09, 1.6888e-08, 8.9340e-07, 1.0000e+00],\n",
      "        [6.2483e-09, 3.6017e-09, 1.0306e-05, 9.9999e-01],\n",
      "        [1.3113e-09, 1.3123e-08, 4.2982e-06, 1.0000e+00],\n",
      "        [2.4312e-09, 2.7218e-08, 4.7909e-06, 1.0000e+00],\n",
      "        [2.0569e-09, 1.3385e-08, 1.2059e-05, 9.9999e-01],\n",
      "        [1.3223e-08, 4.1174e-08, 2.7980e-06, 1.0000e+00],\n",
      "        [5.6083e-09, 8.3645e-09, 4.6200e-06, 1.0000e+00],\n",
      "        [4.3212e-09, 1.8182e-08, 1.9713e-05, 9.9998e-01],\n",
      "        [7.0755e-09, 4.5161e-08, 1.5075e-05, 9.9998e-01],\n",
      "        [2.4844e-09, 2.2394e-08, 1.8810e-05, 9.9998e-01],\n",
      "        [4.1444e-09, 1.6097e-08, 4.9105e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.3156) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.0786e-07, 9.9988e-01, 1.2170e-04, 2.8137e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.5136e-07, 3.3532e-07, 3.9074e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[4.3943e-07, 2.1186e-04, 9.9979e-01, 2.4648e-06],\n",
      "        [4.2621e-08, 3.2929e-05, 9.9997e-01, 1.2945e-06],\n",
      "        [6.5510e-08, 4.0149e-05, 9.9996e-01, 3.2726e-06],\n",
      "        [1.9617e-07, 3.8074e-05, 9.9996e-01, 1.1441e-06],\n",
      "        [1.3588e-07, 1.1208e-04, 9.9988e-01, 3.4951e-06],\n",
      "        [2.6852e-07, 5.0877e-05, 9.9995e-01, 1.4943e-06],\n",
      "        [9.4251e-08, 4.9811e-05, 9.9995e-01, 8.7827e-07],\n",
      "        [2.3099e-07, 9.8722e-05, 9.9990e-01, 2.5219e-06],\n",
      "        [9.1645e-08, 7.1193e-05, 9.9993e-01, 1.8216e-06],\n",
      "        [9.3155e-07, 3.8184e-05, 9.9996e-01, 1.2985e-06],\n",
      "        [6.1665e-08, 8.1848e-05, 9.9992e-01, 1.8025e-06],\n",
      "        [7.8260e-08, 5.5824e-05, 9.9994e-01, 1.1053e-06],\n",
      "        [6.8317e-07, 1.3955e-04, 9.9986e-01, 2.3643e-06],\n",
      "        [2.9271e-07, 8.3112e-05, 9.9991e-01, 1.7727e-06],\n",
      "        [3.4513e-07, 6.8756e-04, 9.9931e-01, 3.7373e-06],\n",
      "        [7.3037e-08, 3.7518e-05, 9.9996e-01, 4.6359e-06],\n",
      "        [9.6544e-08, 4.2315e-05, 9.9995e-01, 2.5669e-06],\n",
      "        [1.3918e-07, 4.3134e-05, 9.9996e-01, 1.6490e-06],\n",
      "        [1.1154e-07, 5.8471e-05, 9.9994e-01, 2.2486e-06],\n",
      "        [5.6361e-07, 6.7371e-05, 9.9993e-01, 9.2735e-07],\n",
      "        [2.1716e-07, 1.1164e-04, 9.9989e-01, 1.1452e-06],\n",
      "        [6.8462e-07, 3.7199e-04, 9.9963e-01, 2.1818e-06],\n",
      "        [2.7164e-07, 4.0868e-05, 9.9996e-01, 7.0500e-07],\n",
      "        [5.2505e-07, 1.9404e-04, 9.9980e-01, 2.1053e-06],\n",
      "        [1.5869e-07, 1.7239e-04, 9.9983e-01, 8.9332e-07],\n",
      "        [1.2808e-07, 2.7491e-05, 9.9997e-01, 1.2753e-06],\n",
      "        [1.0054e-07, 3.8838e-05, 9.9996e-01, 1.4985e-06],\n",
      "        [5.5133e-08, 8.6787e-05, 9.9991e-01, 6.8601e-07],\n",
      "        [6.7289e-07, 5.1951e-05, 9.9995e-01, 1.3737e-06],\n",
      "        [4.5321e-08, 7.0728e-05, 9.9993e-01, 6.5020e-07],\n",
      "        [5.1134e-08, 4.2927e-05, 9.9996e-01, 8.4469e-07],\n",
      "        [1.2231e-07, 5.0184e-05, 9.9995e-01, 1.5854e-06],\n",
      "        [1.2302e-07, 1.1716e-04, 9.9988e-01, 1.7340e-06],\n",
      "        [1.9495e-07, 6.3171e-05, 9.9994e-01, 1.0010e-06],\n",
      "        [1.8737e-07, 1.2267e-04, 9.9987e-01, 2.4278e-06],\n",
      "        [1.0245e-07, 4.1143e-05, 9.9996e-01, 2.4238e-06],\n",
      "        [2.0226e-07, 1.3674e-04, 9.9986e-01, 1.7457e-06],\n",
      "        [6.0134e-08, 6.4215e-05, 9.9993e-01, 1.1423e-06],\n",
      "        [2.8632e-07, 5.8990e-05, 9.9994e-01, 2.6913e-06],\n",
      "        [1.4328e-07, 1.1236e-04, 9.9989e-01, 2.3557e-06],\n",
      "        [4.5107e-08, 2.4831e-05, 9.9997e-01, 1.7341e-06],\n",
      "        [7.8296e-08, 1.1358e-04, 9.9988e-01, 2.8462e-06],\n",
      "        [9.9945e-07, 2.1283e-04, 9.9978e-01, 3.6917e-06],\n",
      "        [1.0213e-07, 7.9628e-05, 9.9992e-01, 3.7268e-06],\n",
      "        [8.4559e-08, 2.9408e-05, 9.9997e-01, 3.1256e-06],\n",
      "        [5.8067e-08, 4.6589e-05, 9.9995e-01, 9.8322e-07],\n",
      "        [4.0485e-08, 5.9382e-05, 9.9994e-01, 5.9612e-07],\n",
      "        [1.2689e-07, 1.1346e-04, 9.9988e-01, 2.8934e-06],\n",
      "        [1.6864e-07, 5.9710e-05, 9.9994e-01, 3.2354e-06],\n",
      "        [7.1608e-07, 1.5576e-04, 9.9984e-01, 1.6162e-06],\n",
      "        [6.7901e-08, 5.1177e-05, 9.9995e-01, 1.1946e-06],\n",
      "        [1.0510e-07, 4.6846e-05, 9.9995e-01, 8.8744e-07],\n",
      "        [6.6521e-08, 3.2728e-05, 9.9997e-01, 7.7202e-07],\n",
      "        [1.7742e-07, 7.4280e-05, 9.9992e-01, 4.0621e-06],\n",
      "        [1.7894e-07, 7.4692e-05, 9.9992e-01, 8.7623e-07],\n",
      "        [6.8570e-08, 1.1100e-04, 9.9989e-01, 1.7853e-06],\n",
      "        [1.8153e-07, 1.8503e-04, 9.9981e-01, 2.8251e-06],\n",
      "        [3.8727e-07, 5.1074e-05, 9.9995e-01, 2.2416e-06],\n",
      "        [2.5966e-07, 6.9457e-05, 9.9993e-01, 3.0758e-06],\n",
      "        [1.5853e-07, 1.2099e-04, 9.9988e-01, 8.5845e-07],\n",
      "        [1.3788e-07, 7.6261e-05, 9.9992e-01, 2.2763e-06],\n",
      "        [3.4973e-08, 4.5088e-05, 9.9995e-01, 8.5597e-07],\n",
      "        [2.5530e-07, 1.5820e-04, 9.9984e-01, 3.0776e-06],\n",
      "        [1.3801e-07, 3.3623e-05, 9.9996e-01, 1.9079e-06],\n",
      "        [3.9288e-07, 1.4803e-04, 9.9985e-01, 3.2547e-06],\n",
      "        [2.5006e-07, 1.2105e-04, 9.9987e-01, 4.9458e-06],\n",
      "        [2.5101e-08, 4.3652e-05, 9.9995e-01, 1.8870e-06],\n",
      "        [6.8646e-08, 1.3549e-04, 9.9986e-01, 1.8665e-06],\n",
      "        [2.4047e-07, 1.6751e-04, 9.9983e-01, 2.5575e-06],\n",
      "        [2.2099e-07, 1.4302e-04, 9.9985e-01, 3.4530e-06],\n",
      "        [6.5575e-08, 1.4090e-04, 9.9986e-01, 3.5250e-06],\n",
      "        [6.6385e-07, 2.3295e-04, 9.9976e-01, 2.9947e-06],\n",
      "        [1.4506e-07, 9.0570e-05, 9.9991e-01, 1.7246e-06],\n",
      "        [2.3447e-07, 6.0613e-05, 9.9993e-01, 4.2340e-06],\n",
      "        [8.3098e-08, 8.3849e-05, 9.9991e-01, 2.3964e-06],\n",
      "        [1.5155e-07, 3.2927e-05, 9.9997e-01, 1.0736e-06],\n",
      "        [3.8836e-08, 5.2693e-05, 9.9995e-01, 9.9889e-07],\n",
      "        [1.0664e-07, 1.0282e-04, 9.9989e-01, 2.5527e-06],\n",
      "        [1.1857e-07, 1.0566e-04, 9.9989e-01, 1.9908e-06],\n",
      "        [1.4821e-07, 8.7576e-05, 9.9991e-01, 2.4998e-06],\n",
      "        [1.3184e-07, 7.7439e-05, 9.9992e-01, 1.4021e-06],\n",
      "        [1.2205e-07, 1.1272e-04, 9.9989e-01, 1.9593e-06],\n",
      "        [7.9781e-08, 5.8952e-05, 9.9994e-01, 1.1333e-06],\n",
      "        [2.0447e-07, 4.1927e-05, 9.9996e-01, 1.1900e-06],\n",
      "        [1.9088e-07, 1.1951e-04, 9.9988e-01, 2.3724e-06],\n",
      "        [2.4646e-06, 4.0262e-04, 9.9959e-01, 2.2667e-06],\n",
      "        [2.7214e-07, 5.6530e-05, 9.9994e-01, 1.4119e-06],\n",
      "        [7.7753e-08, 1.3889e-04, 9.9986e-01, 8.9713e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.4440e-09, 1.1504e-07, 1.7569e-05, 9.9998e-01],\n",
      "        [2.7281e-09, 5.3171e-08, 2.4675e-05, 9.9998e-01],\n",
      "        [2.6388e-09, 3.2839e-07, 6.5253e-05, 9.9993e-01],\n",
      "        [4.9501e-09, 5.0691e-08, 1.5619e-05, 9.9998e-01],\n",
      "        [4.4463e-09, 1.8975e-07, 1.6027e-04, 9.9984e-01],\n",
      "        [3.3742e-09, 2.2244e-08, 4.3698e-06, 1.0000e+00],\n",
      "        [1.5130e-09, 5.1978e-08, 1.3592e-05, 9.9999e-01],\n",
      "        [9.7625e-10, 1.2997e-08, 3.4755e-06, 1.0000e+00],\n",
      "        [3.7888e-10, 1.1569e-08, 7.0475e-07, 1.0000e+00],\n",
      "        [2.2514e-09, 6.3483e-08, 8.4015e-06, 9.9999e-01],\n",
      "        [1.9889e-09, 6.7970e-08, 2.4833e-06, 1.0000e+00],\n",
      "        [3.5634e-09, 2.4037e-08, 7.6766e-06, 9.9999e-01],\n",
      "        [1.6097e-09, 1.6523e-08, 2.1331e-06, 1.0000e+00],\n",
      "        [1.1449e-09, 8.5448e-08, 8.6610e-06, 9.9999e-01],\n",
      "        [1.7439e-09, 4.1461e-08, 5.9378e-06, 9.9999e-01],\n",
      "        [3.8235e-09, 3.5905e-07, 1.7553e-05, 9.9998e-01],\n",
      "        [1.5116e-09, 3.4216e-08, 6.0119e-06, 9.9999e-01],\n",
      "        [7.4293e-09, 1.3635e-07, 6.2402e-05, 9.9994e-01],\n",
      "        [1.9100e-09, 4.6815e-08, 3.9384e-06, 1.0000e+00],\n",
      "        [9.4222e-10, 3.3291e-08, 1.8432e-05, 9.9998e-01],\n",
      "        [6.8878e-10, 3.5585e-08, 5.6600e-06, 9.9999e-01],\n",
      "        [3.0421e-09, 9.6496e-08, 1.1091e-05, 9.9999e-01],\n",
      "        [9.2215e-10, 1.5799e-08, 7.2835e-06, 9.9999e-01],\n",
      "        [3.7870e-09, 1.6420e-07, 1.5515e-05, 9.9998e-01],\n",
      "        [4.6132e-09, 2.8757e-08, 2.5924e-06, 1.0000e+00],\n",
      "        [6.9640e-09, 3.3129e-07, 2.6028e-05, 9.9997e-01],\n",
      "        [1.0830e-09, 1.1738e-08, 7.6608e-06, 9.9999e-01],\n",
      "        [3.4897e-09, 6.2778e-08, 1.4101e-05, 9.9999e-01],\n",
      "        [1.9489e-09, 4.8699e-08, 2.1085e-05, 9.9998e-01],\n",
      "        [3.5365e-09, 4.9153e-08, 2.1857e-06, 1.0000e+00],\n",
      "        [2.1692e-09, 1.9399e-08, 2.3565e-06, 1.0000e+00],\n",
      "        [2.3772e-09, 1.6854e-08, 2.4950e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(98.3671) tokens processed per second.\n",
      "Discriminator loss: tensor([[7.5160e-07, 1.0000e+00, 1.5653e-06, 2.2605e-06],\n",
      "        [7.9618e-07, 1.0000e+00, 1.2659e-06, 2.2160e-06],\n",
      "        [1.6314e-07, 1.0000e+00, 3.3135e-07, 1.6570e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.8233e-07, 4.1167e-08, 1.4420e-07],\n",
      "        [9.9998e-01, 1.4578e-05, 1.4798e-07, 1.8188e-06],\n",
      "        [9.9997e-01, 3.2285e-05, 1.3934e-07, 1.1579e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[6.4974e-06, 8.0853e-04, 9.9916e-01, 2.3668e-05],\n",
      "        [3.7186e-05, 1.4582e-03, 9.9848e-01, 2.1630e-05],\n",
      "        [8.0650e-06, 8.9013e-04, 9.9909e-01, 1.3673e-05],\n",
      "        [2.8217e-05, 1.9504e-03, 9.9795e-01, 7.3537e-05],\n",
      "        [5.1645e-06, 4.4961e-04, 9.9954e-01, 8.7579e-06],\n",
      "        [9.3607e-06, 6.7841e-04, 9.9930e-01, 1.6117e-05],\n",
      "        [3.1452e-05, 7.8544e-04, 9.9916e-01, 1.9443e-05],\n",
      "        [5.6247e-06, 2.2491e-04, 9.9976e-01, 1.0573e-05],\n",
      "        [1.1825e-05, 4.8219e-04, 9.9949e-01, 1.5049e-05],\n",
      "        [7.9869e-06, 3.0680e-04, 9.9967e-01, 1.4962e-05],\n",
      "        [1.6049e-05, 7.4983e-04, 9.9921e-01, 2.0123e-05],\n",
      "        [2.2917e-05, 8.1613e-04, 9.9914e-01, 2.0326e-05],\n",
      "        [6.1702e-06, 2.6225e-04, 9.9972e-01, 8.1938e-06],\n",
      "        [7.4747e-06, 2.7939e-04, 9.9968e-01, 3.0476e-05],\n",
      "        [5.9881e-06, 8.9962e-04, 9.9908e-01, 1.2995e-05],\n",
      "        [2.1278e-05, 1.1761e-03, 9.9876e-01, 3.9937e-05],\n",
      "        [4.8927e-06, 1.8642e-04, 9.9980e-01, 1.2853e-05],\n",
      "        [2.8378e-06, 3.1062e-04, 9.9968e-01, 1.0498e-05],\n",
      "        [1.3580e-05, 1.9539e-03, 9.9800e-01, 3.1335e-05],\n",
      "        [4.8127e-06, 2.6859e-04, 9.9972e-01, 9.4476e-06],\n",
      "        [2.9103e-05, 1.5270e-03, 9.9840e-01, 4.4140e-05],\n",
      "        [6.3900e-06, 3.2093e-04, 9.9966e-01, 9.7055e-06],\n",
      "        [2.6231e-05, 4.9489e-04, 9.9946e-01, 2.1405e-05],\n",
      "        [7.9027e-06, 3.6163e-04, 9.9961e-01, 1.8234e-05],\n",
      "        [7.3305e-06, 4.6967e-04, 9.9951e-01, 1.4501e-05],\n",
      "        [3.6918e-06, 3.0070e-04, 9.9968e-01, 1.2907e-05],\n",
      "        [3.6755e-06, 1.9538e-04, 9.9977e-01, 3.2493e-05],\n",
      "        [1.1760e-05, 5.9478e-04, 9.9939e-01, 6.9053e-06],\n",
      "        [1.0909e-05, 5.1233e-04, 9.9946e-01, 1.5343e-05],\n",
      "        [7.8500e-06, 4.8474e-04, 9.9949e-01, 1.5274e-05],\n",
      "        [3.8403e-06, 5.0704e-04, 9.9947e-01, 1.9714e-05],\n",
      "        [3.0408e-06, 2.0884e-04, 9.9977e-01, 1.5429e-05],\n",
      "        [6.5247e-06, 3.7189e-04, 9.9960e-01, 2.4211e-05],\n",
      "        [9.5473e-06, 1.3842e-03, 9.9855e-01, 5.8598e-05],\n",
      "        [1.7424e-05, 4.6441e-04, 9.9950e-01, 1.7945e-05],\n",
      "        [1.0939e-05, 6.0916e-04, 9.9936e-01, 1.9610e-05],\n",
      "        [3.2639e-05, 1.0026e-03, 9.9892e-01, 4.8131e-05],\n",
      "        [4.5784e-06, 6.0882e-04, 9.9936e-01, 2.3497e-05],\n",
      "        [1.9814e-05, 3.4470e-04, 9.9961e-01, 2.8561e-05],\n",
      "        [3.9292e-06, 3.8840e-04, 9.9959e-01, 1.8090e-05],\n",
      "        [1.2063e-05, 7.2493e-04, 9.9925e-01, 1.7779e-05],\n",
      "        [2.2824e-05, 4.2271e-04, 9.9954e-01, 1.7587e-05],\n",
      "        [1.1171e-05, 9.4086e-04, 9.9902e-01, 2.9253e-05],\n",
      "        [9.2259e-06, 6.9891e-04, 9.9927e-01, 1.8538e-05],\n",
      "        [2.6193e-05, 6.9749e-04, 9.9922e-01, 5.3767e-05],\n",
      "        [7.5805e-06, 2.1024e-04, 9.9976e-01, 1.8537e-05],\n",
      "        [1.2844e-05, 6.1480e-04, 9.9935e-01, 2.6286e-05],\n",
      "        [1.3314e-05, 2.8592e-04, 9.9969e-01, 1.4039e-05],\n",
      "        [1.0397e-05, 2.6594e-04, 9.9971e-01, 1.3867e-05],\n",
      "        [4.6855e-06, 4.2842e-04, 9.9956e-01, 8.1638e-06],\n",
      "        [4.0408e-06, 1.7381e-04, 9.9981e-01, 1.3077e-05],\n",
      "        [3.1329e-05, 2.1138e-03, 9.9778e-01, 7.0497e-05],\n",
      "        [1.5338e-05, 1.4068e-03, 9.9856e-01, 2.1572e-05],\n",
      "        [8.1763e-06, 3.1232e-04, 9.9965e-01, 2.4967e-05],\n",
      "        [1.7651e-05, 5.8642e-04, 9.9936e-01, 4.0864e-05],\n",
      "        [1.1806e-05, 9.8071e-04, 9.9898e-01, 2.8398e-05],\n",
      "        [5.5500e-06, 1.8429e-03, 9.9809e-01, 6.4104e-05],\n",
      "        [8.0106e-06, 7.1209e-04, 9.9926e-01, 1.5428e-05],\n",
      "        [2.5251e-05, 7.9154e-04, 9.9916e-01, 2.4271e-05],\n",
      "        [2.4163e-06, 4.7232e-04, 9.9950e-01, 2.3317e-05],\n",
      "        [9.1105e-06, 4.4904e-04, 9.9953e-01, 9.0922e-06],\n",
      "        [7.1614e-06, 2.8237e-04, 9.9970e-01, 9.7420e-06],\n",
      "        [9.5261e-06, 8.2643e-04, 9.9915e-01, 1.0181e-05],\n",
      "        [1.5670e-05, 1.2341e-03, 9.9873e-01, 1.9680e-05],\n",
      "        [6.5217e-06, 5.5081e-04, 9.9942e-01, 2.6147e-05],\n",
      "        [5.3315e-05, 2.2064e-03, 9.9769e-01, 5.3021e-05],\n",
      "        [1.1358e-05, 3.5220e-04, 9.9963e-01, 9.7115e-06],\n",
      "        [1.1296e-05, 4.1827e-04, 9.9953e-01, 4.0067e-05],\n",
      "        [4.1901e-06, 4.8405e-04, 9.9950e-01, 1.1858e-05],\n",
      "        [3.4323e-06, 2.2508e-04, 9.9976e-01, 1.1045e-05],\n",
      "        [6.0088e-06, 1.7269e-04, 9.9981e-01, 1.0154e-05],\n",
      "        [8.9040e-06, 1.0376e-03, 9.9893e-01, 2.1133e-05],\n",
      "        [3.7494e-06, 1.2402e-04, 9.9986e-01, 1.4968e-05],\n",
      "        [3.1369e-05, 2.5237e-03, 9.9742e-01, 2.2671e-05],\n",
      "        [1.3770e-05, 9.1767e-04, 9.9904e-01, 2.6537e-05],\n",
      "        [1.1890e-05, 1.4289e-03, 9.9854e-01, 1.6673e-05],\n",
      "        [8.7988e-06, 2.6124e-04, 9.9972e-01, 9.1869e-06],\n",
      "        [1.0609e-05, 4.6763e-04, 9.9951e-01, 1.2484e-05],\n",
      "        [1.6728e-05, 5.5605e-04, 9.9940e-01, 2.4759e-05],\n",
      "        [1.8996e-05, 5.7157e-04, 9.9937e-01, 3.6333e-05],\n",
      "        [5.0814e-06, 2.8141e-04, 9.9969e-01, 1.9294e-05],\n",
      "        [4.5659e-06, 9.2638e-04, 9.9905e-01, 2.3671e-05],\n",
      "        [1.6700e-05, 5.3079e-04, 9.9943e-01, 1.9442e-05],\n",
      "        [1.6999e-05, 1.6511e-03, 9.9825e-01, 8.2070e-05],\n",
      "        [8.6461e-06, 3.3737e-04, 9.9964e-01, 1.7399e-05],\n",
      "        [1.3194e-05, 5.8251e-04, 9.9939e-01, 1.3808e-05],\n",
      "        [6.7290e-06, 4.4726e-04, 9.9953e-01, 1.2293e-05],\n",
      "        [1.5671e-04, 4.5479e-03, 9.9518e-01, 1.1519e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.9288e-09, 9.8426e-08, 2.1555e-05, 9.9998e-01],\n",
      "        [5.5773e-09, 8.0601e-08, 7.5615e-06, 9.9999e-01],\n",
      "        [2.6901e-09, 7.8607e-08, 5.8100e-06, 9.9999e-01],\n",
      "        [6.4093e-08, 5.5682e-07, 5.7713e-05, 9.9994e-01],\n",
      "        [2.9937e-09, 1.3273e-08, 1.1595e-06, 1.0000e+00],\n",
      "        [1.8316e-08, 7.5256e-08, 4.0607e-06, 1.0000e+00],\n",
      "        [7.9801e-09, 1.0470e-07, 3.8778e-05, 9.9996e-01],\n",
      "        [5.2128e-09, 5.5937e-08, 2.2109e-06, 1.0000e+00],\n",
      "        [6.4182e-08, 1.2078e-06, 2.6232e-04, 9.9974e-01],\n",
      "        [1.0522e-08, 6.3443e-08, 1.0689e-05, 9.9999e-01],\n",
      "        [1.2749e-08, 7.1068e-08, 1.4122e-06, 1.0000e+00],\n",
      "        [5.0856e-09, 6.3095e-08, 7.0851e-06, 9.9999e-01],\n",
      "        [5.9332e-09, 3.4390e-08, 2.3524e-05, 9.9998e-01],\n",
      "        [1.7626e-08, 1.5861e-07, 2.1268e-05, 9.9998e-01],\n",
      "        [1.7729e-08, 4.2320e-07, 1.1578e-04, 9.9988e-01],\n",
      "        [6.0640e-09, 1.0660e-07, 7.7701e-06, 9.9999e-01],\n",
      "        [3.1984e-09, 1.6501e-07, 9.8271e-06, 9.9999e-01],\n",
      "        [1.9397e-08, 1.4117e-07, 1.6428e-05, 9.9998e-01],\n",
      "        [1.2273e-09, 1.3522e-08, 1.7050e-06, 1.0000e+00],\n",
      "        [2.7231e-08, 2.8436e-07, 2.7845e-06, 1.0000e+00],\n",
      "        [1.0384e-08, 1.7176e-07, 6.4671e-06, 9.9999e-01],\n",
      "        [6.6289e-09, 1.7141e-07, 2.4031e-05, 9.9998e-01],\n",
      "        [4.7496e-08, 2.2771e-07, 7.4540e-05, 9.9993e-01],\n",
      "        [4.8220e-09, 2.7498e-07, 8.3773e-06, 9.9999e-01],\n",
      "        [2.2783e-09, 7.1928e-08, 7.1232e-06, 9.9999e-01],\n",
      "        [1.0306e-08, 2.9106e-08, 3.8549e-07, 1.0000e+00],\n",
      "        [1.3093e-08, 1.2857e-07, 1.9155e-05, 9.9998e-01],\n",
      "        [1.1920e-08, 1.6320e-07, 6.6862e-06, 9.9999e-01],\n",
      "        [4.3989e-09, 9.6712e-08, 1.3078e-05, 9.9999e-01],\n",
      "        [8.8510e-09, 6.6566e-08, 1.1981e-05, 9.9999e-01],\n",
      "        [1.3368e-08, 9.5522e-08, 1.1748e-05, 9.9999e-01],\n",
      "        [1.0243e-08, 1.2919e-07, 6.9832e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(99.4742) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.7988e-06, 9.9999e-01, 1.6448e-06, 5.4496e-06],\n",
      "        [6.2522e-07, 1.0000e+00, 6.3489e-07, 1.1850e-06],\n",
      "        [2.7529e-07, 1.0000e+00, 4.5580e-07, 1.3128e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9997e-01, 2.7547e-05, 2.1117e-07, 1.2268e-06],\n",
      "        [9.9999e-01, 7.4464e-06, 7.0858e-08, 4.0021e-07],\n",
      "        [9.9991e-01, 7.9318e-05, 3.7585e-07, 7.3616e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[3.1433e-05, 2.4878e-04, 9.9971e-01, 1.1288e-05],\n",
      "        [8.6646e-06, 1.6704e-04, 9.9981e-01, 1.5279e-05],\n",
      "        [8.5852e-06, 3.0572e-04, 9.9967e-01, 1.6737e-05],\n",
      "        [2.7586e-05, 8.1129e-04, 9.9914e-01, 1.9014e-05],\n",
      "        [8.7870e-06, 1.1338e-03, 9.9881e-01, 4.3179e-05],\n",
      "        [2.7483e-05, 4.0048e-04, 9.9954e-01, 3.3267e-05],\n",
      "        [7.7087e-05, 1.6713e-03, 9.9823e-01, 2.5652e-05],\n",
      "        [4.4235e-05, 1.7062e-03, 9.9821e-01, 3.5208e-05],\n",
      "        [6.4162e-06, 6.9257e-04, 9.9929e-01, 1.4093e-05],\n",
      "        [8.4463e-06, 5.4302e-04, 9.9941e-01, 3.4402e-05],\n",
      "        [1.0698e-05, 2.4041e-04, 9.9973e-01, 1.7749e-05],\n",
      "        [6.5911e-06, 5.6399e-04, 9.9940e-01, 3.2692e-05],\n",
      "        [8.1160e-06, 1.1297e-04, 9.9987e-01, 1.3501e-05],\n",
      "        [1.3326e-05, 3.1205e-04, 9.9965e-01, 2.0861e-05],\n",
      "        [1.4534e-05, 5.2487e-04, 9.9943e-01, 2.9797e-05],\n",
      "        [5.9941e-06, 7.1853e-04, 9.9926e-01, 1.1686e-05],\n",
      "        [5.9975e-06, 2.4114e-04, 9.9974e-01, 1.5662e-05],\n",
      "        [3.7899e-06, 2.4215e-04, 9.9974e-01, 1.0078e-05],\n",
      "        [7.5964e-06, 1.8328e-04, 9.9979e-01, 2.0276e-05],\n",
      "        [9.1874e-06, 2.8797e-04, 9.9968e-01, 2.0730e-05],\n",
      "        [7.0884e-06, 3.6876e-04, 9.9961e-01, 1.1107e-05],\n",
      "        [1.0508e-05, 9.6361e-05, 9.9988e-01, 1.1367e-05],\n",
      "        [1.3023e-05, 3.4387e-04, 9.9963e-01, 1.2024e-05],\n",
      "        [9.0706e-06, 3.2401e-04, 9.9965e-01, 1.2643e-05],\n",
      "        [1.1691e-05, 2.1494e-04, 9.9974e-01, 3.3569e-05],\n",
      "        [8.4857e-06, 5.7958e-04, 9.9937e-01, 4.2476e-05],\n",
      "        [1.3691e-05, 9.0642e-04, 9.9905e-01, 2.5273e-05],\n",
      "        [3.1969e-05, 1.0521e-03, 9.9890e-01, 1.1215e-05],\n",
      "        [5.9159e-06, 5.0625e-05, 9.9994e-01, 3.9675e-06],\n",
      "        [7.8145e-06, 3.7350e-04, 9.9960e-01, 1.7239e-05],\n",
      "        [1.7340e-06, 6.4824e-05, 9.9992e-01, 1.6633e-05],\n",
      "        [1.6352e-05, 5.3846e-04, 9.9941e-01, 3.4548e-05],\n",
      "        [5.5274e-06, 3.0674e-04, 9.9968e-01, 7.2047e-06],\n",
      "        [1.2232e-05, 3.3594e-04, 9.9961e-01, 3.9650e-05],\n",
      "        [7.1148e-06, 1.6247e-04, 9.9981e-01, 1.7081e-05],\n",
      "        [1.1462e-05, 4.1501e-04, 9.9955e-01, 2.8393e-05],\n",
      "        [2.7165e-05, 7.4932e-04, 9.9920e-01, 2.3530e-05],\n",
      "        [4.3112e-06, 2.3184e-04, 9.9974e-01, 2.8602e-05],\n",
      "        [1.4927e-05, 8.2096e-04, 9.9912e-01, 4.3223e-05],\n",
      "        [6.0440e-05, 9.3989e-04, 9.9896e-01, 4.3740e-05],\n",
      "        [2.6871e-06, 2.0273e-04, 9.9979e-01, 8.7361e-06],\n",
      "        [1.5782e-05, 6.1658e-04, 9.9935e-01, 1.2956e-05],\n",
      "        [1.0089e-05, 5.4118e-04, 9.9943e-01, 1.6177e-05],\n",
      "        [5.7454e-05, 1.7777e-03, 9.9812e-01, 4.0959e-05],\n",
      "        [1.2614e-05, 8.6881e-04, 9.9909e-01, 2.7705e-05],\n",
      "        [1.1091e-05, 2.3169e-04, 9.9973e-01, 2.4530e-05],\n",
      "        [2.2496e-05, 8.2567e-04, 9.9914e-01, 7.2200e-06],\n",
      "        [3.4314e-06, 1.7260e-04, 9.9981e-01, 1.2492e-05],\n",
      "        [1.3908e-05, 3.9528e-04, 9.9958e-01, 1.2687e-05],\n",
      "        [4.3532e-06, 2.7484e-04, 9.9971e-01, 1.1680e-05],\n",
      "        [4.7105e-06, 1.4756e-04, 9.9984e-01, 1.1808e-05],\n",
      "        [3.8407e-06, 9.8376e-05, 9.9989e-01, 4.1110e-06],\n",
      "        [5.7369e-06, 2.2580e-04, 9.9975e-01, 1.6319e-05],\n",
      "        [5.5795e-06, 1.4993e-04, 9.9983e-01, 1.1119e-05],\n",
      "        [2.1513e-06, 4.5723e-04, 9.9953e-01, 7.8923e-06],\n",
      "        [3.6075e-06, 6.3082e-04, 9.9934e-01, 2.7557e-05],\n",
      "        [8.8833e-06, 7.4838e-04, 9.9923e-01, 1.3893e-05],\n",
      "        [1.1241e-05, 3.0882e-04, 9.9963e-01, 5.0402e-05],\n",
      "        [1.1122e-05, 2.1236e-04, 9.9976e-01, 1.7229e-05],\n",
      "        [6.9535e-06, 2.4145e-04, 9.9974e-01, 1.4433e-05],\n",
      "        [3.0600e-06, 3.1687e-04, 9.9967e-01, 9.7957e-06],\n",
      "        [4.5484e-05, 3.2378e-04, 9.9960e-01, 2.8305e-05],\n",
      "        [7.1103e-06, 1.1720e-04, 9.9987e-01, 5.9158e-06],\n",
      "        [8.1593e-06, 2.9671e-04, 9.9967e-01, 2.8910e-05],\n",
      "        [5.5088e-06, 4.3725e-04, 9.9953e-01, 2.2450e-05],\n",
      "        [4.6048e-06, 2.0444e-04, 9.9977e-01, 2.0235e-05],\n",
      "        [6.0736e-06, 2.2953e-04, 9.9974e-01, 2.9217e-05],\n",
      "        [7.1802e-06, 8.2515e-04, 9.9915e-01, 1.4223e-05],\n",
      "        [3.9523e-06, 1.5370e-04, 9.9983e-01, 1.3720e-05],\n",
      "        [3.5893e-05, 1.1745e-03, 9.9876e-01, 3.2246e-05],\n",
      "        [1.3968e-05, 6.6520e-04, 9.9930e-01, 1.8358e-05],\n",
      "        [5.3980e-06, 1.4772e-04, 9.9982e-01, 2.5255e-05],\n",
      "        [6.0479e-05, 7.1701e-04, 9.9921e-01, 1.6729e-05],\n",
      "        [1.3370e-05, 4.0195e-04, 9.9957e-01, 1.1763e-05],\n",
      "        [2.5746e-06, 1.8381e-04, 9.9981e-01, 7.4235e-06],\n",
      "        [1.1117e-05, 3.4732e-04, 9.9962e-01, 2.1211e-05],\n",
      "        [1.7302e-05, 5.8271e-04, 9.9936e-01, 3.5977e-05],\n",
      "        [1.0665e-06, 6.9588e-05, 9.9992e-01, 4.5620e-06],\n",
      "        [8.3463e-06, 6.7664e-04, 9.9927e-01, 4.4683e-05],\n",
      "        [3.3281e-05, 6.3137e-04, 9.9931e-01, 2.5836e-05],\n",
      "        [1.2999e-05, 3.5217e-04, 9.9961e-01, 2.5971e-05],\n",
      "        [8.0872e-06, 9.7509e-04, 9.9900e-01, 1.2041e-05],\n",
      "        [7.1788e-06, 2.1682e-04, 9.9976e-01, 1.6026e-05],\n",
      "        [4.9770e-06, 4.2985e-04, 9.9955e-01, 1.3904e-05],\n",
      "        [8.0391e-06, 1.3208e-04, 9.9985e-01, 7.2854e-06],\n",
      "        [1.8456e-05, 4.0817e-04, 9.9956e-01, 1.7808e-05],\n",
      "        [4.3960e-06, 6.7809e-04, 9.9928e-01, 4.1828e-05],\n",
      "        [1.6985e-05, 3.5298e-04, 9.9962e-01, 7.2497e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.5567e-09, 1.1531e-07, 1.1021e-05, 9.9999e-01],\n",
      "        [7.6292e-09, 1.5104e-07, 2.6847e-05, 9.9997e-01],\n",
      "        [4.9207e-09, 1.1171e-07, 3.9268e-05, 9.9996e-01],\n",
      "        [6.1499e-09, 1.8186e-07, 4.6896e-05, 9.9995e-01],\n",
      "        [4.3459e-08, 3.7808e-07, 6.2062e-05, 9.9994e-01],\n",
      "        [1.8287e-08, 1.8108e-07, 2.1339e-06, 1.0000e+00],\n",
      "        [7.2622e-09, 1.2878e-07, 1.8268e-05, 9.9998e-01],\n",
      "        [6.6848e-09, 5.1578e-08, 9.2100e-06, 9.9999e-01],\n",
      "        [2.2973e-08, 6.0529e-07, 1.7864e-05, 9.9998e-01],\n",
      "        [5.2034e-08, 5.5441e-08, 1.9309e-05, 9.9998e-01],\n",
      "        [1.0015e-08, 9.2634e-08, 1.0498e-05, 9.9999e-01],\n",
      "        [1.7847e-08, 1.7575e-07, 2.8352e-05, 9.9997e-01],\n",
      "        [7.6211e-09, 1.7382e-08, 1.2786e-05, 9.9999e-01],\n",
      "        [2.0575e-08, 1.2757e-06, 8.9173e-05, 9.9991e-01],\n",
      "        [1.8421e-09, 1.6276e-08, 1.8555e-06, 1.0000e+00],\n",
      "        [6.7880e-09, 2.0924e-08, 1.9262e-06, 1.0000e+00],\n",
      "        [1.8466e-08, 1.3604e-07, 1.8747e-05, 9.9998e-01],\n",
      "        [1.1685e-08, 6.1366e-08, 9.0830e-06, 9.9999e-01],\n",
      "        [5.0315e-09, 6.9778e-08, 9.9852e-06, 9.9999e-01],\n",
      "        [4.9200e-09, 4.5677e-08, 3.2057e-05, 9.9997e-01],\n",
      "        [9.1305e-09, 1.1484e-07, 2.8419e-06, 1.0000e+00],\n",
      "        [5.5080e-09, 3.0656e-08, 3.3670e-06, 1.0000e+00],\n",
      "        [9.9863e-09, 1.0804e-07, 2.8629e-05, 9.9997e-01],\n",
      "        [1.3166e-08, 6.4942e-07, 7.8021e-05, 9.9992e-01],\n",
      "        [8.4135e-09, 2.4262e-07, 3.7251e-05, 9.9996e-01],\n",
      "        [3.7684e-08, 1.6463e-07, 3.6557e-05, 9.9996e-01],\n",
      "        [5.6842e-09, 1.8326e-07, 1.0881e-05, 9.9999e-01],\n",
      "        [1.3320e-08, 7.7388e-08, 3.6932e-05, 9.9996e-01],\n",
      "        [1.6400e-08, 2.3163e-07, 5.6384e-05, 9.9994e-01],\n",
      "        [1.6755e-08, 1.7050e-07, 8.9455e-06, 9.9999e-01],\n",
      "        [5.7698e-09, 2.0695e-07, 4.1419e-05, 9.9996e-01],\n",
      "        [1.1631e-08, 6.1314e-08, 1.1895e-05, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.5746) tokens processed per second.\n",
      "Discriminator loss: tensor([[8.0620e-07, 9.9999e-01, 3.0307e-06, 3.3971e-06],\n",
      "        [7.4863e-06, 9.9998e-01, 9.6146e-06, 4.2033e-06],\n",
      "        [9.3678e-07, 1.0000e+00, 7.4604e-07, 2.4213e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.2742e-07, 9.2509e-09, 5.2614e-08],\n",
      "        [1.0000e+00, 9.0089e-07, 2.0153e-08, 1.1525e-07],\n",
      "        [1.0000e+00, 2.5653e-06, 3.4068e-08, 8.3818e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.1119e-05, 1.3588e-04, 9.9984e-01, 8.1903e-06],\n",
      "        [1.1296e-05, 4.2150e-04, 9.9956e-01, 1.0828e-05],\n",
      "        [4.5764e-05, 6.7759e-04, 9.9925e-01, 2.2170e-05],\n",
      "        [9.0297e-06, 1.0666e-04, 9.9987e-01, 1.2789e-05],\n",
      "        [2.7120e-06, 1.1271e-04, 9.9987e-01, 1.0052e-05],\n",
      "        [3.6451e-05, 5.6183e-04, 9.9938e-01, 2.2214e-05],\n",
      "        [1.8302e-05, 2.6314e-04, 9.9971e-01, 8.6770e-06],\n",
      "        [1.0889e-05, 5.2500e-04, 9.9945e-01, 9.4086e-06],\n",
      "        [1.2208e-05, 1.6440e-04, 9.9981e-01, 1.1841e-05],\n",
      "        [9.8860e-05, 1.0788e-03, 9.9879e-01, 2.9709e-05],\n",
      "        [1.1050e-05, 5.9777e-05, 9.9992e-01, 7.1869e-06],\n",
      "        [2.0117e-06, 5.8325e-05, 9.9992e-01, 1.4830e-05],\n",
      "        [2.7367e-06, 7.9656e-05, 9.9990e-01, 1.3049e-05],\n",
      "        [2.5247e-05, 1.8114e-04, 9.9977e-01, 2.2124e-05],\n",
      "        [6.2277e-06, 2.9271e-04, 9.9969e-01, 1.3610e-05],\n",
      "        [8.6617e-06, 6.7324e-05, 9.9991e-01, 1.6275e-05],\n",
      "        [3.0397e-05, 3.5310e-04, 9.9959e-01, 2.2711e-05],\n",
      "        [4.0424e-06, 1.9949e-04, 9.9979e-01, 3.5147e-06],\n",
      "        [2.2752e-06, 2.8684e-04, 9.9969e-01, 2.1109e-05],\n",
      "        [5.5142e-06, 1.1030e-04, 9.9987e-01, 1.4236e-05],\n",
      "        [4.6606e-06, 1.5869e-04, 9.9983e-01, 7.8858e-06],\n",
      "        [9.5220e-06, 3.2706e-04, 9.9965e-01, 1.0230e-05],\n",
      "        [6.1243e-06, 1.5653e-04, 9.9982e-01, 2.1876e-05],\n",
      "        [1.0889e-05, 1.9029e-04, 9.9979e-01, 1.0424e-05],\n",
      "        [1.1891e-05, 3.5527e-04, 9.9963e-01, 6.2435e-06],\n",
      "        [7.0825e-06, 5.6063e-05, 9.9993e-01, 8.0568e-06],\n",
      "        [9.0061e-06, 1.4469e-04, 9.9984e-01, 3.7213e-06],\n",
      "        [5.1815e-06, 2.1217e-04, 9.9977e-01, 8.7195e-06],\n",
      "        [4.2767e-06, 1.9771e-04, 9.9978e-01, 2.0962e-05],\n",
      "        [5.1789e-06, 2.1591e-04, 9.9976e-01, 1.9441e-05],\n",
      "        [1.1667e-05, 1.1767e-04, 9.9986e-01, 7.1050e-06],\n",
      "        [1.1066e-05, 2.5132e-04, 9.9973e-01, 5.0857e-06],\n",
      "        [8.1971e-06, 1.3452e-04, 9.9985e-01, 6.4795e-06],\n",
      "        [8.8594e-06, 1.6005e-04, 9.9981e-01, 2.1454e-05],\n",
      "        [8.0515e-06, 5.7090e-05, 9.9993e-01, 4.1081e-06],\n",
      "        [4.4506e-06, 2.2832e-04, 9.9975e-01, 1.2290e-05],\n",
      "        [4.4027e-06, 4.4990e-04, 9.9953e-01, 1.4288e-05],\n",
      "        [7.2673e-06, 1.3857e-04, 9.9985e-01, 6.4546e-06],\n",
      "        [5.9250e-06, 1.5259e-04, 9.9983e-01, 1.1758e-05],\n",
      "        [1.9491e-06, 1.1012e-04, 9.9988e-01, 4.6352e-06],\n",
      "        [5.0392e-06, 2.4065e-04, 9.9974e-01, 1.0016e-05],\n",
      "        [3.4156e-06, 2.5815e-04, 9.9973e-01, 1.1120e-05],\n",
      "        [1.0282e-05, 6.4332e-04, 9.9929e-01, 5.2074e-05],\n",
      "        [2.0196e-05, 2.1580e-04, 9.9976e-01, 8.8752e-06],\n",
      "        [5.6492e-06, 1.8785e-04, 9.9979e-01, 1.4786e-05],\n",
      "        [3.4597e-06, 2.3480e-04, 9.9975e-01, 8.7615e-06],\n",
      "        [4.8966e-06, 1.4057e-04, 9.9985e-01, 9.2795e-06],\n",
      "        [8.7009e-06, 3.1890e-04, 9.9966e-01, 1.5835e-05],\n",
      "        [7.2787e-06, 2.0884e-04, 9.9977e-01, 1.1843e-05],\n",
      "        [1.2804e-05, 5.8311e-04, 9.9938e-01, 2.4690e-05],\n",
      "        [3.2523e-06, 1.8890e-04, 9.9980e-01, 6.5832e-06],\n",
      "        [9.5168e-06, 1.7583e-04, 9.9977e-01, 4.9320e-05],\n",
      "        [2.9019e-05, 3.9041e-04, 9.9957e-01, 9.5384e-06],\n",
      "        [8.7932e-06, 2.9175e-04, 9.9969e-01, 9.9937e-06],\n",
      "        [4.3562e-06, 1.8105e-04, 9.9980e-01, 1.7146e-05],\n",
      "        [7.5963e-06, 1.2906e-04, 9.9985e-01, 1.4451e-05],\n",
      "        [7.0768e-06, 5.6577e-04, 9.9939e-01, 3.3329e-05],\n",
      "        [1.4012e-05, 1.1165e-04, 9.9986e-01, 1.7725e-05],\n",
      "        [9.1586e-06, 3.3028e-04, 9.9965e-01, 9.6743e-06],\n",
      "        [5.9389e-06, 3.0356e-04, 9.9967e-01, 2.2112e-05],\n",
      "        [7.1279e-06, 2.1844e-04, 9.9974e-01, 3.2385e-05],\n",
      "        [1.1248e-04, 8.4584e-04, 9.9901e-01, 3.1361e-05],\n",
      "        [1.3004e-05, 1.1009e-04, 9.9986e-01, 1.8799e-05],\n",
      "        [4.4337e-06, 1.4117e-04, 9.9984e-01, 1.3222e-05],\n",
      "        [1.1265e-05, 3.3236e-04, 9.9963e-01, 2.2199e-05],\n",
      "        [6.4422e-06, 3.5427e-04, 9.9962e-01, 1.7302e-05],\n",
      "        [4.3514e-06, 1.0944e-04, 9.9988e-01, 8.7785e-06],\n",
      "        [1.1910e-05, 1.2162e-04, 9.9986e-01, 9.4375e-06],\n",
      "        [8.4271e-06, 3.1367e-04, 9.9966e-01, 1.8018e-05],\n",
      "        [3.6764e-06, 1.9248e-04, 9.9979e-01, 1.4006e-05],\n",
      "        [5.0971e-06, 1.7392e-04, 9.9981e-01, 9.4838e-06],\n",
      "        [3.2842e-05, 2.4358e-04, 9.9970e-01, 2.8221e-05],\n",
      "        [2.5797e-05, 8.0391e-04, 9.9914e-01, 3.2540e-05],\n",
      "        [3.3339e-06, 1.1050e-04, 9.9988e-01, 1.0770e-05],\n",
      "        [2.1643e-05, 3.6505e-04, 9.9957e-01, 4.5449e-05],\n",
      "        [1.5395e-05, 3.2125e-04, 9.9963e-01, 3.3898e-05],\n",
      "        [5.0354e-07, 6.3417e-05, 9.9993e-01, 3.8959e-06],\n",
      "        [9.6635e-06, 1.8006e-04, 9.9980e-01, 7.4738e-06],\n",
      "        [6.9458e-06, 2.5758e-04, 9.9972e-01, 1.8224e-05],\n",
      "        [1.7973e-05, 3.4693e-04, 9.9963e-01, 5.3981e-06],\n",
      "        [7.1639e-06, 4.3965e-04, 9.9954e-01, 1.3491e-05],\n",
      "        [3.4085e-06, 7.2779e-05, 9.9991e-01, 1.3004e-05],\n",
      "        [8.4150e-06, 2.6053e-04, 9.9972e-01, 6.6782e-06],\n",
      "        [4.1604e-06, 2.6552e-04, 9.9971e-01, 1.6058e-05],\n",
      "        [2.1088e-05, 3.4635e-04, 9.9962e-01, 9.2984e-06],\n",
      "        [1.0960e-05, 2.4432e-04, 9.9973e-01, 1.6721e-05],\n",
      "        [5.4728e-06, 1.9821e-04, 9.9977e-01, 2.3018e-05],\n",
      "        [4.2995e-05, 2.8152e-04, 9.9966e-01, 1.1464e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.5269e-09, 5.8084e-08, 1.1089e-05, 9.9999e-01],\n",
      "        [4.9404e-08, 1.7735e-07, 4.3165e-05, 9.9996e-01],\n",
      "        [9.6127e-09, 1.2721e-07, 7.6337e-06, 9.9999e-01],\n",
      "        [1.8240e-09, 2.2290e-08, 1.9498e-07, 1.0000e+00],\n",
      "        [2.1381e-08, 9.6894e-08, 8.1703e-06, 9.9999e-01],\n",
      "        [2.1475e-09, 1.8858e-08, 2.4819e-06, 1.0000e+00],\n",
      "        [1.6833e-08, 1.6245e-07, 1.7976e-05, 9.9998e-01],\n",
      "        [1.5388e-09, 1.2701e-08, 5.2372e-07, 1.0000e+00],\n",
      "        [4.7797e-09, 2.7517e-08, 8.0280e-06, 9.9999e-01],\n",
      "        [1.6474e-08, 9.1636e-08, 1.4752e-06, 1.0000e+00],\n",
      "        [7.6079e-09, 3.0478e-08, 1.1603e-05, 9.9999e-01],\n",
      "        [2.4268e-09, 1.0275e-07, 1.5558e-05, 9.9998e-01],\n",
      "        [3.1715e-09, 5.0194e-08, 3.0311e-06, 1.0000e+00],\n",
      "        [1.9671e-08, 2.6206e-07, 3.6324e-05, 9.9996e-01],\n",
      "        [5.0968e-09, 2.5086e-08, 3.6766e-06, 1.0000e+00],\n",
      "        [3.4273e-09, 5.8310e-08, 3.5388e-06, 1.0000e+00],\n",
      "        [1.8139e-08, 1.4952e-07, 6.3485e-05, 9.9994e-01],\n",
      "        [6.8599e-09, 6.0840e-08, 1.3832e-05, 9.9999e-01],\n",
      "        [1.3365e-09, 3.8512e-09, 6.9154e-08, 1.0000e+00],\n",
      "        [7.1171e-10, 3.1401e-08, 1.8364e-06, 1.0000e+00],\n",
      "        [3.2382e-09, 3.3749e-08, 6.9456e-06, 9.9999e-01],\n",
      "        [2.6435e-08, 5.8134e-08, 1.7271e-05, 9.9998e-01],\n",
      "        [4.3984e-09, 1.9978e-08, 1.5700e-06, 1.0000e+00],\n",
      "        [1.0884e-08, 3.0523e-07, 4.7734e-05, 9.9995e-01],\n",
      "        [1.1889e-08, 9.3879e-08, 6.7972e-06, 9.9999e-01],\n",
      "        [1.1679e-08, 9.4586e-08, 4.9633e-05, 9.9995e-01],\n",
      "        [3.9745e-09, 6.6525e-08, 5.9012e-06, 9.9999e-01],\n",
      "        [4.8746e-09, 1.8438e-08, 3.6200e-06, 1.0000e+00],\n",
      "        [8.4557e-09, 2.6565e-08, 1.4825e-06, 1.0000e+00],\n",
      "        [3.0304e-09, 1.4555e-07, 1.6015e-05, 9.9998e-01],\n",
      "        [1.4512e-08, 7.5272e-08, 5.1335e-05, 9.9995e-01],\n",
      "        [5.2452e-09, 6.2830e-08, 2.5857e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.3885) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[8.1336e-04, 7.8344e-01, 2.1501e-01, 7.3715e-04],\n",
      "        [1.0496e-04, 9.5815e-01, 4.1110e-02, 6.3157e-04],\n",
      "        [1.2692e-04, 9.9770e-01, 2.0324e-03, 1.4249e-04]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.2974e-08, 2.2054e-07, 2.6276e-07],\n",
      "        [9.9999e-01, 1.0207e-06, 1.6407e-06, 2.6055e-06],\n",
      "        [1.0000e+00, 5.6029e-08, 1.0505e-06, 7.9353e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.3757e-06, 1.6971e-06, 9.9999e-01, 7.2604e-06],\n",
      "        [3.6754e-06, 2.4534e-06, 9.9999e-01, 8.4952e-06],\n",
      "        [2.7617e-06, 2.8348e-06, 9.9998e-01, 1.0662e-05],\n",
      "        [8.2050e-07, 1.2959e-06, 9.9999e-01, 4.6778e-06],\n",
      "        [3.2334e-06, 4.1121e-06, 9.9999e-01, 7.4307e-06],\n",
      "        [1.1295e-05, 5.1734e-06, 9.9997e-01, 1.2667e-05],\n",
      "        [1.8554e-06, 2.8327e-06, 9.9999e-01, 2.4563e-06],\n",
      "        [1.8343e-06, 2.6484e-06, 9.9998e-01, 1.0671e-05],\n",
      "        [5.6257e-06, 2.3740e-06, 9.9999e-01, 6.3816e-06],\n",
      "        [2.2841e-06, 1.5020e-06, 9.9999e-01, 3.6387e-06],\n",
      "        [7.5161e-06, 3.4182e-06, 9.9998e-01, 1.3112e-05],\n",
      "        [2.5191e-06, 4.6627e-06, 9.9998e-01, 9.1482e-06],\n",
      "        [3.1022e-06, 2.6811e-06, 9.9999e-01, 8.7909e-06],\n",
      "        [3.5617e-06, 1.8197e-06, 9.9999e-01, 7.1688e-06],\n",
      "        [5.7383e-06, 2.8328e-06, 9.9998e-01, 6.6296e-06],\n",
      "        [2.2417e-06, 2.0952e-06, 9.9998e-01, 1.3845e-05],\n",
      "        [3.0922e-06, 5.0871e-06, 9.9999e-01, 4.7608e-06],\n",
      "        [1.5840e-06, 1.6512e-06, 9.9999e-01, 8.9633e-06],\n",
      "        [6.8749e-07, 1.8019e-06, 9.9999e-01, 4.2824e-06],\n",
      "        [1.4034e-06, 2.5755e-06, 9.9999e-01, 3.9748e-06],\n",
      "        [1.7453e-06, 1.9983e-06, 9.9999e-01, 1.8128e-06],\n",
      "        [2.6516e-06, 2.7620e-06, 9.9999e-01, 6.8905e-06],\n",
      "        [2.7673e-06, 2.1476e-06, 9.9998e-01, 1.6044e-05],\n",
      "        [1.0694e-06, 1.9161e-06, 9.9999e-01, 4.7534e-06],\n",
      "        [3.2348e-06, 2.6659e-06, 9.9999e-01, 4.9890e-06],\n",
      "        [1.3860e-06, 1.6948e-06, 9.9999e-01, 1.1792e-05],\n",
      "        [3.6129e-06, 4.1783e-06, 9.9998e-01, 1.6865e-05],\n",
      "        [2.7648e-05, 1.1009e-05, 9.9995e-01, 7.8791e-06],\n",
      "        [1.6590e-06, 2.8088e-06, 9.9999e-01, 8.3939e-06],\n",
      "        [1.3763e-06, 1.6204e-06, 9.9999e-01, 1.0454e-05],\n",
      "        [1.2579e-06, 2.2210e-06, 9.9999e-01, 4.0317e-06],\n",
      "        [2.1383e-06, 1.7672e-06, 9.9999e-01, 1.0098e-05],\n",
      "        [3.3815e-06, 2.4223e-06, 9.9999e-01, 5.5366e-06],\n",
      "        [9.0976e-06, 5.1547e-06, 9.9997e-01, 1.4460e-05],\n",
      "        [1.2742e-06, 2.1183e-06, 9.9999e-01, 3.6017e-06],\n",
      "        [1.1928e-06, 2.0672e-06, 9.9999e-01, 5.5641e-06],\n",
      "        [9.6919e-06, 8.0427e-06, 9.9996e-01, 2.0168e-05],\n",
      "        [1.8892e-06, 1.8463e-06, 9.9999e-01, 3.9642e-06],\n",
      "        [5.2267e-06, 2.4626e-06, 9.9998e-01, 1.0729e-05],\n",
      "        [5.3763e-06, 3.2520e-06, 9.9997e-01, 2.3567e-05],\n",
      "        [2.8231e-05, 2.2466e-05, 9.9992e-01, 2.5007e-05],\n",
      "        [1.4097e-06, 2.1800e-06, 9.9999e-01, 5.1904e-06],\n",
      "        [2.8770e-06, 3.2062e-06, 9.9999e-01, 5.1450e-06],\n",
      "        [1.3407e-06, 1.6589e-06, 9.9999e-01, 5.6070e-06],\n",
      "        [6.5014e-06, 3.6682e-06, 9.9997e-01, 1.7946e-05],\n",
      "        [8.7051e-07, 1.3116e-06, 9.9999e-01, 5.2786e-06],\n",
      "        [6.1082e-06, 4.3325e-06, 9.9996e-01, 2.6636e-05],\n",
      "        [2.0073e-06, 1.6854e-06, 9.9998e-01, 1.4362e-05],\n",
      "        [1.4565e-06, 3.5679e-06, 9.9999e-01, 2.5951e-06],\n",
      "        [2.8109e-06, 3.6543e-06, 9.9999e-01, 3.2408e-06],\n",
      "        [1.1559e-06, 2.1701e-06, 9.9999e-01, 5.5738e-06],\n",
      "        [1.3336e-06, 3.0934e-06, 9.9999e-01, 8.1454e-06],\n",
      "        [1.0366e-04, 2.6507e-05, 9.9984e-01, 2.7348e-05],\n",
      "        [2.3550e-06, 4.3933e-06, 9.9999e-01, 5.6875e-06],\n",
      "        [7.5613e-07, 3.6532e-06, 9.9999e-01, 5.8020e-06],\n",
      "        [2.1339e-06, 6.7440e-06, 9.9998e-01, 8.6511e-06],\n",
      "        [1.0341e-06, 2.7062e-06, 9.9999e-01, 6.0575e-06],\n",
      "        [2.8627e-06, 2.4963e-06, 9.9999e-01, 9.5268e-06],\n",
      "        [1.3050e-06, 1.1876e-06, 9.9999e-01, 6.7682e-06],\n",
      "        [1.0070e-06, 2.2668e-06, 9.9999e-01, 3.7736e-06],\n",
      "        [8.6286e-07, 2.2944e-06, 9.9999e-01, 7.5870e-06],\n",
      "        [4.8765e-06, 2.7722e-06, 9.9998e-01, 1.2917e-05],\n",
      "        [9.1350e-06, 8.3429e-06, 9.9997e-01, 1.0999e-05],\n",
      "        [1.0057e-06, 7.9300e-07, 1.0000e+00, 2.2803e-06],\n",
      "        [1.6446e-06, 1.6546e-06, 9.9999e-01, 5.9850e-06],\n",
      "        [3.3750e-06, 4.0435e-06, 9.9998e-01, 1.4850e-05],\n",
      "        [4.7198e-06, 3.0454e-06, 9.9998e-01, 1.3201e-05],\n",
      "        [1.4807e-06, 2.2301e-06, 9.9999e-01, 3.9044e-06],\n",
      "        [1.0041e-06, 1.6624e-06, 9.9999e-01, 7.4801e-06],\n",
      "        [4.2561e-06, 1.6396e-06, 9.9999e-01, 5.7621e-06],\n",
      "        [5.9462e-06, 4.5210e-06, 9.9998e-01, 7.1738e-06],\n",
      "        [3.1996e-06, 3.7020e-06, 9.9998e-01, 8.0519e-06],\n",
      "        [1.7405e-06, 1.0127e-06, 9.9999e-01, 9.5882e-06],\n",
      "        [1.7432e-06, 2.2369e-06, 9.9999e-01, 4.3239e-06],\n",
      "        [1.9099e-06, 2.4771e-06, 9.9999e-01, 3.9928e-06],\n",
      "        [1.7068e-06, 2.4119e-06, 9.9999e-01, 4.4253e-06],\n",
      "        [2.2083e-06, 2.5860e-06, 9.9999e-01, 3.0895e-06],\n",
      "        [4.3991e-06, 4.4192e-06, 9.9998e-01, 7.4057e-06],\n",
      "        [4.8580e-06, 1.4504e-06, 9.9998e-01, 8.9793e-06],\n",
      "        [3.8135e-06, 1.9260e-06, 9.9998e-01, 1.0299e-05],\n",
      "        [6.2308e-07, 1.2724e-06, 9.9999e-01, 7.1433e-06],\n",
      "        [1.6465e-06, 2.2364e-06, 9.9999e-01, 7.2301e-06],\n",
      "        [2.0785e-06, 1.9941e-06, 9.9999e-01, 8.2329e-06],\n",
      "        [5.1379e-07, 1.7499e-06, 9.9999e-01, 3.9006e-06],\n",
      "        [1.8793e-04, 7.5216e-05, 9.9967e-01, 6.4955e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[8.7325e-08, 6.8206e-08, 1.4390e-03, 9.9856e-01],\n",
      "        [4.9750e-07, 2.8483e-07, 3.1432e-03, 9.9686e-01],\n",
      "        [5.7293e-08, 2.5238e-08, 8.9288e-04, 9.9911e-01],\n",
      "        [4.1055e-07, 2.1447e-07, 2.6131e-02, 9.7387e-01],\n",
      "        [1.3768e-07, 4.7410e-08, 9.3302e-04, 9.9907e-01],\n",
      "        [8.5061e-08, 2.7791e-08, 2.6985e-04, 9.9973e-01],\n",
      "        [4.0159e-08, 1.5710e-08, 1.7371e-04, 9.9983e-01],\n",
      "        [1.5005e-08, 1.3873e-08, 7.5330e-05, 9.9992e-01],\n",
      "        [3.0348e-07, 1.0778e-07, 2.2064e-03, 9.9779e-01],\n",
      "        [2.4090e-07, 8.8626e-08, 2.9359e-03, 9.9706e-01],\n",
      "        [9.9298e-08, 5.5356e-08, 1.5707e-03, 9.9843e-01],\n",
      "        [3.2333e-08, 1.9950e-08, 1.9421e-04, 9.9981e-01],\n",
      "        [1.0598e-07, 5.6911e-08, 1.2851e-03, 9.9871e-01],\n",
      "        [5.9012e-08, 3.7736e-08, 3.0324e-04, 9.9970e-01],\n",
      "        [2.1923e-07, 7.7915e-08, 3.8941e-03, 9.9611e-01],\n",
      "        [1.2390e-07, 1.0825e-07, 2.7468e-03, 9.9725e-01],\n",
      "        [2.9888e-08, 3.9291e-08, 5.4434e-04, 9.9946e-01],\n",
      "        [2.6039e-08, 1.1191e-08, 1.2994e-04, 9.9987e-01],\n",
      "        [3.8704e-08, 4.5799e-08, 1.9058e-04, 9.9981e-01],\n",
      "        [1.1311e-08, 1.4366e-08, 7.3056e-05, 9.9993e-01],\n",
      "        [6.2122e-07, 1.3134e-07, 1.7182e-03, 9.9828e-01],\n",
      "        [7.8993e-08, 1.6579e-08, 4.7295e-04, 9.9953e-01],\n",
      "        [9.6026e-08, 7.0642e-08, 1.4150e-03, 9.9858e-01],\n",
      "        [1.1671e-07, 1.6579e-07, 3.3037e-03, 9.9670e-01],\n",
      "        [7.1549e-07, 1.5764e-07, 1.6313e-02, 9.8369e-01],\n",
      "        [9.5282e-08, 6.6253e-08, 7.1475e-04, 9.9929e-01],\n",
      "        [6.8626e-08, 3.4847e-08, 2.6998e-04, 9.9973e-01],\n",
      "        [2.0901e-07, 1.8493e-07, 3.6471e-03, 9.9635e-01],\n",
      "        [6.0792e-07, 1.0613e-07, 6.4246e-03, 9.9357e-01],\n",
      "        [7.6449e-08, 2.3679e-08, 1.2276e-03, 9.9877e-01],\n",
      "        [3.6596e-07, 1.0025e-07, 3.2571e-05, 9.9997e-01],\n",
      "        [1.6918e-07, 8.5679e-08, 2.1000e-03, 9.9790e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.7237) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.9454e-07, 1.0000e+00, 2.6480e-08, 5.3774e-07],\n",
      "        [4.1146e-07, 1.0000e+00, 6.8828e-08, 1.9615e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.6808e-06, 1.4052e-09, 8.0025e-08],\n",
      "        [9.9671e-01, 3.2807e-03, 6.2368e-08, 8.3010e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[3.2693e-04, 1.2410e-03, 9.9834e-01, 9.1497e-05],\n",
      "        [8.1301e-05, 3.5787e-04, 9.9955e-01, 1.5323e-05],\n",
      "        [4.7050e-04, 1.9758e-03, 9.9713e-01, 4.1895e-04],\n",
      "        [3.1377e-04, 9.4545e-04, 9.9856e-01, 1.7684e-04],\n",
      "        [3.9268e-05, 8.7877e-04, 9.9902e-01, 6.3049e-05],\n",
      "        [5.1347e-05, 9.4803e-04, 9.9895e-01, 4.7867e-05],\n",
      "        [4.7947e-05, 7.5558e-04, 9.9914e-01, 5.4452e-05],\n",
      "        [7.6752e-05, 6.1720e-04, 9.9928e-01, 2.2566e-05],\n",
      "        [1.0331e-04, 1.0185e-03, 9.9872e-01, 1.5624e-04],\n",
      "        [3.2885e-05, 5.9821e-04, 9.9932e-01, 4.6395e-05],\n",
      "        [6.6914e-05, 1.4337e-03, 9.9846e-01, 4.1623e-05],\n",
      "        [2.6853e-04, 1.9158e-03, 9.9770e-01, 1.1621e-04],\n",
      "        [5.0013e-05, 6.4863e-04, 9.9924e-01, 5.6441e-05],\n",
      "        [4.2797e-05, 3.9258e-04, 9.9950e-01, 6.7082e-05],\n",
      "        [6.3029e-05, 8.3623e-04, 9.9908e-01, 2.4521e-05],\n",
      "        [9.0954e-05, 6.9152e-04, 9.9912e-01, 9.6737e-05],\n",
      "        [7.9100e-05, 9.0504e-04, 9.9896e-01, 5.6911e-05],\n",
      "        [6.8802e-05, 6.5521e-04, 9.9925e-01, 2.3432e-05],\n",
      "        [1.4679e-03, 8.2714e-03, 9.9000e-01, 2.6164e-04],\n",
      "        [1.6574e-04, 2.1713e-03, 9.9735e-01, 3.1040e-04],\n",
      "        [2.4600e-04, 1.6594e-03, 9.9804e-01, 5.3123e-05],\n",
      "        [1.3240e-03, 4.2975e-03, 9.9420e-01, 1.7357e-04],\n",
      "        [6.1122e-04, 3.4842e-03, 9.9584e-01, 6.8887e-05],\n",
      "        [3.7388e-04, 9.8183e-04, 9.9852e-01, 1.2058e-04],\n",
      "        [2.5016e-04, 1.5934e-03, 9.9801e-01, 1.4158e-04],\n",
      "        [4.8917e-04, 1.6294e-03, 9.9779e-01, 8.6991e-05],\n",
      "        [9.7628e-05, 8.4021e-04, 9.9902e-01, 4.0929e-05],\n",
      "        [3.1949e-04, 1.6761e-03, 9.9783e-01, 1.7636e-04],\n",
      "        [2.4841e-05, 4.2237e-04, 9.9951e-01, 4.0786e-05],\n",
      "        [8.0375e-04, 1.9548e-03, 9.9719e-01, 5.6390e-05],\n",
      "        [1.8054e-04, 1.6996e-03, 9.9804e-01, 8.3132e-05],\n",
      "        [3.8832e-05, 5.9751e-04, 9.9934e-01, 1.9410e-05],\n",
      "        [5.0953e-05, 8.3101e-04, 9.9906e-01, 5.9304e-05],\n",
      "        [9.7358e-04, 3.3869e-03, 9.9542e-01, 2.2361e-04],\n",
      "        [1.5524e-05, 3.7976e-04, 9.9959e-01, 1.9268e-05],\n",
      "        [2.9301e-04, 4.5496e-03, 9.9498e-01, 1.7330e-04],\n",
      "        [2.6978e-04, 2.1954e-03, 9.9744e-01, 9.3648e-05],\n",
      "        [1.0670e-04, 7.1762e-04, 9.9904e-01, 1.3120e-04],\n",
      "        [2.7125e-05, 7.8523e-04, 9.9905e-01, 1.3685e-04],\n",
      "        [2.4090e-05, 4.9443e-04, 9.9942e-01, 6.0563e-05],\n",
      "        [2.3469e-04, 9.9156e-04, 9.9871e-01, 6.7911e-05],\n",
      "        [2.6721e-04, 2.1759e-03, 9.9748e-01, 7.6599e-05],\n",
      "        [2.0122e-04, 2.6674e-03, 9.9703e-01, 1.0058e-04],\n",
      "        [2.6864e-04, 1.0492e-03, 9.9859e-01, 9.0410e-05],\n",
      "        [4.6773e-04, 4.6249e-03, 9.9479e-01, 1.1631e-04],\n",
      "        [7.8872e-05, 1.7091e-03, 9.9813e-01, 7.8458e-05],\n",
      "        [2.8686e-04, 1.1079e-03, 9.9850e-01, 1.0120e-04],\n",
      "        [7.5095e-05, 1.9923e-03, 9.9788e-01, 4.9195e-05],\n",
      "        [1.2149e-04, 1.6250e-03, 9.9806e-01, 1.9696e-04],\n",
      "        [2.1298e-04, 5.4205e-04, 9.9920e-01, 4.6755e-05],\n",
      "        [9.5641e-05, 9.8894e-04, 9.9871e-01, 2.0846e-04],\n",
      "        [2.6066e-04, 1.3803e-03, 9.9827e-01, 8.6614e-05],\n",
      "        [1.0270e-04, 1.0463e-03, 9.9858e-01, 2.7537e-04],\n",
      "        [2.0322e-04, 6.1012e-04, 9.9906e-01, 1.2448e-04],\n",
      "        [4.7179e-04, 1.6798e-03, 9.9779e-01, 5.7265e-05],\n",
      "        [5.5537e-04, 1.4493e-03, 9.9771e-01, 2.8421e-04],\n",
      "        [2.5853e-04, 1.5279e-03, 9.9810e-01, 1.1010e-04],\n",
      "        [4.6139e-05, 3.6401e-04, 9.9955e-01, 4.3648e-05],\n",
      "        [3.6899e-04, 1.4477e-03, 9.9814e-01, 4.5475e-05],\n",
      "        [1.2246e-04, 1.6510e-03, 9.9816e-01, 7.1226e-05],\n",
      "        [2.7658e-04, 4.4930e-03, 9.9490e-01, 3.3198e-04],\n",
      "        [3.4642e-04, 1.2558e-03, 9.9833e-01, 6.3626e-05],\n",
      "        [2.5495e-04, 7.3570e-04, 9.9894e-01, 7.3974e-05],\n",
      "        [9.4747e-04, 2.8927e-03, 9.9590e-01, 2.5914e-04],\n",
      "        [6.2494e-05, 9.3357e-04, 9.9887e-01, 1.3059e-04],\n",
      "        [3.8575e-04, 2.5578e-03, 9.9693e-01, 1.2798e-04],\n",
      "        [5.4520e-05, 4.9873e-04, 9.9941e-01, 3.2704e-05],\n",
      "        [5.0806e-05, 2.6935e-04, 9.9965e-01, 2.9821e-05],\n",
      "        [3.2103e-04, 3.9129e-03, 9.9564e-01, 1.2739e-04],\n",
      "        [9.1883e-05, 6.4888e-04, 9.9918e-01, 7.4643e-05],\n",
      "        [2.6295e-04, 1.4059e-03, 9.9823e-01, 9.7061e-05],\n",
      "        [2.9255e-03, 8.5115e-03, 9.8836e-01, 2.0699e-04],\n",
      "        [1.0525e-03, 6.2746e-03, 9.9256e-01, 1.1594e-04],\n",
      "        [1.8367e-04, 4.1518e-04, 9.9928e-01, 1.2606e-04],\n",
      "        [1.2041e-04, 1.3560e-03, 9.9838e-01, 1.4345e-04],\n",
      "        [1.5037e-04, 8.0135e-04, 9.9891e-01, 1.3692e-04],\n",
      "        [1.8610e-05, 2.8243e-04, 9.9965e-01, 5.3435e-05],\n",
      "        [5.5474e-05, 5.1905e-04, 9.9931e-01, 1.1532e-04],\n",
      "        [6.9921e-04, 2.0624e-03, 9.9713e-01, 1.0421e-04],\n",
      "        [6.8649e-05, 1.2288e-03, 9.9865e-01, 5.5606e-05],\n",
      "        [8.3108e-05, 8.6343e-04, 9.9900e-01, 5.4166e-05],\n",
      "        [4.5273e-05, 7.5318e-04, 9.9917e-01, 3.3825e-05],\n",
      "        [1.3531e-04, 8.3890e-04, 9.9897e-01, 5.5631e-05],\n",
      "        [3.1344e-04, 9.9144e-04, 9.9853e-01, 1.6291e-04],\n",
      "        [2.6491e-05, 3.3326e-04, 9.9960e-01, 4.1827e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.2439e-08, 7.9440e-08, 5.8402e-06, 9.9999e-01],\n",
      "        [1.4768e-08, 5.7748e-08, 2.3067e-06, 1.0000e+00],\n",
      "        [2.0280e-08, 1.6532e-08, 1.2112e-06, 1.0000e+00],\n",
      "        [1.6030e-08, 1.3488e-07, 1.8762e-05, 9.9998e-01],\n",
      "        [8.2331e-09, 5.7984e-08, 4.7094e-06, 1.0000e+00],\n",
      "        [1.3344e-08, 7.0555e-08, 1.2437e-06, 1.0000e+00],\n",
      "        [9.1186e-10, 8.6470e-09, 2.3439e-07, 1.0000e+00],\n",
      "        [7.6182e-09, 2.2095e-08, 1.3445e-07, 1.0000e+00],\n",
      "        [5.5993e-09, 1.4627e-08, 5.8519e-07, 1.0000e+00],\n",
      "        [7.0630e-09, 7.3378e-08, 2.7931e-06, 1.0000e+00],\n",
      "        [4.3541e-08, 1.5096e-07, 2.4203e-06, 1.0000e+00],\n",
      "        [9.7023e-08, 8.1836e-08, 1.2935e-05, 9.9999e-01],\n",
      "        [6.2681e-08, 3.2256e-07, 3.5895e-05, 9.9996e-01],\n",
      "        [4.5233e-09, 5.9630e-08, 4.9578e-07, 1.0000e+00],\n",
      "        [6.7220e-08, 8.1710e-07, 6.1315e-05, 9.9994e-01],\n",
      "        [3.6633e-09, 1.3886e-08, 5.2893e-07, 1.0000e+00],\n",
      "        [8.7981e-09, 2.7073e-08, 1.6152e-06, 1.0000e+00],\n",
      "        [2.0592e-08, 8.9756e-08, 5.6447e-06, 9.9999e-01],\n",
      "        [2.7916e-08, 1.2664e-07, 9.3750e-06, 9.9999e-01],\n",
      "        [9.8148e-08, 1.5678e-07, 1.4868e-05, 9.9998e-01],\n",
      "        [1.5712e-08, 7.1123e-08, 5.1232e-06, 9.9999e-01],\n",
      "        [1.0350e-08, 3.5659e-08, 7.0779e-07, 1.0000e+00],\n",
      "        [2.5364e-09, 1.2640e-08, 1.2201e-06, 1.0000e+00],\n",
      "        [4.9497e-09, 6.6666e-08, 5.9303e-06, 9.9999e-01],\n",
      "        [7.6234e-09, 2.6165e-08, 2.0663e-06, 1.0000e+00],\n",
      "        [2.6441e-09, 5.4080e-09, 6.3641e-07, 1.0000e+00],\n",
      "        [4.1872e-08, 3.0521e-07, 4.6644e-05, 9.9995e-01],\n",
      "        [5.7988e-09, 6.1374e-08, 8.1660e-07, 1.0000e+00],\n",
      "        [2.1721e-08, 4.6713e-07, 1.7938e-05, 9.9998e-01],\n",
      "        [5.5397e-09, 3.0347e-08, 2.8034e-06, 1.0000e+00],\n",
      "        [1.4199e-08, 1.8905e-07, 7.3247e-06, 9.9999e-01],\n",
      "        [1.5302e-08, 4.9684e-08, 3.0071e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.3506) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.8215e-07, 1.0000e+00, 1.2471e-08, 9.5765e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9995e-01, 4.5998e-05, 1.4376e-08, 5.6121e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.3803e-05, 3.4485e-04, 9.9961e-01, 2.1588e-05],\n",
      "        [1.5664e-04, 7.0469e-04, 9.9911e-01, 3.0028e-05],\n",
      "        [2.7230e-05, 6.6761e-04, 9.9927e-01, 3.4780e-05],\n",
      "        [1.1662e-03, 1.0608e-03, 9.9771e-01, 6.8039e-05],\n",
      "        [5.6180e-05, 3.9458e-04, 9.9952e-01, 3.1535e-05],\n",
      "        [2.2933e-05, 1.6441e-04, 9.9976e-01, 5.6284e-05],\n",
      "        [5.5549e-05, 2.8254e-04, 9.9964e-01, 1.9464e-05],\n",
      "        [6.4140e-05, 6.3760e-04, 9.9920e-01, 9.7401e-05],\n",
      "        [2.6747e-05, 9.1926e-04, 9.9892e-01, 1.3214e-04],\n",
      "        [3.7812e-05, 4.1011e-04, 9.9949e-01, 6.2635e-05],\n",
      "        [3.0783e-04, 5.5130e-04, 9.9905e-01, 8.7996e-05],\n",
      "        [2.1814e-04, 1.2118e-03, 9.9853e-01, 4.1764e-05],\n",
      "        [1.5577e-05, 2.6107e-04, 9.9971e-01, 1.2955e-05],\n",
      "        [4.2727e-04, 1.0056e-03, 9.9854e-01, 2.9301e-05],\n",
      "        [3.8082e-05, 3.8509e-04, 9.9955e-01, 2.2879e-05],\n",
      "        [1.0998e-04, 3.2690e-04, 9.9952e-01, 4.1532e-05],\n",
      "        [2.5125e-05, 8.4981e-05, 9.9988e-01, 6.3993e-06],\n",
      "        [3.4033e-05, 4.2430e-04, 9.9950e-01, 3.6853e-05],\n",
      "        [2.2215e-05, 3.8202e-04, 9.9955e-01, 5.0243e-05],\n",
      "        [2.7715e-05, 3.6330e-04, 9.9954e-01, 6.5657e-05],\n",
      "        [3.4639e-05, 4.8116e-04, 9.9945e-01, 3.6440e-05],\n",
      "        [2.6582e-05, 2.5316e-04, 9.9970e-01, 2.2040e-05],\n",
      "        [5.6799e-05, 2.2119e-04, 9.9968e-01, 4.0576e-05],\n",
      "        [1.9050e-04, 3.8010e-04, 9.9940e-01, 2.5941e-05],\n",
      "        [1.1287e-05, 2.0769e-04, 9.9977e-01, 1.4365e-05],\n",
      "        [8.7349e-05, 4.0127e-04, 9.9946e-01, 5.6008e-05],\n",
      "        [4.6740e-05, 4.0324e-04, 9.9949e-01, 6.2652e-05],\n",
      "        [2.0839e-05, 4.3329e-04, 9.9952e-01, 2.6852e-05],\n",
      "        [2.9647e-05, 9.6358e-05, 9.9984e-01, 3.7686e-05],\n",
      "        [1.0707e-05, 1.3148e-04, 9.9984e-01, 1.7465e-05],\n",
      "        [8.7604e-05, 5.2706e-04, 9.9934e-01, 4.1124e-05],\n",
      "        [2.5332e-04, 6.3056e-04, 9.9907e-01, 4.6646e-05],\n",
      "        [2.6001e-05, 2.8482e-04, 9.9967e-01, 1.7167e-05],\n",
      "        [1.5844e-05, 1.0097e-04, 9.9987e-01, 1.2944e-05],\n",
      "        [2.0464e-05, 2.6577e-04, 9.9959e-01, 1.2679e-04],\n",
      "        [4.0775e-05, 3.1666e-04, 9.9957e-01, 7.1843e-05],\n",
      "        [2.4616e-05, 3.7130e-04, 9.9956e-01, 4.2477e-05],\n",
      "        [2.9051e-05, 4.8565e-04, 9.9947e-01, 1.5929e-05],\n",
      "        [1.0778e-04, 4.1059e-04, 9.9943e-01, 5.1063e-05],\n",
      "        [1.8927e-05, 3.2529e-04, 9.9964e-01, 1.9406e-05],\n",
      "        [1.6780e-04, 5.7367e-04, 9.9918e-01, 8.3000e-05],\n",
      "        [5.0241e-05, 2.5064e-04, 9.9967e-01, 3.0999e-05],\n",
      "        [1.8907e-04, 9.1621e-04, 9.9884e-01, 5.6880e-05],\n",
      "        [6.5229e-05, 5.5241e-04, 9.9933e-01, 4.8640e-05],\n",
      "        [1.3845e-05, 3.4763e-04, 9.9962e-01, 1.6633e-05],\n",
      "        [3.9202e-05, 3.8719e-04, 9.9952e-01, 5.2002e-05],\n",
      "        [2.1886e-05, 4.6954e-04, 9.9948e-01, 2.8004e-05],\n",
      "        [1.5054e-05, 1.8998e-04, 9.9976e-01, 3.7083e-05],\n",
      "        [8.5745e-06, 2.2386e-04, 9.9976e-01, 1.2279e-05],\n",
      "        [6.2214e-05, 2.0422e-04, 9.9965e-01, 7.9743e-05],\n",
      "        [1.8064e-05, 2.0194e-04, 9.9973e-01, 4.8143e-05],\n",
      "        [2.4849e-05, 2.0707e-04, 9.9975e-01, 2.2481e-05],\n",
      "        [9.8275e-05, 4.0800e-04, 9.9947e-01, 2.4551e-05],\n",
      "        [8.4084e-05, 5.8978e-04, 9.9926e-01, 6.3624e-05],\n",
      "        [2.1226e-05, 4.7940e-04, 9.9940e-01, 9.6534e-05],\n",
      "        [1.2004e-05, 3.0670e-04, 9.9966e-01, 1.7517e-05],\n",
      "        [1.8669e-05, 6.6843e-05, 9.9990e-01, 1.5864e-05],\n",
      "        [1.0645e-03, 1.6815e-03, 9.9716e-01, 9.5213e-05],\n",
      "        [1.8620e-05, 3.2747e-04, 9.9962e-01, 3.8444e-05],\n",
      "        [1.0375e-04, 6.8319e-04, 9.9914e-01, 7.5088e-05],\n",
      "        [4.9921e-05, 1.0756e-03, 9.9875e-01, 1.2809e-04],\n",
      "        [6.2937e-05, 5.0642e-04, 9.9934e-01, 9.4412e-05],\n",
      "        [6.2149e-05, 1.6633e-04, 9.9972e-01, 4.7129e-05],\n",
      "        [6.0221e-05, 2.8289e-04, 9.9962e-01, 3.4252e-05],\n",
      "        [5.4074e-05, 1.0248e-03, 9.9889e-01, 3.0861e-05],\n",
      "        [1.1850e-04, 8.6567e-04, 9.9899e-01, 2.3424e-05],\n",
      "        [2.2540e-04, 5.3711e-04, 9.9917e-01, 7.0811e-05],\n",
      "        [1.7592e-05, 2.1455e-04, 9.9972e-01, 4.4112e-05],\n",
      "        [3.3330e-05, 3.3393e-04, 9.9958e-01, 4.7882e-05],\n",
      "        [1.4853e-04, 8.0352e-04, 9.9899e-01, 5.3350e-05],\n",
      "        [9.6928e-05, 3.1479e-04, 9.9952e-01, 6.4996e-05],\n",
      "        [1.2531e-04, 1.0233e-03, 9.9880e-01, 5.1839e-05],\n",
      "        [1.4284e-05, 1.7326e-04, 9.9979e-01, 2.2947e-05],\n",
      "        [4.5924e-05, 3.4529e-04, 9.9959e-01, 1.6367e-05],\n",
      "        [1.7672e-04, 1.0714e-03, 9.9870e-01, 5.2820e-05],\n",
      "        [3.6456e-05, 8.1178e-04, 9.9912e-01, 2.9037e-05],\n",
      "        [1.2314e-03, 2.1801e-03, 9.9635e-01, 2.4255e-04],\n",
      "        [1.1299e-05, 6.7374e-04, 9.9928e-01, 3.4596e-05],\n",
      "        [2.0313e-04, 2.9060e-04, 9.9942e-01, 8.3616e-05],\n",
      "        [5.0347e-05, 3.6405e-04, 9.9953e-01, 5.9592e-05],\n",
      "        [1.7371e-05, 1.1261e-04, 9.9986e-01, 9.9310e-06],\n",
      "        [6.0459e-05, 3.1001e-04, 9.9954e-01, 9.2373e-05],\n",
      "        [2.5716e-05, 3.0066e-04, 9.9966e-01, 1.4374e-05],\n",
      "        [9.6091e-04, 4.0142e-03, 9.9480e-01, 2.2342e-04],\n",
      "        [3.6692e-05, 5.4150e-04, 9.9940e-01, 1.7174e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[5.1497e-09, 1.0902e-08, 1.3315e-06, 1.0000e+00],\n",
      "        [3.0801e-08, 1.5126e-08, 5.0823e-08, 1.0000e+00],\n",
      "        [1.8769e-08, 2.0022e-08, 5.0946e-06, 9.9999e-01],\n",
      "        [7.6881e-09, 1.7691e-08, 8.8165e-07, 1.0000e+00],\n",
      "        [1.2165e-08, 1.3011e-08, 7.8191e-07, 1.0000e+00],\n",
      "        [6.1082e-09, 5.9751e-08, 9.4131e-06, 9.9999e-01],\n",
      "        [2.9456e-08, 5.4592e-08, 4.0444e-06, 1.0000e+00],\n",
      "        [1.9138e-08, 2.6268e-08, 2.8710e-06, 1.0000e+00],\n",
      "        [9.6293e-09, 1.6664e-08, 1.6315e-06, 1.0000e+00],\n",
      "        [1.7521e-08, 6.5529e-08, 6.7237e-06, 9.9999e-01],\n",
      "        [1.7082e-08, 5.1654e-08, 6.4948e-06, 9.9999e-01],\n",
      "        [2.8556e-08, 1.7339e-07, 5.9362e-06, 9.9999e-01],\n",
      "        [5.7227e-08, 9.2444e-08, 6.6108e-05, 9.9993e-01],\n",
      "        [7.0457e-09, 1.4975e-08, 6.8940e-07, 1.0000e+00],\n",
      "        [4.7272e-09, 1.1270e-08, 1.3111e-06, 1.0000e+00],\n",
      "        [6.4894e-09, 3.8328e-08, 1.5466e-06, 1.0000e+00],\n",
      "        [3.5733e-09, 6.2307e-09, 1.9763e-07, 1.0000e+00],\n",
      "        [3.8589e-08, 4.8370e-08, 1.5209e-06, 1.0000e+00],\n",
      "        [5.6972e-08, 1.7960e-07, 4.1014e-05, 9.9996e-01],\n",
      "        [3.0433e-08, 1.1565e-07, 5.7269e-08, 1.0000e+00],\n",
      "        [1.3444e-08, 1.5060e-08, 2.7626e-06, 1.0000e+00],\n",
      "        [5.1539e-07, 1.1181e-06, 2.0143e-04, 9.9980e-01],\n",
      "        [3.2432e-08, 4.4019e-08, 1.0138e-05, 9.9999e-01],\n",
      "        [2.7188e-08, 1.1330e-07, 1.1979e-05, 9.9999e-01],\n",
      "        [6.5182e-09, 1.0242e-08, 1.4064e-06, 1.0000e+00],\n",
      "        [1.5416e-08, 6.8182e-08, 4.2612e-06, 1.0000e+00],\n",
      "        [1.7044e-08, 3.9716e-08, 7.9728e-06, 9.9999e-01],\n",
      "        [3.1067e-09, 1.7874e-08, 1.0354e-06, 1.0000e+00],\n",
      "        [2.9115e-09, 5.5797e-09, 5.1618e-07, 1.0000e+00],\n",
      "        [1.0821e-09, 1.0565e-08, 1.3939e-07, 1.0000e+00],\n",
      "        [2.3244e-08, 1.3103e-08, 1.3167e-07, 1.0000e+00],\n",
      "        [8.9297e-10, 8.0074e-09, 6.0899e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.2188) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.3586e-06, 1.0000e+00, 7.9478e-08, 3.4030e-06],\n",
      "        [1.9228e-06, 9.9999e-01, 2.6094e-07, 3.4680e-06],\n",
      "        [8.8460e-07, 1.0000e+00, 3.3208e-08, 8.3610e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.1442e-07, 2.7934e-10, 4.7939e-08],\n",
      "        [9.9997e-01, 2.9127e-05, 3.7329e-09, 8.6431e-07],\n",
      "        [1.0000e+00, 3.4302e-08, 1.8624e-10, 2.8249e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.4389e-05, 1.0882e-04, 9.9985e-01, 2.1272e-05],\n",
      "        [3.0359e-05, 5.7666e-04, 9.9932e-01, 7.7666e-05],\n",
      "        [3.2303e-05, 1.5579e-04, 9.9980e-01, 1.5213e-05],\n",
      "        [4.9607e-05, 2.6343e-04, 9.9965e-01, 3.5782e-05],\n",
      "        [2.2774e-05, 2.7898e-04, 9.9965e-01, 4.5347e-05],\n",
      "        [2.0083e-05, 1.0606e-04, 9.9984e-01, 3.6893e-05],\n",
      "        [1.8889e-04, 4.8242e-04, 9.9926e-01, 6.8529e-05],\n",
      "        [3.3906e-04, 1.4242e-03, 9.9815e-01, 8.4236e-05],\n",
      "        [3.1817e-05, 1.4224e-04, 9.9979e-01, 3.8003e-05],\n",
      "        [1.5406e-03, 3.8677e-03, 9.9419e-01, 3.9967e-04],\n",
      "        [1.6486e-05, 2.1713e-04, 9.9973e-01, 3.4949e-05],\n",
      "        [2.1606e-05, 1.2587e-04, 9.9981e-01, 4.2850e-05],\n",
      "        [1.0766e-04, 4.5379e-04, 9.9932e-01, 1.1571e-04],\n",
      "        [8.0190e-05, 6.8429e-04, 9.9912e-01, 1.1356e-04],\n",
      "        [3.3643e-04, 5.4741e-04, 9.9906e-01, 5.9625e-05],\n",
      "        [1.3222e-05, 1.8387e-04, 9.9978e-01, 2.6068e-05],\n",
      "        [1.0142e-04, 7.2371e-04, 9.9911e-01, 6.1087e-05],\n",
      "        [1.6809e-05, 3.9935e-04, 9.9956e-01, 2.8592e-05],\n",
      "        [2.6301e-05, 1.9305e-04, 9.9976e-01, 1.6359e-05],\n",
      "        [2.9882e-05, 1.0876e-03, 9.9881e-01, 7.3778e-05],\n",
      "        [2.7986e-05, 6.2490e-04, 9.9927e-01, 7.3704e-05],\n",
      "        [5.5338e-05, 5.5260e-04, 9.9935e-01, 4.5856e-05],\n",
      "        [2.2846e-05, 1.1749e-03, 9.9877e-01, 3.1812e-05],\n",
      "        [6.1500e-05, 9.7969e-04, 9.9885e-01, 1.0692e-04],\n",
      "        [1.3881e-05, 3.9711e-04, 9.9953e-01, 6.4047e-05],\n",
      "        [7.8996e-06, 1.5554e-04, 9.9982e-01, 1.6310e-05],\n",
      "        [7.2740e-05, 4.6267e-04, 9.9943e-01, 3.5333e-05],\n",
      "        [4.3815e-05, 2.0801e-04, 9.9972e-01, 2.9447e-05],\n",
      "        [7.3058e-05, 2.9877e-04, 9.9957e-01, 5.3222e-05],\n",
      "        [6.1228e-05, 2.0747e-04, 9.9960e-01, 1.3576e-04],\n",
      "        [9.9105e-05, 1.3435e-03, 9.9848e-01, 7.4555e-05],\n",
      "        [1.7927e-05, 3.0260e-04, 9.9965e-01, 2.5226e-05],\n",
      "        [2.8996e-05, 4.3305e-04, 9.9942e-01, 1.1462e-04],\n",
      "        [2.3151e-05, 3.8042e-04, 9.9949e-01, 1.0980e-04],\n",
      "        [5.3113e-05, 4.2457e-04, 9.9947e-01, 5.3312e-05],\n",
      "        [1.8572e-04, 2.0004e-04, 9.9957e-01, 4.6378e-05],\n",
      "        [1.1868e-04, 6.7528e-04, 9.9917e-01, 3.2733e-05],\n",
      "        [4.0056e-04, 1.4221e-03, 9.9810e-01, 7.7366e-05],\n",
      "        [9.1970e-05, 5.5977e-04, 9.9930e-01, 4.5853e-05],\n",
      "        [3.9933e-05, 2.1754e-04, 9.9965e-01, 9.0744e-05],\n",
      "        [6.4927e-06, 1.4517e-04, 9.9979e-01, 5.8389e-05],\n",
      "        [3.7031e-05, 2.5060e-04, 9.9969e-01, 2.5646e-05],\n",
      "        [1.2282e-05, 1.3934e-04, 9.9982e-01, 2.5415e-05],\n",
      "        [2.2970e-04, 3.6248e-04, 9.9935e-01, 6.1421e-05],\n",
      "        [1.0350e-05, 1.4308e-04, 9.9979e-01, 5.4838e-05],\n",
      "        [1.3261e-04, 3.6983e-04, 9.9947e-01, 2.5523e-05],\n",
      "        [2.1897e-05, 2.7971e-04, 9.9962e-01, 7.7899e-05],\n",
      "        [2.2282e-05, 1.7193e-04, 9.9977e-01, 3.5946e-05],\n",
      "        [1.9855e-05, 2.0356e-04, 9.9974e-01, 3.6077e-05],\n",
      "        [5.1030e-05, 7.0561e-04, 9.9920e-01, 4.1478e-05],\n",
      "        [1.3507e-04, 7.9827e-04, 9.9901e-01, 5.3396e-05],\n",
      "        [5.7019e-05, 6.2273e-04, 9.9912e-01, 2.0178e-04],\n",
      "        [1.1269e-05, 1.9172e-04, 9.9974e-01, 5.5998e-05],\n",
      "        [8.1289e-06, 2.5684e-04, 9.9972e-01, 1.6528e-05],\n",
      "        [8.7798e-05, 6.4744e-04, 9.9915e-01, 1.1277e-04],\n",
      "        [5.5494e-04, 1.3783e-03, 9.9799e-01, 7.8340e-05],\n",
      "        [3.9915e-05, 1.4240e-04, 9.9972e-01, 9.3069e-05],\n",
      "        [6.0157e-04, 4.3453e-04, 9.9883e-01, 1.3811e-04],\n",
      "        [2.7663e-05, 2.3716e-04, 9.9972e-01, 1.9726e-05],\n",
      "        [3.5159e-05, 3.3570e-04, 9.9952e-01, 1.0997e-04],\n",
      "        [9.0861e-05, 9.6347e-04, 9.9892e-01, 2.9529e-05],\n",
      "        [9.5612e-05, 9.3129e-04, 9.9891e-01, 5.9859e-05],\n",
      "        [5.1112e-05, 5.3854e-04, 9.9937e-01, 4.5203e-05],\n",
      "        [4.6860e-05, 1.8833e-04, 9.9974e-01, 2.9790e-05],\n",
      "        [7.9426e-06, 1.8365e-04, 9.9979e-01, 1.9779e-05],\n",
      "        [1.4265e-05, 3.3246e-04, 9.9963e-01, 1.9607e-05],\n",
      "        [1.0160e-04, 1.1683e-04, 9.9974e-01, 4.5157e-05],\n",
      "        [3.9839e-05, 5.2105e-04, 9.9939e-01, 5.1506e-05],\n",
      "        [2.3603e-05, 2.4367e-04, 9.9971e-01, 1.9592e-05],\n",
      "        [6.0667e-05, 4.0604e-04, 9.9942e-01, 1.1734e-04],\n",
      "        [7.5183e-06, 7.8679e-05, 9.9990e-01, 1.8196e-05],\n",
      "        [1.4726e-05, 2.8234e-04, 9.9967e-01, 3.5870e-05],\n",
      "        [5.5883e-05, 5.0884e-04, 9.9938e-01, 6.0284e-05],\n",
      "        [4.4727e-05, 8.6352e-04, 9.9904e-01, 5.3854e-05],\n",
      "        [3.2645e-05, 2.1951e-04, 9.9973e-01, 1.8177e-05],\n",
      "        [3.0784e-05, 2.0432e-04, 9.9969e-01, 7.0633e-05],\n",
      "        [1.9989e-05, 1.1456e-04, 9.9986e-01, 9.2386e-06],\n",
      "        [2.4014e-05, 3.0677e-04, 9.9958e-01, 8.6389e-05],\n",
      "        [1.1878e-05, 1.6825e-04, 9.9980e-01, 2.0754e-05],\n",
      "        [2.8632e-05, 4.2566e-04, 9.9953e-01, 1.3481e-05],\n",
      "        [3.0049e-05, 2.8214e-04, 9.9963e-01, 6.2378e-05],\n",
      "        [5.0911e-05, 2.7267e-04, 9.9963e-01, 5.0922e-05],\n",
      "        [6.4603e-05, 2.8724e-04, 9.9961e-01, 4.1807e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.9465e-07, 3.2863e-07, 1.8604e-04, 9.9981e-01],\n",
      "        [1.9138e-07, 1.1142e-07, 5.5750e-05, 9.9994e-01],\n",
      "        [2.3439e-07, 2.1119e-07, 1.8593e-04, 9.9981e-01],\n",
      "        [1.3673e-07, 2.7127e-07, 1.9270e-04, 9.9981e-01],\n",
      "        [1.2932e-07, 1.0005e-07, 5.1741e-06, 9.9999e-01],\n",
      "        [9.0847e-07, 1.5038e-06, 4.5773e-04, 9.9954e-01],\n",
      "        [2.3326e-07, 1.7561e-06, 1.0592e-03, 9.9894e-01],\n",
      "        [2.8062e-08, 6.5759e-08, 1.3516e-05, 9.9999e-01],\n",
      "        [2.4838e-08, 4.8584e-08, 2.2410e-05, 9.9998e-01],\n",
      "        [1.8830e-06, 6.9474e-07, 2.0962e-03, 9.9790e-01],\n",
      "        [7.7674e-07, 4.7143e-07, 1.4439e-03, 9.9855e-01],\n",
      "        [9.9399e-08, 1.1412e-07, 1.4328e-04, 9.9986e-01],\n",
      "        [4.4878e-07, 8.9549e-07, 1.7153e-03, 9.9828e-01],\n",
      "        [5.1603e-08, 2.0644e-07, 8.8296e-05, 9.9991e-01],\n",
      "        [3.7138e-07, 6.9817e-08, 5.6007e-05, 9.9994e-01],\n",
      "        [1.3691e-07, 8.6261e-08, 3.8194e-05, 9.9996e-01],\n",
      "        [1.3464e-07, 3.2254e-08, 3.7458e-05, 9.9996e-01],\n",
      "        [1.2001e-07, 3.3681e-07, 4.8866e-05, 9.9995e-01],\n",
      "        [1.7012e-07, 3.6905e-07, 1.5563e-04, 9.9984e-01],\n",
      "        [4.0697e-07, 3.2932e-07, 5.8174e-04, 9.9942e-01],\n",
      "        [3.3409e-07, 1.0947e-07, 6.7534e-05, 9.9993e-01],\n",
      "        [7.2740e-07, 1.4569e-06, 8.0792e-04, 9.9919e-01],\n",
      "        [8.9147e-07, 7.8267e-07, 1.6498e-03, 9.9835e-01],\n",
      "        [3.1565e-06, 1.3601e-06, 2.0177e-03, 9.9798e-01],\n",
      "        [1.9462e-07, 1.1675e-07, 8.9753e-05, 9.9991e-01],\n",
      "        [4.2182e-07, 3.8273e-07, 3.1514e-04, 9.9968e-01],\n",
      "        [3.1490e-07, 4.3217e-07, 6.3948e-04, 9.9936e-01],\n",
      "        [5.9825e-07, 1.2184e-06, 2.5038e-03, 9.9749e-01],\n",
      "        [6.9424e-07, 3.9434e-07, 1.5746e-04, 9.9984e-01],\n",
      "        [6.6573e-07, 5.4154e-07, 1.1367e-05, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.6362) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[2.9258e-06, 9.9999e-01, 9.9166e-07, 3.4020e-06],\n",
      "        [2.8426e-06, 9.9999e-01, 1.5528e-07, 2.3758e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9867e-01, 1.3252e-03, 3.4418e-08, 6.7789e-06],\n",
      "        [1.0000e+00, 1.8710e-06, 2.1881e-09, 2.0557e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.8233e-05, 3.2920e-04, 9.9957e-01, 8.7531e-05],\n",
      "        [3.6705e-05, 1.1992e-04, 9.9979e-01, 5.0177e-05],\n",
      "        [1.4871e-04, 9.5614e-04, 9.9883e-01, 6.5804e-05],\n",
      "        [8.2992e-06, 1.9732e-04, 9.9976e-01, 3.7963e-05],\n",
      "        [2.8482e-05, 9.0154e-05, 9.9981e-01, 6.6776e-05],\n",
      "        [4.1378e-05, 3.3584e-04, 9.9957e-01, 5.5617e-05],\n",
      "        [2.6048e-05, 3.1609e-04, 9.9960e-01, 5.3587e-05],\n",
      "        [9.5571e-06, 6.5392e-05, 9.9991e-01, 1.2171e-05],\n",
      "        [1.4522e-05, 2.0768e-04, 9.9976e-01, 2.2538e-05],\n",
      "        [1.9162e-05, 2.2392e-04, 9.9969e-01, 6.2938e-05],\n",
      "        [4.5188e-05, 2.0758e-04, 9.9970e-01, 4.4031e-05],\n",
      "        [2.5564e-05, 1.1298e-04, 9.9985e-01, 1.6269e-05],\n",
      "        [2.6643e-05, 2.6215e-04, 9.9969e-01, 1.7801e-05],\n",
      "        [4.8668e-05, 3.8614e-04, 9.9950e-01, 6.6093e-05],\n",
      "        [2.1176e-05, 1.8045e-04, 9.9978e-01, 2.1618e-05],\n",
      "        [5.7264e-05, 4.9932e-04, 9.9937e-01, 7.7756e-05],\n",
      "        [2.8424e-05, 1.2660e-04, 9.9982e-01, 2.7964e-05],\n",
      "        [5.6984e-06, 1.4882e-04, 9.9981e-01, 3.4301e-05],\n",
      "        [2.0073e-05, 3.0357e-04, 9.9960e-01, 7.3786e-05],\n",
      "        [1.3981e-05, 1.2991e-04, 9.9981e-01, 4.4815e-05],\n",
      "        [1.7685e-05, 1.1685e-04, 9.9983e-01, 3.9890e-05],\n",
      "        [1.1743e-05, 5.2794e-05, 9.9992e-01, 1.3998e-05],\n",
      "        [1.8253e-05, 2.1956e-04, 9.9975e-01, 1.2846e-05],\n",
      "        [9.2558e-06, 1.3505e-04, 9.9984e-01, 1.1470e-05],\n",
      "        [1.4186e-05, 1.4001e-04, 9.9981e-01, 3.5693e-05],\n",
      "        [1.7290e-05, 2.4355e-04, 9.9972e-01, 1.6215e-05],\n",
      "        [1.5908e-05, 4.2253e-05, 9.9992e-01, 2.0173e-05],\n",
      "        [1.0650e-05, 2.3508e-04, 9.9973e-01, 2.5078e-05],\n",
      "        [3.7442e-05, 2.6275e-04, 9.9965e-01, 5.2233e-05],\n",
      "        [2.4957e-05, 3.4100e-04, 9.9960e-01, 3.4487e-05],\n",
      "        [1.0793e-05, 4.1499e-04, 9.9949e-01, 8.2467e-05],\n",
      "        [6.0670e-05, 2.7634e-04, 9.9962e-01, 3.8206e-05],\n",
      "        [1.2396e-04, 2.9393e-04, 9.9953e-01, 4.7930e-05],\n",
      "        [1.9267e-04, 1.1832e-03, 9.9856e-01, 6.1127e-05],\n",
      "        [1.5553e-05, 4.5585e-04, 9.9947e-01, 6.0675e-05],\n",
      "        [1.1804e-05, 1.1006e-04, 9.9985e-01, 2.6441e-05],\n",
      "        [4.5040e-06, 2.1567e-04, 9.9975e-01, 3.4058e-05],\n",
      "        [6.5212e-06, 2.9975e-05, 9.9996e-01, 5.2067e-06],\n",
      "        [1.0053e-05, 1.5986e-04, 9.9979e-01, 4.0663e-05],\n",
      "        [3.7935e-05, 2.1034e-04, 9.9970e-01, 4.8420e-05],\n",
      "        [1.0728e-05, 1.8666e-04, 9.9978e-01, 2.2576e-05],\n",
      "        [2.2763e-05, 2.0374e-04, 9.9974e-01, 3.0645e-05],\n",
      "        [1.1658e-04, 1.8812e-04, 9.9967e-01, 2.6380e-05],\n",
      "        [3.7519e-06, 5.4401e-05, 9.9994e-01, 6.8837e-06],\n",
      "        [5.0710e-05, 1.2103e-04, 9.9974e-01, 8.6996e-05],\n",
      "        [2.6275e-04, 1.3639e-03, 9.9827e-01, 1.0125e-04],\n",
      "        [2.2944e-05, 1.3931e-04, 9.9981e-01, 2.7391e-05],\n",
      "        [1.3678e-04, 5.7640e-04, 9.9924e-01, 5.1179e-05],\n",
      "        [3.1309e-05, 2.3376e-04, 9.9971e-01, 2.1759e-05],\n",
      "        [2.0127e-05, 1.0692e-04, 9.9983e-01, 4.1186e-05],\n",
      "        [9.0049e-06, 8.0653e-05, 9.9989e-01, 2.3889e-05],\n",
      "        [4.7256e-05, 4.4857e-04, 9.9945e-01, 5.8990e-05],\n",
      "        [5.2387e-06, 8.6190e-05, 9.9986e-01, 5.2629e-05],\n",
      "        [1.4208e-05, 1.3758e-04, 9.9983e-01, 1.7542e-05],\n",
      "        [7.6820e-06, 2.3361e-04, 9.9974e-01, 1.4368e-05],\n",
      "        [1.4235e-05, 1.7953e-04, 9.9973e-01, 7.1922e-05],\n",
      "        [3.4496e-05, 9.7680e-05, 9.9977e-01, 9.9499e-05],\n",
      "        [2.2728e-05, 1.2007e-04, 9.9984e-01, 1.4746e-05],\n",
      "        [1.5440e-05, 1.3280e-04, 9.9981e-01, 4.5817e-05],\n",
      "        [1.6696e-05, 1.2523e-04, 9.9980e-01, 5.8677e-05],\n",
      "        [3.9106e-05, 2.2158e-04, 9.9969e-01, 4.4585e-05],\n",
      "        [2.0080e-05, 2.8319e-04, 9.9967e-01, 3.1216e-05],\n",
      "        [1.6607e-04, 4.9293e-04, 9.9928e-01, 5.8208e-05],\n",
      "        [1.8970e-05, 2.9910e-04, 9.9961e-01, 7.7039e-05],\n",
      "        [2.9484e-05, 4.2379e-04, 9.9949e-01, 5.9223e-05],\n",
      "        [7.6509e-05, 1.5541e-04, 9.9974e-01, 3.0689e-05],\n",
      "        [3.1663e-05, 9.9671e-05, 9.9984e-01, 3.2142e-05],\n",
      "        [7.6154e-05, 5.1581e-04, 9.9935e-01, 5.5787e-05],\n",
      "        [2.4579e-05, 2.8565e-04, 9.9966e-01, 2.6261e-05],\n",
      "        [1.3916e-05, 1.1965e-04, 9.9984e-01, 2.6270e-05],\n",
      "        [1.1406e-05, 3.5860e-04, 9.9955e-01, 8.4134e-05],\n",
      "        [2.8490e-05, 1.7427e-04, 9.9978e-01, 1.6101e-05],\n",
      "        [4.1574e-05, 7.5041e-05, 9.9979e-01, 9.1718e-05],\n",
      "        [1.1412e-05, 1.4322e-04, 9.9980e-01, 4.1361e-05],\n",
      "        [1.0891e-05, 1.3120e-04, 9.9984e-01, 2.0720e-05],\n",
      "        [1.0909e-05, 1.0194e-04, 9.9987e-01, 2.1545e-05],\n",
      "        [2.8855e-05, 2.3361e-04, 9.9967e-01, 6.6365e-05],\n",
      "        [5.8417e-06, 8.5187e-05, 9.9989e-01, 1.8546e-05],\n",
      "        [3.8692e-05, 2.0112e-04, 9.9962e-01, 1.3965e-04],\n",
      "        [8.4542e-06, 1.3926e-04, 9.9980e-01, 5.6814e-05],\n",
      "        [4.3250e-05, 8.0854e-05, 9.9986e-01, 1.5763e-05],\n",
      "        [9.8974e-06, 7.2872e-05, 9.9986e-01, 5.7180e-05],\n",
      "        [3.3619e-05, 7.1986e-04, 9.9921e-01, 3.8373e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.9887e-08, 2.1797e-08, 2.1808e-05, 9.9998e-01],\n",
      "        [6.2712e-08, 2.6977e-08, 2.2924e-05, 9.9998e-01],\n",
      "        [7.5194e-08, 1.9687e-08, 5.6841e-06, 9.9999e-01],\n",
      "        [4.0145e-08, 4.3977e-08, 4.2346e-05, 9.9996e-01],\n",
      "        [3.3685e-07, 4.5685e-07, 3.6912e-04, 9.9963e-01],\n",
      "        [1.4965e-07, 7.9780e-08, 3.3117e-05, 9.9997e-01],\n",
      "        [5.2470e-08, 1.1936e-07, 3.1926e-05, 9.9997e-01],\n",
      "        [1.2157e-07, 1.7966e-07, 9.5803e-05, 9.9990e-01],\n",
      "        [9.9007e-08, 5.7511e-08, 1.5128e-05, 9.9998e-01],\n",
      "        [1.2062e-08, 3.3303e-08, 8.1510e-06, 9.9999e-01],\n",
      "        [5.1821e-08, 6.1425e-08, 2.5367e-05, 9.9997e-01],\n",
      "        [2.0001e-07, 9.0554e-07, 6.5459e-04, 9.9934e-01],\n",
      "        [5.9390e-08, 3.2135e-07, 2.7702e-04, 9.9972e-01],\n",
      "        [4.6888e-08, 2.9418e-08, 5.5102e-06, 9.9999e-01],\n",
      "        [9.5362e-08, 6.2425e-08, 5.6664e-05, 9.9994e-01],\n",
      "        [7.1291e-08, 2.0053e-07, 1.3050e-04, 9.9987e-01],\n",
      "        [1.7370e-07, 3.0290e-07, 1.2340e-04, 9.9988e-01],\n",
      "        [3.6090e-08, 4.2814e-08, 2.8966e-05, 9.9997e-01],\n",
      "        [5.7044e-08, 6.3301e-08, 5.3450e-05, 9.9995e-01],\n",
      "        [7.4088e-08, 5.3663e-08, 4.7308e-05, 9.9995e-01],\n",
      "        [2.0201e-08, 8.4120e-08, 2.9831e-05, 9.9997e-01],\n",
      "        [1.1703e-07, 3.8829e-07, 2.4983e-05, 9.9997e-01],\n",
      "        [6.0367e-08, 6.1798e-08, 3.8396e-05, 9.9996e-01],\n",
      "        [2.7331e-08, 8.0757e-08, 2.2793e-05, 9.9998e-01],\n",
      "        [3.1521e-08, 3.0399e-08, 1.0344e-05, 9.9999e-01],\n",
      "        [9.6739e-08, 7.7186e-08, 1.0405e-04, 9.9990e-01],\n",
      "        [7.4662e-08, 9.4922e-08, 3.5343e-05, 9.9996e-01],\n",
      "        [6.3945e-08, 5.4457e-08, 1.1192e-06, 1.0000e+00],\n",
      "        [2.8860e-08, 6.8319e-08, 2.7883e-05, 9.9997e-01],\n",
      "        [3.2807e-08, 1.9058e-08, 1.9595e-05, 9.9998e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.7354) tokens processed per second.\n",
      "Discriminator loss: tensor([[5.4049e-07, 1.0000e+00, 9.5611e-08, 1.8503e-06],\n",
      "        [5.1685e-07, 1.0000e+00, 1.2551e-07, 1.0809e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.0436e-08, 2.5741e-10, 2.2671e-08],\n",
      "        [1.0000e+00, 4.8394e-08, 1.9162e-10, 1.5945e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.3402e-05, 7.2024e-05, 9.9990e-01, 1.0316e-05],\n",
      "        [4.0402e-06, 2.0222e-05, 9.9996e-01, 1.3944e-05],\n",
      "        [3.9124e-06, 4.8236e-05, 9.9993e-01, 2.2622e-05],\n",
      "        [1.3946e-05, 6.5290e-05, 9.9990e-01, 2.0502e-05],\n",
      "        [2.2803e-05, 1.5001e-04, 9.9979e-01, 4.1844e-05],\n",
      "        [3.7323e-05, 5.8733e-05, 9.9982e-01, 8.0192e-05],\n",
      "        [4.5315e-05, 3.2897e-04, 9.9957e-01, 6.0100e-05],\n",
      "        [1.5054e-05, 1.4006e-04, 9.9982e-01, 2.8275e-05],\n",
      "        [3.2071e-05, 2.2450e-04, 9.9971e-01, 3.4782e-05],\n",
      "        [9.2475e-06, 1.4471e-04, 9.9981e-01, 3.1464e-05],\n",
      "        [2.8348e-05, 1.0266e-04, 9.9984e-01, 2.7380e-05],\n",
      "        [5.8404e-05, 2.0964e-04, 9.9969e-01, 4.2667e-05],\n",
      "        [1.6121e-05, 7.4019e-05, 9.9989e-01, 1.9024e-05],\n",
      "        [1.0220e-04, 4.9412e-04, 9.9935e-01, 5.0375e-05],\n",
      "        [2.8352e-05, 2.3927e-04, 9.9971e-01, 2.6341e-05],\n",
      "        [2.8997e-05, 2.2606e-04, 9.9973e-01, 1.8400e-05],\n",
      "        [1.5751e-05, 1.7439e-04, 9.9977e-01, 4.4495e-05],\n",
      "        [4.1707e-06, 4.7238e-05, 9.9992e-01, 2.7522e-05],\n",
      "        [2.2012e-05, 1.2031e-04, 9.9982e-01, 3.8684e-05],\n",
      "        [9.3683e-06, 9.3631e-05, 9.9989e-01, 7.1911e-06],\n",
      "        [3.0064e-06, 4.1266e-05, 9.9994e-01, 1.8620e-05],\n",
      "        [5.4291e-06, 2.1629e-04, 9.9968e-01, 9.4412e-05],\n",
      "        [2.3035e-05, 5.7185e-05, 9.9988e-01, 3.5267e-05],\n",
      "        [1.6839e-05, 1.7781e-04, 9.9976e-01, 4.2025e-05],\n",
      "        [9.8834e-06, 1.1880e-04, 9.9980e-01, 7.0572e-05],\n",
      "        [5.8591e-05, 1.0236e-04, 9.9975e-01, 8.7922e-05],\n",
      "        [1.6180e-05, 1.1537e-04, 9.9984e-01, 2.7344e-05],\n",
      "        [6.2615e-06, 6.4228e-05, 9.9992e-01, 1.3507e-05],\n",
      "        [1.4986e-05, 6.5760e-05, 9.9975e-01, 1.6758e-04],\n",
      "        [7.2121e-06, 1.0071e-04, 9.9987e-01, 2.4522e-05],\n",
      "        [8.7569e-06, 6.3219e-05, 9.9988e-01, 5.0812e-05],\n",
      "        [1.4216e-05, 1.0656e-04, 9.9983e-01, 4.5181e-05],\n",
      "        [1.6957e-05, 1.1582e-04, 9.9983e-01, 3.9419e-05],\n",
      "        [7.2022e-06, 8.0130e-05, 9.9990e-01, 1.0283e-05],\n",
      "        [6.0337e-06, 1.1701e-04, 9.9986e-01, 1.4317e-05],\n",
      "        [1.2442e-05, 1.0101e-04, 9.9985e-01, 3.4260e-05],\n",
      "        [1.3258e-04, 3.6151e-04, 9.9943e-01, 7.2592e-05],\n",
      "        [1.8053e-05, 1.5119e-04, 9.9978e-01, 4.9731e-05],\n",
      "        [9.5490e-05, 1.6382e-04, 9.9970e-01, 3.9866e-05],\n",
      "        [6.3819e-06, 4.7034e-05, 9.9993e-01, 1.3956e-05],\n",
      "        [1.6576e-05, 1.2753e-04, 9.9984e-01, 2.0625e-05],\n",
      "        [3.2068e-05, 1.3729e-04, 9.9980e-01, 3.3917e-05],\n",
      "        [6.1552e-06, 5.1360e-05, 9.9993e-01, 1.0060e-05],\n",
      "        [1.0742e-05, 5.4844e-05, 9.9992e-01, 1.1283e-05],\n",
      "        [3.3085e-04, 4.1322e-04, 9.9919e-01, 6.7640e-05],\n",
      "        [9.5206e-06, 1.5107e-04, 9.9982e-01, 2.1043e-05],\n",
      "        [9.8023e-06, 2.4559e-04, 9.9964e-01, 1.0103e-04],\n",
      "        [5.6790e-05, 1.9889e-04, 9.9965e-01, 9.1277e-05],\n",
      "        [1.8815e-05, 1.2771e-04, 9.9983e-01, 2.8167e-05],\n",
      "        [2.0912e-04, 3.6150e-04, 9.9936e-01, 6.7399e-05],\n",
      "        [3.5754e-06, 1.8550e-05, 9.9997e-01, 1.0649e-05],\n",
      "        [4.2660e-05, 2.4755e-04, 9.9961e-01, 9.7625e-05],\n",
      "        [1.4247e-04, 4.1425e-04, 9.9931e-01, 1.2868e-04],\n",
      "        [7.0823e-05, 1.6473e-04, 9.9973e-01, 3.1910e-05],\n",
      "        [1.1870e-05, 9.9327e-05, 9.9988e-01, 1.2218e-05],\n",
      "        [7.5546e-06, 1.3196e-04, 9.9984e-01, 2.2082e-05],\n",
      "        [3.5418e-06, 4.7445e-05, 9.9993e-01, 1.4872e-05],\n",
      "        [5.4371e-05, 3.5225e-04, 9.9955e-01, 4.6124e-05],\n",
      "        [2.4663e-05, 4.3579e-04, 9.9947e-01, 6.6281e-05],\n",
      "        [1.3873e-05, 9.7974e-05, 9.9983e-01, 5.4546e-05],\n",
      "        [4.9110e-06, 1.1725e-04, 9.9985e-01, 2.5660e-05],\n",
      "        [3.1700e-05, 2.0960e-04, 9.9962e-01, 1.3810e-04],\n",
      "        [2.4995e-05, 8.7233e-05, 9.9987e-01, 2.0419e-05],\n",
      "        [1.0821e-03, 1.0068e-03, 9.9773e-01, 1.7912e-04],\n",
      "        [9.3341e-06, 9.7605e-05, 9.9986e-01, 3.5910e-05],\n",
      "        [7.1469e-05, 2.6959e-04, 9.9956e-01, 1.0382e-04],\n",
      "        [1.3287e-05, 2.1912e-04, 9.9974e-01, 2.5469e-05],\n",
      "        [1.6238e-05, 1.1114e-04, 9.9979e-01, 8.7496e-05],\n",
      "        [1.0202e-05, 1.9687e-04, 9.9973e-01, 6.4432e-05],\n",
      "        [3.3132e-05, 2.3565e-04, 9.9966e-01, 6.9119e-05],\n",
      "        [1.4377e-05, 1.4370e-04, 9.9982e-01, 2.5951e-05],\n",
      "        [2.9675e-05, 1.4003e-04, 9.9977e-01, 6.5194e-05],\n",
      "        [2.1407e-05, 6.2199e-05, 9.9989e-01, 2.1614e-05],\n",
      "        [1.5161e-05, 1.3952e-04, 9.9981e-01, 3.4953e-05],\n",
      "        [3.0992e-05, 2.4168e-04, 9.9962e-01, 1.0458e-04],\n",
      "        [1.2577e-05, 1.1355e-04, 9.9985e-01, 1.8911e-05],\n",
      "        [3.2493e-05, 1.2647e-04, 9.9983e-01, 1.5577e-05],\n",
      "        [5.3356e-06, 7.6296e-05, 9.9990e-01, 2.2399e-05],\n",
      "        [5.2702e-05, 1.2189e-04, 9.9979e-01, 3.7920e-05],\n",
      "        [1.0247e-05, 6.0727e-05, 9.9987e-01, 5.7372e-05],\n",
      "        [3.2206e-05, 1.3364e-04, 9.9978e-01, 4.9340e-05],\n",
      "        [6.5511e-06, 1.0195e-04, 9.9988e-01, 1.1556e-05],\n",
      "        [1.6861e-05, 8.0710e-05, 9.9987e-01, 3.4081e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.7401e-08, 1.0609e-08, 4.2629e-06, 1.0000e+00],\n",
      "        [2.3559e-09, 5.4809e-09, 8.2141e-07, 1.0000e+00],\n",
      "        [2.9263e-07, 1.2942e-07, 8.5404e-05, 9.9991e-01],\n",
      "        [9.7529e-08, 1.6336e-07, 2.3591e-04, 9.9976e-01],\n",
      "        [3.3642e-08, 9.6895e-08, 6.3020e-05, 9.9994e-01],\n",
      "        [3.7388e-08, 9.1876e-08, 4.5457e-04, 9.9955e-01],\n",
      "        [1.7493e-07, 8.5273e-08, 5.2458e-05, 9.9995e-01],\n",
      "        [2.2101e-08, 2.8869e-08, 2.9943e-06, 1.0000e+00],\n",
      "        [1.3902e-08, 2.0707e-08, 4.7567e-06, 1.0000e+00],\n",
      "        [8.5280e-09, 2.7773e-08, 3.4927e-06, 1.0000e+00],\n",
      "        [1.9150e-07, 1.7805e-07, 8.5063e-05, 9.9991e-01],\n",
      "        [3.3143e-10, 5.3928e-09, 1.6938e-07, 1.0000e+00],\n",
      "        [3.4569e-08, 2.6932e-08, 4.1187e-05, 9.9996e-01],\n",
      "        [2.1998e-08, 1.5754e-08, 1.6084e-05, 9.9998e-01],\n",
      "        [5.9605e-09, 3.8411e-09, 1.7957e-06, 1.0000e+00],\n",
      "        [2.0644e-08, 1.1067e-08, 8.8010e-06, 9.9999e-01],\n",
      "        [1.5743e-07, 7.8825e-08, 1.7668e-04, 9.9982e-01],\n",
      "        [5.3990e-09, 6.6301e-09, 3.7153e-07, 1.0000e+00],\n",
      "        [1.9274e-06, 2.0319e-07, 1.0634e-04, 9.9989e-01],\n",
      "        [2.6075e-07, 1.0207e-07, 3.8757e-04, 9.9961e-01],\n",
      "        [9.0625e-08, 1.2691e-07, 5.9998e-05, 9.9994e-01],\n",
      "        [6.0876e-08, 2.0147e-08, 3.7951e-06, 1.0000e+00],\n",
      "        [4.0888e-08, 2.2138e-08, 2.5107e-05, 9.9997e-01],\n",
      "        [9.0435e-08, 2.2793e-08, 2.7790e-06, 1.0000e+00],\n",
      "        [2.0961e-07, 1.0706e-07, 1.6747e-05, 9.9998e-01],\n",
      "        [1.6038e-08, 1.9285e-08, 5.6191e-06, 9.9999e-01],\n",
      "        [6.3256e-08, 1.7780e-08, 4.0413e-05, 9.9996e-01],\n",
      "        [1.1438e-07, 1.0758e-07, 2.2197e-04, 9.9978e-01],\n",
      "        [1.6807e-07, 1.4019e-07, 1.1516e-04, 9.9988e-01],\n",
      "        [4.2563e-09, 8.8893e-09, 3.2810e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.1195) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.5442e-07, 1.0000e+00, 4.0483e-08, 9.2873e-07],\n",
      "        [6.8829e-08, 1.0000e+00, 2.1747e-08, 4.7678e-07],\n",
      "        [1.4902e-06, 9.9999e-01, 5.7344e-07, 4.3556e-06],\n",
      "        [1.1805e-07, 1.0000e+00, 7.5782e-08, 1.4484e-06],\n",
      "        [3.5844e-06, 1.0000e+00, 1.2626e-07, 9.0562e-07],\n",
      "        [1.4193e-07, 1.0000e+00, 5.4463e-08, 1.2686e-06],\n",
      "        [2.1725e-07, 1.0000e+00, 4.8301e-08, 1.1606e-06],\n",
      "        [5.7954e-04, 9.9930e-01, 9.5151e-05, 2.2602e-05],\n",
      "        [1.2154e-06, 1.0000e+00, 6.9020e-07, 2.4058e-06],\n",
      "        [1.3289e-07, 1.0000e+00, 2.9526e-08, 1.0520e-06],\n",
      "        [3.1136e-07, 1.0000e+00, 1.2365e-07, 9.6583e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 5.8952e-07, 2.8414e-07, 1.7591e-07],\n",
      "        [9.9999e-01, 8.1403e-06, 3.1972e-07, 3.3316e-07],\n",
      "        [1.0000e+00, 2.6569e-06, 5.5090e-07, 9.8678e-07],\n",
      "        [9.9994e-01, 5.3492e-05, 9.4314e-07, 1.2001e-06],\n",
      "        [1.0000e+00, 1.9089e-06, 2.2364e-07, 1.1589e-07],\n",
      "        [1.0000e+00, 1.1825e-06, 3.9688e-07, 1.5586e-07],\n",
      "        [1.0000e+00, 3.0423e-06, 1.0507e-06, 2.4373e-07],\n",
      "        [1.0000e+00, 1.2139e-06, 5.6922e-07, 3.0811e-07],\n",
      "        [1.0000e+00, 1.5193e-06, 2.7860e-07, 2.0692e-07],\n",
      "        [1.0000e+00, 2.2249e-06, 3.4870e-07, 3.3650e-07],\n",
      "        [1.0000e+00, 2.7503e-06, 8.8228e-07, 2.8920e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.9945e-06, 1.3275e-04, 9.9986e-01, 7.7561e-06],\n",
      "        [1.1329e-05, 2.0440e-04, 9.9973e-01, 5.3645e-05],\n",
      "        [1.2292e-05, 6.9956e-05, 9.9987e-01, 4.4434e-05],\n",
      "        [8.6787e-05, 4.7998e-04, 9.9936e-01, 7.7697e-05],\n",
      "        [4.6398e-06, 7.1191e-05, 9.9990e-01, 2.2709e-05],\n",
      "        [5.8699e-06, 3.6106e-05, 9.9995e-01, 1.0187e-05],\n",
      "        [8.6737e-06, 1.2828e-04, 9.9980e-01, 5.9210e-05],\n",
      "        [2.4593e-06, 2.3289e-05, 9.9993e-01, 4.0386e-05],\n",
      "        [1.3384e-06, 3.4670e-05, 9.9993e-01, 3.1549e-05],\n",
      "        [8.5188e-06, 6.1160e-05, 9.9987e-01, 5.7515e-05],\n",
      "        [6.9417e-06, 3.9293e-05, 9.9992e-01, 3.7054e-05],\n",
      "        [1.4115e-06, 6.0201e-05, 9.9991e-01, 3.2001e-05],\n",
      "        [2.7107e-05, 1.3408e-04, 9.9979e-01, 5.0525e-05],\n",
      "        [5.5131e-06, 7.9360e-05, 9.9989e-01, 2.0256e-05],\n",
      "        [1.9272e-06, 4.3683e-05, 9.9991e-01, 4.8059e-05],\n",
      "        [3.7611e-06, 1.8015e-05, 9.9995e-01, 2.6711e-05],\n",
      "        [1.5483e-05, 1.0360e-04, 9.9986e-01, 1.7411e-05],\n",
      "        [1.3762e-05, 3.6823e-05, 9.9994e-01, 9.9312e-06],\n",
      "        [2.4937e-05, 2.8316e-04, 9.9963e-01, 6.0423e-05],\n",
      "        [4.9679e-06, 7.4155e-05, 9.9985e-01, 7.3270e-05],\n",
      "        [3.5223e-06, 1.2557e-04, 9.9985e-01, 2.0681e-05],\n",
      "        [1.2363e-05, 4.1736e-05, 9.9994e-01, 8.0374e-06],\n",
      "        [8.1969e-06, 8.6773e-05, 9.9988e-01, 2.8215e-05],\n",
      "        [4.5921e-06, 5.6230e-05, 9.9993e-01, 8.1650e-06],\n",
      "        [8.5918e-05, 1.1877e-04, 9.9977e-01, 2.3816e-05],\n",
      "        [1.1023e-05, 6.8257e-05, 9.9989e-01, 2.7406e-05],\n",
      "        [5.3264e-06, 1.0785e-04, 9.9986e-01, 2.5888e-05],\n",
      "        [1.4010e-04, 4.3854e-04, 9.9937e-01, 5.2579e-05],\n",
      "        [4.2179e-06, 4.4590e-05, 9.9994e-01, 1.3749e-05],\n",
      "        [5.8655e-06, 5.0663e-05, 9.9993e-01, 1.3227e-05],\n",
      "        [3.0200e-05, 4.0802e-05, 9.9991e-01, 1.4625e-05],\n",
      "        [2.4412e-04, 8.1695e-04, 9.9887e-01, 7.2289e-05],\n",
      "        [7.3977e-06, 7.3704e-05, 9.9990e-01, 1.9331e-05],\n",
      "        [3.6331e-04, 1.0668e-03, 9.9853e-01, 3.9109e-05],\n",
      "        [6.9875e-06, 1.4907e-04, 9.9981e-01, 2.9572e-05],\n",
      "        [1.7962e-05, 2.2992e-04, 9.9962e-01, 1.3458e-04],\n",
      "        [1.4409e-05, 8.1883e-05, 9.9988e-01, 2.6285e-05],\n",
      "        [1.0997e-05, 2.1306e-04, 9.9972e-01, 5.1058e-05],\n",
      "        [5.8357e-06, 6.7732e-05, 9.9991e-01, 1.9997e-05],\n",
      "        [4.8403e-06, 5.4957e-05, 9.9993e-01, 1.3398e-05],\n",
      "        [7.1494e-06, 6.7984e-05, 9.9991e-01, 1.6796e-05],\n",
      "        [6.0652e-05, 3.5659e-04, 9.9955e-01, 3.6854e-05],\n",
      "        [9.7087e-07, 1.9236e-05, 9.9997e-01, 1.1156e-05],\n",
      "        [7.3803e-06, 4.7722e-05, 9.9992e-01, 2.6816e-05],\n",
      "        [1.7789e-06, 4.7488e-05, 9.9993e-01, 2.4279e-05],\n",
      "        [6.8109e-06, 3.1179e-05, 9.9995e-01, 9.4263e-06],\n",
      "        [3.1442e-06, 6.5539e-05, 9.9991e-01, 1.7956e-05],\n",
      "        [4.0807e-06, 8.3388e-05, 9.9989e-01, 2.5180e-05],\n",
      "        [9.8228e-06, 3.0788e-04, 9.9963e-01, 5.4455e-05],\n",
      "        [2.8900e-06, 8.2047e-05, 9.9988e-01, 3.5533e-05],\n",
      "        [7.3322e-06, 1.3190e-04, 9.9983e-01, 3.3975e-05],\n",
      "        [8.3441e-05, 1.2729e-04, 9.9976e-01, 2.9869e-05],\n",
      "        [1.6282e-05, 7.3761e-05, 9.9988e-01, 3.1583e-05],\n",
      "        [3.0670e-06, 4.9401e-05, 9.9994e-01, 1.1127e-05],\n",
      "        [8.6143e-06, 3.8354e-05, 9.9994e-01, 9.1197e-06],\n",
      "        [1.1237e-05, 7.1100e-05, 9.9983e-01, 8.8985e-05],\n",
      "        [1.4309e-05, 1.9997e-04, 9.9977e-01, 1.9637e-05],\n",
      "        [2.6484e-05, 1.3564e-04, 9.9979e-01, 4.6591e-05],\n",
      "        [7.2930e-06, 2.1834e-04, 9.9972e-01, 5.4993e-05],\n",
      "        [1.3295e-05, 1.0370e-04, 9.9985e-01, 3.1635e-05],\n",
      "        [3.5610e-06, 3.6109e-05, 9.9995e-01, 1.1892e-05],\n",
      "        [2.5378e-05, 2.2593e-04, 9.9971e-01, 3.3792e-05],\n",
      "        [2.5329e-05, 1.5597e-04, 9.9979e-01, 2.4825e-05],\n",
      "        [7.5994e-06, 1.5812e-04, 9.9979e-01, 4.1229e-05],\n",
      "        [1.8619e-06, 5.2108e-05, 9.9991e-01, 3.3678e-05],\n",
      "        [5.6819e-06, 1.3062e-04, 9.9985e-01, 9.2951e-06],\n",
      "        [1.1611e-05, 8.4187e-05, 9.9989e-01, 1.5290e-05],\n",
      "        [1.7233e-05, 1.3773e-04, 9.9982e-01, 2.8142e-05],\n",
      "        [1.9966e-05, 1.2080e-04, 9.9983e-01, 2.9669e-05],\n",
      "        [1.3439e-05, 1.1888e-04, 9.9982e-01, 4.3285e-05],\n",
      "        [1.6192e-06, 3.0906e-05, 9.9996e-01, 9.9518e-06],\n",
      "        [4.0613e-05, 3.6699e-04, 9.9953e-01, 5.9225e-05],\n",
      "        [9.8368e-06, 8.7419e-05, 9.9987e-01, 3.1621e-05],\n",
      "        [1.7793e-06, 2.2371e-05, 9.9997e-01, 5.0856e-06],\n",
      "        [5.4991e-05, 7.8200e-04, 9.9900e-01, 1.6007e-04],\n",
      "        [1.6990e-06, 1.5103e-04, 9.9982e-01, 2.6944e-05],\n",
      "        [4.3180e-06, 3.3351e-05, 9.9994e-01, 1.7677e-05],\n",
      "        [1.0509e-05, 1.1280e-04, 9.9985e-01, 2.8944e-05],\n",
      "        [6.9569e-06, 1.5824e-04, 9.9980e-01, 3.3472e-05],\n",
      "        [2.3246e-06, 6.6743e-05, 9.9991e-01, 1.8990e-05],\n",
      "        [4.2027e-05, 1.3931e-04, 9.9977e-01, 4.4109e-05],\n",
      "        [1.0747e-05, 1.0590e-04, 9.9985e-01, 3.0223e-05],\n",
      "        [4.3111e-06, 6.0507e-05, 9.9991e-01, 2.0471e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[8.3086e-08, 8.9228e-08, 4.8311e-05, 9.9995e-01],\n",
      "        [5.7034e-09, 1.3850e-08, 1.7450e-06, 1.0000e+00],\n",
      "        [2.2632e-09, 2.2064e-09, 8.9460e-07, 1.0000e+00],\n",
      "        [1.1405e-09, 4.0633e-09, 1.0029e-06, 1.0000e+00],\n",
      "        [6.3446e-09, 5.4061e-09, 3.5182e-06, 1.0000e+00],\n",
      "        [2.7647e-09, 1.4757e-08, 4.5647e-06, 1.0000e+00],\n",
      "        [1.0752e-08, 2.2841e-08, 1.1232e-05, 9.9999e-01],\n",
      "        [4.0064e-09, 5.1336e-09, 1.8656e-06, 1.0000e+00],\n",
      "        [5.8196e-07, 1.1793e-07, 2.0322e-04, 9.9980e-01],\n",
      "        [2.6673e-09, 6.2130e-09, 2.6721e-06, 1.0000e+00],\n",
      "        [6.7118e-09, 4.8523e-09, 1.2783e-06, 1.0000e+00],\n",
      "        [6.9140e-09, 1.2621e-08, 9.9405e-06, 9.9999e-01],\n",
      "        [2.6079e-08, 1.1847e-08, 1.0313e-05, 9.9999e-01],\n",
      "        [4.8906e-09, 1.0146e-08, 2.8729e-06, 1.0000e+00],\n",
      "        [1.0663e-08, 1.1477e-08, 4.9278e-05, 9.9995e-01],\n",
      "        [8.3404e-09, 1.0404e-08, 8.9573e-06, 9.9999e-01],\n",
      "        [7.9719e-09, 1.3527e-08, 1.2432e-05, 9.9999e-01],\n",
      "        [9.9032e-09, 7.1411e-09, 4.7626e-06, 1.0000e+00],\n",
      "        [3.7794e-08, 8.2462e-09, 2.0020e-06, 1.0000e+00],\n",
      "        [1.2536e-08, 2.2811e-08, 5.9812e-07, 1.0000e+00],\n",
      "        [2.1121e-08, 3.2976e-08, 1.0472e-05, 9.9999e-01],\n",
      "        [3.7682e-09, 8.5023e-09, 7.5400e-06, 9.9999e-01],\n",
      "        [2.2816e-08, 3.7127e-09, 8.6007e-07, 1.0000e+00],\n",
      "        [2.0892e-08, 3.7956e-08, 1.1555e-05, 9.9999e-01],\n",
      "        [1.9685e-09, 1.1916e-09, 4.8002e-07, 1.0000e+00],\n",
      "        [1.4913e-08, 1.1106e-08, 5.4192e-06, 9.9999e-01],\n",
      "        [2.9518e-09, 3.3343e-09, 2.6492e-07, 1.0000e+00],\n",
      "        [9.3808e-10, 4.2213e-09, 1.2634e-06, 1.0000e+00],\n",
      "        [1.4085e-08, 5.1770e-09, 9.7083e-06, 9.9999e-01],\n",
      "        [3.2700e-09, 1.6795e-09, 4.3929e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.6987) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.0776e-06, 1.0000e+00, 2.0206e-07, 1.2891e-06],\n",
      "        [1.2453e-06, 9.9999e-01, 3.2483e-07, 3.9253e-06],\n",
      "        [1.2735e-07, 1.0000e+00, 4.6456e-08, 9.4933e-07],\n",
      "        [2.5413e-06, 9.9999e-01, 7.2620e-07, 2.2959e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[9.9996e-01, 4.2112e-05, 4.8404e-09, 8.1072e-07],\n",
      "        [1.0000e+00, 5.5191e-08, 2.4229e-10, 4.9339e-08],\n",
      "        [1.0000e+00, 1.5435e-06, 2.7703e-10, 8.6717e-08],\n",
      "        [9.9990e-01, 9.6171e-05, 9.5875e-09, 4.0083e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[7.4443e-06, 4.0083e-05, 9.9994e-01, 9.8998e-06],\n",
      "        [2.2746e-05, 3.3780e-04, 9.9959e-01, 5.3554e-05],\n",
      "        [6.2077e-06, 7.8806e-05, 9.9990e-01, 1.4838e-05],\n",
      "        [2.5209e-05, 2.2094e-04, 9.9974e-01, 1.6831e-05],\n",
      "        [1.0937e-05, 2.6435e-04, 9.9962e-01, 9.9867e-05],\n",
      "        [2.1808e-05, 2.3811e-04, 9.9971e-01, 3.3280e-05],\n",
      "        [1.4876e-06, 5.4563e-05, 9.9993e-01, 1.3855e-05],\n",
      "        [1.3133e-05, 3.8480e-04, 9.9959e-01, 1.4985e-05],\n",
      "        [5.8556e-06, 3.2927e-05, 9.9996e-01, 6.0420e-06],\n",
      "        [5.2313e-05, 1.1062e-04, 9.9981e-01, 3.1666e-05],\n",
      "        [3.7579e-06, 3.8484e-05, 9.9995e-01, 8.7775e-06],\n",
      "        [3.8362e-06, 5.1379e-05, 9.9993e-01, 9.8892e-06],\n",
      "        [7.4069e-06, 1.8755e-04, 9.9979e-01, 1.9784e-05],\n",
      "        [3.0641e-06, 2.2039e-04, 9.9975e-01, 2.7669e-05],\n",
      "        [5.5047e-06, 4.4927e-05, 9.9993e-01, 1.7272e-05],\n",
      "        [1.0169e-05, 3.6152e-04, 9.9951e-01, 1.2315e-04],\n",
      "        [1.1991e-05, 3.9991e-05, 9.9992e-01, 3.0549e-05],\n",
      "        [5.2987e-05, 1.4835e-04, 9.9975e-01, 5.2815e-05],\n",
      "        [3.2832e-06, 2.8145e-04, 9.9969e-01, 2.5743e-05],\n",
      "        [5.7370e-06, 1.0087e-04, 9.9988e-01, 1.8145e-05],\n",
      "        [4.2292e-05, 3.9827e-04, 9.9953e-01, 3.4425e-05],\n",
      "        [1.6595e-05, 2.3322e-04, 9.9970e-01, 5.4125e-05],\n",
      "        [3.0246e-05, 3.8744e-04, 9.9954e-01, 4.5469e-05],\n",
      "        [1.4038e-05, 7.3126e-05, 9.9985e-01, 6.6998e-05],\n",
      "        [4.8877e-06, 4.3077e-05, 9.9994e-01, 1.6855e-05],\n",
      "        [1.6016e-05, 3.5477e-04, 9.9953e-01, 9.4297e-05],\n",
      "        [7.7379e-06, 7.6431e-05, 9.9989e-01, 2.4776e-05],\n",
      "        [2.5239e-05, 1.7369e-04, 9.9963e-01, 1.6653e-04],\n",
      "        [2.4742e-05, 1.7429e-04, 9.9974e-01, 5.5986e-05],\n",
      "        [6.9543e-06, 6.3596e-05, 9.9989e-01, 4.1390e-05],\n",
      "        [6.7715e-06, 8.1422e-05, 9.9989e-01, 2.3774e-05],\n",
      "        [2.3709e-06, 5.8846e-05, 9.9985e-01, 9.0050e-05],\n",
      "        [2.8171e-06, 9.7555e-05, 9.9989e-01, 1.1340e-05],\n",
      "        [8.3681e-06, 1.0028e-04, 9.9988e-01, 1.3317e-05],\n",
      "        [5.7722e-06, 3.7378e-05, 9.9993e-01, 2.5107e-05],\n",
      "        [1.3431e-05, 7.2357e-05, 9.9991e-01, 8.8753e-06],\n",
      "        [2.0880e-05, 4.0585e-04, 9.9955e-01, 1.9605e-05],\n",
      "        [6.5308e-06, 1.2601e-04, 9.9984e-01, 2.2912e-05],\n",
      "        [1.2058e-05, 1.3548e-04, 9.9983e-01, 2.4047e-05],\n",
      "        [2.7400e-06, 9.0151e-05, 9.9990e-01, 1.1853e-05],\n",
      "        [4.2708e-06, 4.5209e-05, 9.9994e-01, 1.3356e-05],\n",
      "        [3.3624e-05, 1.0086e-03, 9.9879e-01, 1.6621e-04],\n",
      "        [5.2243e-06, 2.9220e-05, 9.9996e-01, 9.2508e-06],\n",
      "        [1.4566e-05, 2.4690e-04, 9.9968e-01, 5.3771e-05],\n",
      "        [1.0681e-04, 2.9553e-04, 9.9954e-01, 6.0363e-05],\n",
      "        [6.9802e-06, 6.5372e-05, 9.9988e-01, 4.4914e-05],\n",
      "        [4.2308e-06, 9.2243e-05, 9.9989e-01, 1.5720e-05],\n",
      "        [1.9667e-05, 6.6220e-04, 9.9929e-01, 3.2469e-05],\n",
      "        [2.3135e-05, 4.1861e-04, 9.9946e-01, 9.9675e-05],\n",
      "        [1.0653e-05, 1.3706e-04, 9.9985e-01, 6.1617e-06],\n",
      "        [5.3665e-06, 9.4699e-05, 9.9988e-01, 1.7094e-05],\n",
      "        [2.0852e-05, 7.7612e-05, 9.9986e-01, 4.0252e-05],\n",
      "        [1.7891e-05, 2.7376e-04, 9.9967e-01, 3.8227e-05],\n",
      "        [1.1077e-05, 1.4915e-04, 9.9984e-01, 4.4420e-06],\n",
      "        [1.2338e-05, 2.0643e-04, 9.9976e-01, 2.3155e-05],\n",
      "        [6.3014e-05, 1.1591e-03, 9.9873e-01, 5.2298e-05],\n",
      "        [9.0073e-06, 3.0197e-04, 9.9963e-01, 6.3315e-05],\n",
      "        [1.9966e-06, 7.9002e-05, 9.9991e-01, 1.0982e-05],\n",
      "        [1.5635e-05, 4.5528e-04, 9.9950e-01, 3.3356e-05],\n",
      "        [1.1584e-05, 6.5665e-05, 9.9990e-01, 2.0574e-05],\n",
      "        [7.4922e-06, 1.2416e-04, 9.9984e-01, 2.8249e-05],\n",
      "        [8.4100e-05, 6.6195e-04, 9.9919e-01, 6.7285e-05],\n",
      "        [8.4163e-06, 6.7734e-05, 9.9991e-01, 1.4258e-05],\n",
      "        [1.0348e-04, 9.3905e-04, 9.9890e-01, 5.9276e-05],\n",
      "        [8.9343e-06, 1.9913e-04, 9.9976e-01, 2.9425e-05],\n",
      "        [5.5649e-06, 8.6742e-05, 9.9986e-01, 4.5814e-05],\n",
      "        [2.4624e-06, 1.8025e-05, 9.9997e-01, 7.3859e-06],\n",
      "        [4.6069e-06, 3.0180e-05, 9.9995e-01, 1.7720e-05],\n",
      "        [9.1025e-06, 1.0792e-04, 9.9985e-01, 2.8106e-05],\n",
      "        [4.9843e-06, 8.2817e-05, 9.9989e-01, 1.9835e-05],\n",
      "        [1.0885e-05, 3.1586e-04, 9.9963e-01, 4.6425e-05],\n",
      "        [6.3302e-06, 6.4078e-05, 9.9992e-01, 1.0943e-05],\n",
      "        [1.3386e-06, 5.7222e-05, 9.9992e-01, 2.0763e-05],\n",
      "        [9.1585e-06, 6.4276e-05, 9.9991e-01, 1.6642e-05],\n",
      "        [1.3893e-05, 3.2012e-04, 9.9965e-01, 1.5224e-05],\n",
      "        [2.1468e-05, 2.9885e-04, 9.9965e-01, 2.8868e-05],\n",
      "        [3.2565e-06, 1.3207e-04, 9.9984e-01, 2.6671e-05],\n",
      "        [4.6580e-06, 6.8798e-05, 9.9991e-01, 1.3515e-05],\n",
      "        [4.5497e-06, 1.4463e-04, 9.9983e-01, 1.8205e-05],\n",
      "        [3.8010e-05, 1.8079e-04, 9.9976e-01, 1.7705e-05],\n",
      "        [5.5646e-06, 8.6438e-05, 9.9989e-01, 1.4361e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.0247e-10, 1.9236e-09, 6.8090e-07, 1.0000e+00],\n",
      "        [1.1421e-08, 8.8031e-09, 1.0274e-06, 1.0000e+00],\n",
      "        [2.4566e-08, 2.3281e-08, 1.6476e-05, 9.9998e-01],\n",
      "        [1.8297e-08, 2.3709e-08, 4.2044e-05, 9.9996e-01],\n",
      "        [1.4590e-08, 1.8953e-09, 1.0930e-06, 1.0000e+00],\n",
      "        [9.1041e-09, 5.4555e-09, 5.8018e-06, 9.9999e-01],\n",
      "        [2.0124e-09, 4.1893e-09, 2.4045e-06, 1.0000e+00],\n",
      "        [1.0280e-09, 1.5909e-09, 3.5599e-07, 1.0000e+00],\n",
      "        [3.0743e-08, 7.2857e-09, 1.9057e-05, 9.9998e-01],\n",
      "        [2.6737e-09, 2.8509e-09, 3.3023e-07, 1.0000e+00],\n",
      "        [3.7173e-09, 9.0137e-09, 4.4729e-06, 1.0000e+00],\n",
      "        [1.1790e-09, 3.3475e-09, 4.2960e-07, 1.0000e+00],\n",
      "        [3.5652e-09, 7.9012e-09, 2.1624e-06, 1.0000e+00],\n",
      "        [2.9355e-09, 6.9222e-09, 3.1766e-06, 1.0000e+00],\n",
      "        [3.2831e-08, 2.3847e-08, 9.6583e-06, 9.9999e-01],\n",
      "        [1.1176e-08, 8.5013e-09, 2.5950e-06, 1.0000e+00],\n",
      "        [3.6915e-09, 6.1037e-09, 2.9972e-06, 1.0000e+00],\n",
      "        [1.1958e-08, 4.1844e-08, 3.2633e-05, 9.9997e-01],\n",
      "        [8.3635e-09, 2.1381e-08, 1.6930e-05, 9.9998e-01],\n",
      "        [1.3966e-08, 9.6151e-09, 7.0071e-06, 9.9999e-01],\n",
      "        [2.9249e-09, 1.7400e-09, 2.2858e-06, 1.0000e+00],\n",
      "        [3.2489e-09, 2.9803e-09, 4.1125e-07, 1.0000e+00],\n",
      "        [1.1318e-08, 7.2710e-09, 3.1858e-06, 1.0000e+00],\n",
      "        [4.1590e-09, 5.0668e-09, 8.9000e-07, 1.0000e+00],\n",
      "        [5.4621e-09, 1.2342e-09, 2.5284e-07, 1.0000e+00],\n",
      "        [2.6527e-09, 2.3492e-09, 1.4072e-06, 1.0000e+00],\n",
      "        [1.5125e-09, 4.4102e-09, 1.7107e-06, 1.0000e+00],\n",
      "        [3.8532e-08, 2.0114e-08, 6.3342e-07, 1.0000e+00],\n",
      "        [4.1700e-09, 7.2328e-10, 4.3860e-07, 1.0000e+00],\n",
      "        [8.2330e-09, 8.6604e-09, 7.5827e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.8778) tokens processed per second.\n",
      "Discriminator loss: tensor([[5.3648e-07, 1.0000e+00, 3.4969e-07, 2.1055e-06],\n",
      "        [4.8503e-07, 1.0000e+00, 2.1522e-07, 4.0104e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.5384e-08, 1.5279e-10, 2.1737e-08],\n",
      "        [1.0000e+00, 1.1348e-09, 5.9340e-11, 1.3564e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.9376e-06, 4.0944e-05, 9.9995e-01, 7.8107e-06],\n",
      "        [1.0315e-05, 8.5362e-05, 9.9988e-01, 2.0853e-05],\n",
      "        [1.0301e-05, 5.5169e-05, 9.9990e-01, 3.8028e-05],\n",
      "        [3.7589e-06, 4.1123e-05, 9.9995e-01, 8.5400e-06],\n",
      "        [8.5975e-06, 6.5748e-05, 9.9978e-01, 1.4545e-04],\n",
      "        [2.9428e-06, 3.8885e-05, 9.9993e-01, 2.4914e-05],\n",
      "        [9.5968e-06, 1.1373e-04, 9.9987e-01, 9.6834e-06],\n",
      "        [7.9927e-05, 2.3055e-04, 9.9967e-01, 2.0880e-05],\n",
      "        [9.2741e-07, 3.5297e-05, 9.9995e-01, 1.3021e-05],\n",
      "        [2.8158e-06, 3.7175e-05, 9.9995e-01, 1.4321e-05],\n",
      "        [7.5689e-06, 3.8237e-05, 9.9994e-01, 1.1880e-05],\n",
      "        [6.5739e-06, 4.7883e-05, 9.9993e-01, 1.1085e-05],\n",
      "        [2.6119e-04, 6.4555e-04, 9.9898e-01, 1.1599e-04],\n",
      "        [7.5056e-05, 5.9493e-04, 9.9930e-01, 2.9580e-05],\n",
      "        [7.3269e-05, 1.3363e-04, 9.9975e-01, 3.9041e-05],\n",
      "        [3.2377e-04, 6.0986e-04, 9.9904e-01, 3.1309e-05],\n",
      "        [1.0207e-05, 6.0666e-04, 9.9935e-01, 2.9633e-05],\n",
      "        [4.0832e-05, 3.3882e-04, 9.9951e-01, 1.1101e-04],\n",
      "        [2.1746e-05, 4.0551e-05, 9.9991e-01, 2.5102e-05],\n",
      "        [2.9929e-05, 1.1136e-04, 9.9985e-01, 1.2229e-05],\n",
      "        [7.5290e-06, 8.9352e-05, 9.9989e-01, 1.3101e-05],\n",
      "        [5.6531e-06, 5.3418e-05, 9.9992e-01, 2.5857e-05],\n",
      "        [2.7718e-06, 7.4545e-05, 9.9991e-01, 9.9900e-06],\n",
      "        [2.0446e-06, 4.0441e-05, 9.9994e-01, 1.7077e-05],\n",
      "        [2.6012e-06, 4.5191e-05, 9.9994e-01, 8.5414e-06],\n",
      "        [8.4350e-06, 7.6244e-05, 9.9989e-01, 2.3933e-05],\n",
      "        [7.6360e-06, 3.6363e-05, 9.9995e-01, 6.8159e-06],\n",
      "        [5.4198e-06, 1.0560e-04, 9.9986e-01, 2.7986e-05],\n",
      "        [2.2541e-05, 2.4984e-04, 9.9972e-01, 1.1449e-05],\n",
      "        [2.6515e-06, 1.1965e-04, 9.9984e-01, 3.6255e-05],\n",
      "        [9.3018e-06, 1.5090e-04, 9.9982e-01, 1.5355e-05],\n",
      "        [1.0116e-05, 2.6710e-05, 9.9993e-01, 3.2727e-05],\n",
      "        [3.2406e-06, 6.4198e-05, 9.9992e-01, 1.4235e-05],\n",
      "        [2.0472e-06, 3.0365e-05, 9.9995e-01, 1.7210e-05],\n",
      "        [1.1833e-05, 9.0666e-05, 9.9988e-01, 2.1089e-05],\n",
      "        [3.4806e-05, 1.1913e-04, 9.9982e-01, 2.1805e-05],\n",
      "        [1.2781e-04, 1.8128e-04, 9.9960e-01, 8.8615e-05],\n",
      "        [7.5060e-06, 3.0153e-05, 9.9995e-01, 1.2339e-05],\n",
      "        [3.3661e-06, 4.1033e-05, 9.9995e-01, 5.9416e-06],\n",
      "        [6.8382e-06, 6.2360e-05, 9.9992e-01, 1.4342e-05],\n",
      "        [7.3024e-05, 2.7416e-04, 9.9963e-01, 2.1006e-05],\n",
      "        [2.5771e-06, 3.8877e-05, 9.9994e-01, 1.6978e-05],\n",
      "        [6.0114e-06, 8.5823e-05, 9.9987e-01, 3.9921e-05],\n",
      "        [4.8209e-06, 5.5830e-05, 9.9992e-01, 1.9299e-05],\n",
      "        [7.4484e-05, 2.0233e-04, 9.9970e-01, 2.0634e-05],\n",
      "        [9.4399e-07, 9.5772e-06, 9.9997e-01, 2.4034e-05],\n",
      "        [5.9673e-06, 6.4733e-05, 9.9992e-01, 8.9864e-06],\n",
      "        [3.1939e-06, 1.2709e-05, 9.9996e-01, 2.0364e-05],\n",
      "        [1.4836e-04, 7.0817e-04, 9.9905e-01, 9.4299e-05],\n",
      "        [3.9072e-06, 6.0875e-05, 9.9992e-01, 1.0569e-05],\n",
      "        [5.5174e-06, 1.2220e-04, 9.9985e-01, 2.0409e-05],\n",
      "        [3.0205e-05, 9.4583e-05, 9.9985e-01, 2.5190e-05],\n",
      "        [6.4925e-06, 7.2748e-05, 9.9990e-01, 1.7436e-05],\n",
      "        [3.4565e-06, 3.0274e-05, 9.9996e-01, 8.4620e-06],\n",
      "        [4.9024e-06, 4.1811e-05, 9.9995e-01, 5.6031e-06],\n",
      "        [3.0939e-06, 5.7776e-05, 9.9993e-01, 9.1045e-06],\n",
      "        [6.0943e-06, 5.2449e-05, 9.9989e-01, 5.3550e-05],\n",
      "        [3.3395e-06, 3.5128e-05, 9.9995e-01, 8.7641e-06],\n",
      "        [4.9972e-06, 4.6827e-05, 9.9993e-01, 1.4909e-05],\n",
      "        [2.8664e-06, 1.7440e-04, 9.9979e-01, 3.6039e-05],\n",
      "        [3.7274e-06, 4.8212e-05, 9.9993e-01, 1.8770e-05],\n",
      "        [2.2673e-06, 2.5449e-05, 9.9997e-01, 6.8632e-06],\n",
      "        [3.1480e-06, 2.4075e-05, 9.9996e-01, 1.2029e-05],\n",
      "        [2.2198e-06, 6.6436e-05, 9.9990e-01, 3.0947e-05],\n",
      "        [6.5849e-06, 5.4238e-05, 9.9992e-01, 1.5444e-05],\n",
      "        [2.5877e-05, 1.9069e-04, 9.9959e-01, 1.9104e-04],\n",
      "        [2.3441e-06, 2.2992e-05, 9.9997e-01, 3.4298e-06],\n",
      "        [1.7507e-06, 3.8491e-05, 9.9993e-01, 2.7623e-05],\n",
      "        [3.8328e-05, 1.8889e-04, 9.9968e-01, 9.3978e-05],\n",
      "        [2.0746e-05, 2.1030e-04, 9.9970e-01, 6.9759e-05],\n",
      "        [3.0570e-06, 6.8154e-05, 9.9990e-01, 2.7574e-05],\n",
      "        [1.2515e-06, 2.4926e-05, 9.9996e-01, 1.0501e-05],\n",
      "        [3.3601e-06, 4.8304e-05, 9.9994e-01, 9.9955e-06],\n",
      "        [7.9719e-06, 2.9114e-05, 9.9995e-01, 1.1752e-05],\n",
      "        [6.9630e-06, 5.7146e-05, 9.9988e-01, 5.1690e-05],\n",
      "        [2.1553e-05, 1.8130e-04, 9.9978e-01, 2.0846e-05],\n",
      "        [5.7810e-06, 7.1893e-05, 9.9990e-01, 2.2348e-05],\n",
      "        [4.1157e-06, 8.1697e-05, 9.9987e-01, 4.3491e-05],\n",
      "        [2.9275e-06, 2.0906e-05, 9.9997e-01, 1.0649e-05],\n",
      "        [1.8455e-06, 8.8159e-06, 9.9998e-01, 7.3511e-06],\n",
      "        [2.8492e-05, 4.8563e-05, 9.9991e-01, 9.1289e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.3313e-09, 7.6003e-09, 2.8638e-06, 1.0000e+00],\n",
      "        [4.4352e-09, 1.5456e-08, 1.3529e-05, 9.9999e-01],\n",
      "        [1.7504e-09, 2.8573e-09, 8.3257e-07, 1.0000e+00],\n",
      "        [4.8389e-09, 1.8192e-09, 5.4820e-06, 9.9999e-01],\n",
      "        [1.0571e-08, 5.7119e-09, 4.6565e-06, 1.0000e+00],\n",
      "        [2.0316e-09, 2.3158e-09, 2.4313e-07, 1.0000e+00],\n",
      "        [8.3383e-09, 5.6092e-09, 3.5028e-06, 1.0000e+00],\n",
      "        [2.5805e-08, 1.2416e-08, 9.9620e-06, 9.9999e-01],\n",
      "        [3.9825e-09, 3.6055e-09, 4.0906e-06, 1.0000e+00],\n",
      "        [4.7167e-09, 5.5211e-09, 6.0778e-07, 1.0000e+00],\n",
      "        [5.9457e-09, 4.1741e-09, 2.5159e-06, 1.0000e+00],\n",
      "        [2.5214e-10, 8.1918e-10, 4.1431e-07, 1.0000e+00],\n",
      "        [1.1959e-08, 2.4328e-08, 4.1612e-05, 9.9996e-01],\n",
      "        [2.6049e-09, 1.9989e-09, 1.6585e-07, 1.0000e+00],\n",
      "        [1.2129e-08, 1.9952e-08, 2.8679e-06, 1.0000e+00],\n",
      "        [1.2807e-08, 4.8866e-09, 4.8408e-06, 1.0000e+00],\n",
      "        [2.6033e-09, 2.7198e-09, 1.3907e-06, 1.0000e+00],\n",
      "        [1.5170e-09, 2.6548e-09, 6.8419e-07, 1.0000e+00],\n",
      "        [4.7477e-09, 2.4646e-09, 1.3025e-06, 1.0000e+00],\n",
      "        [7.9107e-09, 6.3996e-09, 3.4919e-06, 1.0000e+00],\n",
      "        [9.2813e-09, 9.4129e-09, 6.4641e-07, 1.0000e+00],\n",
      "        [6.0475e-08, 7.6686e-09, 8.8696e-06, 9.9999e-01],\n",
      "        [6.0972e-09, 1.3808e-08, 2.4626e-05, 9.9998e-01],\n",
      "        [3.0426e-09, 3.1511e-09, 3.1860e-06, 1.0000e+00],\n",
      "        [2.2088e-09, 1.0212e-09, 3.6258e-07, 1.0000e+00],\n",
      "        [6.2799e-09, 9.0476e-09, 2.3178e-05, 9.9998e-01],\n",
      "        [5.8491e-09, 7.0392e-09, 2.0199e-05, 9.9998e-01],\n",
      "        [6.7199e-09, 2.9934e-09, 1.5622e-06, 1.0000e+00],\n",
      "        [4.3117e-09, 8.5878e-09, 2.9977e-06, 1.0000e+00],\n",
      "        [2.3193e-09, 2.5455e-09, 4.1119e-06, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.6221) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.6144e-06, 1.0000e+00, 2.6538e-07, 1.9432e-06],\n",
      "        [1.1396e-06, 1.0000e+00, 3.1033e-07, 7.7344e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 7.1058e-09, 8.2760e-11, 1.8827e-08],\n",
      "        [1.0000e+00, 2.3386e-09, 7.1561e-11, 7.4099e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[8.0023e-06, 4.5671e-05, 9.9993e-01, 1.5468e-05],\n",
      "        [7.6271e-05, 4.9050e-04, 9.9940e-01, 2.9056e-05],\n",
      "        [1.4845e-06, 2.6830e-05, 9.9994e-01, 3.5969e-05],\n",
      "        [2.5333e-06, 1.5188e-05, 9.9998e-01, 6.3811e-06],\n",
      "        [1.8708e-06, 1.3661e-05, 9.9998e-01, 5.2860e-06],\n",
      "        [7.4331e-06, 7.0675e-05, 9.9989e-01, 2.8744e-05],\n",
      "        [1.2527e-05, 2.0416e-04, 9.9977e-01, 1.0552e-05],\n",
      "        [1.6051e-06, 3.5555e-05, 9.9995e-01, 9.7800e-06],\n",
      "        [3.8425e-05, 9.3432e-05, 9.9986e-01, 6.9238e-06],\n",
      "        [1.6153e-05, 1.6142e-04, 9.9979e-01, 3.2092e-05],\n",
      "        [9.5207e-07, 1.9986e-05, 9.9997e-01, 6.5020e-06],\n",
      "        [2.6471e-06, 3.8024e-05, 9.9995e-01, 1.0280e-05],\n",
      "        [2.5085e-05, 1.3844e-04, 9.9979e-01, 4.4477e-05],\n",
      "        [4.9624e-06, 3.9195e-05, 9.9991e-01, 4.2196e-05],\n",
      "        [1.8287e-05, 1.6403e-04, 9.9976e-01, 5.9948e-05],\n",
      "        [8.7745e-05, 4.6115e-04, 9.9943e-01, 2.1999e-05],\n",
      "        [3.7424e-06, 1.1195e-04, 9.9983e-01, 5.0195e-05],\n",
      "        [3.7377e-06, 2.7103e-05, 9.9995e-01, 1.9100e-05],\n",
      "        [5.1101e-06, 1.5710e-05, 9.9997e-01, 5.5716e-06],\n",
      "        [3.2728e-06, 5.7769e-05, 9.9992e-01, 1.9911e-05],\n",
      "        [3.9905e-06, 2.0111e-05, 9.9997e-01, 1.0697e-05],\n",
      "        [4.7396e-06, 4.4274e-05, 9.9993e-01, 1.6338e-05],\n",
      "        [3.5664e-05, 7.1692e-05, 9.9987e-01, 2.4383e-05],\n",
      "        [1.0048e-06, 1.1118e-05, 9.9998e-01, 6.8915e-06],\n",
      "        [2.3126e-06, 1.9360e-05, 9.9997e-01, 9.4637e-06],\n",
      "        [1.4830e-05, 1.7421e-04, 9.9975e-01, 5.8410e-05],\n",
      "        [1.3753e-06, 9.6205e-06, 9.9999e-01, 3.0898e-06],\n",
      "        [1.2162e-06, 1.7110e-05, 9.9998e-01, 3.6412e-06],\n",
      "        [4.5216e-06, 3.3617e-05, 9.9994e-01, 2.1056e-05],\n",
      "        [1.9889e-06, 4.8777e-05, 9.9994e-01, 1.0570e-05],\n",
      "        [2.7253e-06, 4.9354e-05, 9.9993e-01, 2.0061e-05],\n",
      "        [4.0535e-06, 4.5763e-05, 9.9992e-01, 3.2127e-05],\n",
      "        [2.0707e-06, 5.6649e-05, 9.9994e-01, 5.5486e-06],\n",
      "        [2.8174e-06, 3.9513e-05, 9.9994e-01, 1.8317e-05],\n",
      "        [1.8321e-05, 6.2699e-05, 9.9990e-01, 1.4704e-05],\n",
      "        [4.2209e-06, 3.4442e-05, 9.9995e-01, 7.9872e-06],\n",
      "        [5.4228e-06, 7.5050e-05, 9.9991e-01, 9.7874e-06],\n",
      "        [8.5842e-07, 1.4835e-05, 9.9998e-01, 8.8557e-06],\n",
      "        [2.9145e-06, 1.4743e-04, 9.9982e-01, 2.5638e-05],\n",
      "        [3.2536e-07, 1.9005e-05, 9.9997e-01, 1.5468e-05],\n",
      "        [2.1208e-06, 2.7055e-05, 9.9996e-01, 8.5452e-06],\n",
      "        [2.1964e-06, 1.4973e-05, 9.9998e-01, 3.1968e-06],\n",
      "        [4.1848e-06, 9.8016e-05, 9.9988e-01, 1.9066e-05],\n",
      "        [3.0854e-06, 3.7602e-05, 9.9994e-01, 1.9375e-05],\n",
      "        [3.1900e-06, 1.4097e-04, 9.9983e-01, 2.7493e-05],\n",
      "        [2.6184e-06, 2.9090e-05, 9.9996e-01, 7.3084e-06],\n",
      "        [4.4724e-05, 1.8074e-04, 9.9974e-01, 3.7910e-05],\n",
      "        [1.2856e-05, 8.6965e-05, 9.9988e-01, 2.4812e-05],\n",
      "        [2.1320e-06, 5.2569e-05, 9.9992e-01, 2.9124e-05],\n",
      "        [2.7231e-05, 2.3523e-04, 9.9972e-01, 2.0049e-05],\n",
      "        [1.5527e-05, 1.1514e-04, 9.9983e-01, 3.6205e-05],\n",
      "        [9.2647e-06, 8.2589e-05, 9.9985e-01, 5.6531e-05],\n",
      "        [2.4555e-05, 8.5520e-05, 9.9987e-01, 2.0018e-05],\n",
      "        [6.4138e-06, 2.7918e-05, 9.9995e-01, 1.3849e-05],\n",
      "        [3.6235e-06, 1.9714e-05, 9.9996e-01, 1.4728e-05],\n",
      "        [5.0040e-06, 4.4374e-05, 9.9991e-01, 3.6158e-05],\n",
      "        [5.5942e-06, 6.4664e-05, 9.9988e-01, 4.9941e-05],\n",
      "        [3.7125e-06, 1.0275e-04, 9.9989e-01, 5.9176e-06],\n",
      "        [1.9536e-06, 1.5248e-05, 9.9998e-01, 3.9424e-06],\n",
      "        [3.4760e-06, 5.6142e-05, 9.9993e-01, 1.3808e-05],\n",
      "        [1.0673e-05, 1.3030e-04, 9.9985e-01, 7.9993e-06],\n",
      "        [1.1139e-06, 2.0119e-05, 9.9997e-01, 6.0182e-06],\n",
      "        [1.3377e-05, 2.0672e-04, 9.9976e-01, 1.5989e-05],\n",
      "        [3.3053e-06, 1.6365e-05, 9.9997e-01, 1.2218e-05],\n",
      "        [9.3058e-05, 2.8706e-04, 9.9956e-01, 6.4152e-05],\n",
      "        [5.5824e-06, 4.4945e-05, 9.9990e-01, 4.5278e-05],\n",
      "        [6.0559e-06, 7.0824e-05, 9.9992e-01, 7.4708e-06],\n",
      "        [5.7259e-06, 6.8529e-05, 9.9992e-01, 5.2386e-06],\n",
      "        [1.0636e-05, 5.5064e-05, 9.9992e-01, 9.9673e-06],\n",
      "        [4.5085e-06, 3.2046e-05, 9.9993e-01, 3.0854e-05],\n",
      "        [3.2193e-06, 5.3239e-05, 9.9992e-01, 2.5991e-05],\n",
      "        [2.1870e-06, 9.9711e-05, 9.9988e-01, 1.8419e-05],\n",
      "        [1.6615e-06, 7.2181e-05, 9.9990e-01, 2.3686e-05],\n",
      "        [6.0545e-06, 5.2516e-05, 9.9993e-01, 7.1896e-06],\n",
      "        [1.0005e-05, 4.4411e-05, 9.9994e-01, 6.7748e-06],\n",
      "        [2.6619e-05, 5.6776e-05, 9.9987e-01, 4.5286e-05],\n",
      "        [2.8659e-06, 3.2361e-05, 9.9994e-01, 2.1854e-05],\n",
      "        [2.6904e-06, 5.7251e-05, 9.9992e-01, 2.2849e-05],\n",
      "        [2.1523e-05, 3.2647e-05, 9.9993e-01, 2.0468e-05],\n",
      "        [2.1984e-06, 1.6779e-05, 9.9997e-01, 8.2246e-06],\n",
      "        [6.4926e-06, 3.0667e-05, 9.9996e-01, 6.4401e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[8.5204e-09, 8.7819e-09, 2.5241e-06, 1.0000e+00],\n",
      "        [3.5980e-09, 1.0596e-08, 3.4842e-06, 1.0000e+00],\n",
      "        [2.3981e-09, 1.3104e-09, 6.3066e-07, 1.0000e+00],\n",
      "        [7.2013e-10, 1.0936e-09, 1.7499e-07, 1.0000e+00],\n",
      "        [2.6437e-09, 1.4216e-09, 7.2383e-07, 1.0000e+00],\n",
      "        [2.0339e-09, 9.0956e-10, 2.7777e-07, 1.0000e+00],\n",
      "        [1.0443e-09, 7.9477e-10, 4.4715e-07, 1.0000e+00],\n",
      "        [2.1742e-09, 2.7676e-09, 1.0442e-06, 1.0000e+00],\n",
      "        [4.8243e-09, 4.9935e-09, 3.9809e-06, 1.0000e+00],\n",
      "        [2.5552e-09, 7.5875e-09, 1.3678e-05, 9.9999e-01],\n",
      "        [4.6122e-10, 4.2849e-10, 1.7720e-07, 1.0000e+00],\n",
      "        [7.9606e-10, 4.3782e-09, 6.5129e-07, 1.0000e+00],\n",
      "        [7.8005e-09, 4.9786e-09, 1.4137e-05, 9.9999e-01],\n",
      "        [1.6333e-09, 1.7618e-09, 2.1523e-06, 1.0000e+00],\n",
      "        [2.2926e-09, 2.0592e-09, 7.2304e-07, 1.0000e+00],\n",
      "        [3.4779e-09, 1.3309e-09, 2.9011e-07, 1.0000e+00],\n",
      "        [1.4121e-10, 5.3574e-10, 5.7575e-08, 1.0000e+00],\n",
      "        [7.0010e-10, 2.3005e-09, 4.2204e-07, 1.0000e+00],\n",
      "        [2.2624e-09, 2.4194e-09, 3.2567e-07, 1.0000e+00],\n",
      "        [5.9692e-09, 5.2712e-10, 1.1935e-07, 1.0000e+00],\n",
      "        [9.4490e-10, 1.0744e-09, 3.6165e-07, 1.0000e+00],\n",
      "        [1.5434e-09, 5.5326e-09, 2.0330e-06, 1.0000e+00],\n",
      "        [1.3222e-09, 2.5934e-09, 5.4151e-06, 9.9999e-01],\n",
      "        [1.2455e-09, 3.8243e-09, 1.6403e-06, 1.0000e+00],\n",
      "        [2.1827e-10, 6.6853e-10, 1.0345e-07, 1.0000e+00],\n",
      "        [3.5440e-09, 6.9793e-09, 3.9148e-06, 1.0000e+00],\n",
      "        [5.7433e-09, 2.2859e-09, 7.9386e-07, 1.0000e+00],\n",
      "        [3.0666e-09, 4.1066e-10, 3.7250e-07, 1.0000e+00],\n",
      "        [6.7530e-09, 4.9622e-10, 1.3664e-07, 1.0000e+00],\n",
      "        [5.7731e-09, 3.3155e-09, 5.6895e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.7257) tokens processed per second.\n",
      "Discriminator loss: tensor([[7.1297e-05, 9.9993e-01, 8.5262e-07, 2.6606e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.4866e-06, 2.3372e-09, 9.4380e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[7.2614e-07, 3.1114e-05, 9.9996e-01, 8.2697e-06],\n",
      "        [1.2044e-06, 2.3768e-05, 9.9996e-01, 1.3396e-05],\n",
      "        [3.3185e-06, 2.5978e-05, 9.9994e-01, 2.8268e-05],\n",
      "        [9.5759e-06, 8.8232e-05, 9.9989e-01, 1.5757e-05],\n",
      "        [2.4341e-05, 1.6822e-04, 9.9976e-01, 4.2817e-05],\n",
      "        [2.0069e-06, 9.2972e-06, 9.9997e-01, 1.4084e-05],\n",
      "        [3.9755e-06, 2.8381e-05, 9.9994e-01, 2.3582e-05],\n",
      "        [2.1230e-06, 1.2998e-05, 9.9998e-01, 3.3713e-06],\n",
      "        [4.3699e-06, 3.6296e-05, 9.9995e-01, 1.1245e-05],\n",
      "        [3.3728e-06, 5.8300e-05, 9.9992e-01, 1.6054e-05],\n",
      "        [1.4211e-06, 1.0164e-05, 9.9998e-01, 5.2184e-06],\n",
      "        [4.2698e-06, 4.9901e-05, 9.9993e-01, 1.6412e-05],\n",
      "        [3.8754e-06, 2.1868e-05, 9.9996e-01, 1.3735e-05],\n",
      "        [4.3795e-06, 7.0026e-05, 9.9990e-01, 2.2961e-05],\n",
      "        [1.6712e-04, 4.0994e-04, 9.9936e-01, 6.5197e-05],\n",
      "        [2.0072e-06, 3.9724e-05, 9.9995e-01, 1.1211e-05],\n",
      "        [1.0427e-06, 9.9634e-06, 9.9998e-01, 7.0932e-06],\n",
      "        [1.4805e-06, 1.3548e-05, 9.9998e-01, 7.8323e-06],\n",
      "        [4.8876e-06, 2.8174e-05, 9.9995e-01, 1.2864e-05],\n",
      "        [2.5806e-05, 4.3889e-05, 9.9992e-01, 8.9768e-06],\n",
      "        [4.0380e-06, 1.3939e-05, 9.9995e-01, 3.1837e-05],\n",
      "        [3.3920e-06, 4.7017e-05, 9.9994e-01, 7.3996e-06],\n",
      "        [3.7237e-06, 5.5957e-05, 9.9993e-01, 1.2029e-05],\n",
      "        [3.9185e-05, 1.1202e-04, 9.9983e-01, 1.9717e-05],\n",
      "        [8.9013e-07, 1.3744e-05, 9.9998e-01, 6.5010e-06],\n",
      "        [9.5776e-07, 4.6176e-06, 9.9998e-01, 9.4403e-06],\n",
      "        [1.6130e-06, 1.5668e-05, 9.9997e-01, 1.1690e-05],\n",
      "        [1.1784e-06, 6.6131e-06, 9.9999e-01, 7.0095e-06],\n",
      "        [1.4382e-05, 1.0058e-04, 9.9988e-01, 9.5541e-06],\n",
      "        [3.9097e-06, 4.8849e-05, 9.9993e-01, 1.5509e-05],\n",
      "        [1.3881e-06, 4.8856e-05, 9.9994e-01, 5.9486e-06],\n",
      "        [2.2946e-06, 7.8733e-05, 9.9990e-01, 1.6295e-05],\n",
      "        [4.6508e-06, 3.3708e-05, 9.9995e-01, 1.0966e-05],\n",
      "        [3.5909e-06, 4.7877e-05, 9.9994e-01, 9.1938e-06],\n",
      "        [8.7845e-07, 1.9992e-05, 9.9997e-01, 9.8984e-06],\n",
      "        [4.7157e-06, 3.6586e-05, 9.9995e-01, 5.8552e-06],\n",
      "        [4.3485e-06, 4.0803e-05, 9.9993e-01, 2.3931e-05],\n",
      "        [3.1433e-06, 1.3195e-05, 9.9998e-01, 8.5659e-06],\n",
      "        [3.0121e-06, 2.5317e-05, 9.9996e-01, 9.7928e-06],\n",
      "        [5.4245e-06, 4.6978e-05, 9.9994e-01, 5.5270e-06],\n",
      "        [2.0995e-05, 9.6738e-05, 9.9986e-01, 1.9476e-05],\n",
      "        [1.5152e-06, 1.2613e-05, 9.9998e-01, 2.5278e-06],\n",
      "        [4.5590e-05, 1.1395e-04, 9.9982e-01, 2.1357e-05],\n",
      "        [9.2789e-05, 1.8662e-04, 9.9971e-01, 1.5342e-05],\n",
      "        [1.1251e-05, 2.8295e-05, 9.9994e-01, 1.6152e-05],\n",
      "        [3.4846e-06, 3.8498e-05, 9.9995e-01, 8.5296e-06],\n",
      "        [5.8580e-06, 7.0877e-05, 9.9990e-01, 2.4707e-05],\n",
      "        [3.5772e-06, 2.0859e-05, 9.9996e-01, 1.0604e-05],\n",
      "        [6.6879e-07, 1.2842e-05, 9.9998e-01, 6.8285e-06],\n",
      "        [2.3608e-06, 2.9225e-05, 9.9996e-01, 1.0029e-05],\n",
      "        [7.4447e-07, 8.0078e-06, 9.9998e-01, 1.3050e-05],\n",
      "        [3.8706e-05, 1.2464e-04, 9.9982e-01, 1.7206e-05],\n",
      "        [2.0982e-06, 8.9407e-06, 9.9999e-01, 3.7413e-06],\n",
      "        [4.4753e-05, 1.0703e-04, 9.9983e-01, 1.7883e-05],\n",
      "        [3.6440e-06, 1.2003e-05, 9.9998e-01, 6.5764e-06],\n",
      "        [8.2281e-05, 1.1801e-04, 9.9975e-01, 5.3092e-05],\n",
      "        [4.5637e-06, 4.0575e-05, 9.9994e-01, 1.0252e-05],\n",
      "        [8.2289e-06, 4.7585e-05, 9.9990e-01, 4.3098e-05],\n",
      "        [5.4370e-07, 1.9536e-05, 9.9996e-01, 1.8684e-05],\n",
      "        [9.9478e-06, 2.6463e-05, 9.9996e-01, 4.3897e-06],\n",
      "        [5.4457e-06, 5.4066e-05, 9.9993e-01, 7.4819e-06],\n",
      "        [3.0605e-05, 1.5974e-04, 9.9977e-01, 3.6169e-05],\n",
      "        [4.5420e-06, 4.0110e-05, 9.9995e-01, 8.2058e-06],\n",
      "        [4.6290e-06, 8.2487e-05, 9.9990e-01, 1.1291e-05],\n",
      "        [2.2439e-06, 6.7946e-05, 9.9992e-01, 8.8853e-06],\n",
      "        [9.1028e-05, 2.4619e-04, 9.9964e-01, 1.9653e-05],\n",
      "        [2.4560e-06, 1.9490e-05, 9.9996e-01, 1.3060e-05],\n",
      "        [2.5759e-05, 1.9081e-04, 9.9977e-01, 1.7781e-05],\n",
      "        [2.6092e-06, 2.1219e-05, 9.9996e-01, 1.4887e-05],\n",
      "        [1.7875e-06, 1.0146e-05, 9.9998e-01, 1.2167e-05],\n",
      "        [2.2386e-06, 3.7819e-05, 9.9995e-01, 9.4687e-06],\n",
      "        [5.8570e-05, 7.6127e-05, 9.9984e-01, 2.7661e-05],\n",
      "        [6.1969e-06, 2.7625e-05, 9.9994e-01, 3.0714e-05],\n",
      "        [2.9589e-05, 1.1408e-04, 9.9980e-01, 5.4831e-05],\n",
      "        [4.5387e-06, 3.2324e-05, 9.9996e-01, 5.3954e-06],\n",
      "        [4.5240e-06, 2.6737e-05, 9.9996e-01, 6.7712e-06],\n",
      "        [2.9061e-06, 1.7262e-05, 9.9997e-01, 1.0122e-05],\n",
      "        [6.5364e-06, 7.5364e-05, 9.9991e-01, 9.5431e-06],\n",
      "        [5.6635e-06, 3.8385e-05, 9.9994e-01, 1.9238e-05],\n",
      "        [8.4231e-06, 2.1174e-04, 9.9974e-01, 3.4816e-05],\n",
      "        [4.3512e-06, 2.7531e-05, 9.9996e-01, 4.9167e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.6810e-09, 7.7301e-09, 7.9849e-06, 9.9999e-01],\n",
      "        [3.8079e-09, 4.0141e-09, 1.9373e-06, 1.0000e+00],\n",
      "        [2.0489e-09, 1.0907e-09, 1.0324e-06, 1.0000e+00],\n",
      "        [6.7850e-09, 1.7203e-09, 2.2669e-06, 1.0000e+00],\n",
      "        [2.6988e-08, 2.1380e-08, 1.1657e-04, 9.9988e-01],\n",
      "        [4.5008e-10, 2.9892e-10, 3.7796e-07, 1.0000e+00],\n",
      "        [2.5298e-10, 1.6789e-10, 7.0366e-08, 1.0000e+00],\n",
      "        [4.4351e-09, 1.8393e-09, 3.4851e-06, 1.0000e+00],\n",
      "        [4.4149e-09, 1.9738e-09, 4.8410e-07, 1.0000e+00],\n",
      "        [6.2962e-10, 5.4094e-10, 1.4883e-07, 1.0000e+00],\n",
      "        [1.7100e-09, 1.0127e-08, 1.2726e-05, 9.9999e-01],\n",
      "        [1.0546e-08, 1.5706e-08, 2.9282e-05, 9.9997e-01],\n",
      "        [3.3035e-09, 3.2035e-09, 4.1509e-06, 1.0000e+00],\n",
      "        [6.8804e-09, 9.5203e-09, 4.2184e-06, 1.0000e+00],\n",
      "        [5.4787e-09, 2.9755e-09, 4.4717e-06, 1.0000e+00],\n",
      "        [3.7186e-09, 2.0881e-09, 1.2653e-07, 1.0000e+00],\n",
      "        [5.0761e-09, 2.0019e-09, 1.4707e-05, 9.9999e-01],\n",
      "        [1.0320e-08, 4.4882e-09, 1.6524e-05, 9.9998e-01],\n",
      "        [1.4743e-09, 9.3200e-10, 2.5253e-07, 1.0000e+00],\n",
      "        [4.3755e-09, 2.1612e-09, 1.9870e-06, 1.0000e+00],\n",
      "        [1.0173e-09, 3.4804e-10, 5.3493e-07, 1.0000e+00],\n",
      "        [2.3622e-09, 2.0723e-09, 1.2287e-07, 1.0000e+00],\n",
      "        [1.7159e-09, 3.4055e-09, 1.4128e-06, 1.0000e+00],\n",
      "        [6.8717e-09, 1.6545e-09, 2.9781e-06, 1.0000e+00],\n",
      "        [2.3599e-10, 3.5679e-10, 1.7735e-07, 1.0000e+00],\n",
      "        [2.6349e-10, 1.5944e-10, 1.3801e-08, 1.0000e+00],\n",
      "        [1.8114e-10, 1.0025e-10, 6.0375e-08, 1.0000e+00],\n",
      "        [3.4164e-09, 6.7151e-09, 2.2187e-05, 9.9998e-01],\n",
      "        [2.3482e-09, 1.8194e-09, 5.6155e-07, 1.0000e+00],\n",
      "        [2.3118e-09, 2.5802e-09, 5.2335e-06, 9.9999e-01]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.0332) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.5869e-06, 1.0000e+00, 1.7060e-07, 1.0867e-06],\n",
      "        [4.3280e-06, 9.9999e-01, 4.3215e-07, 4.9997e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.7692e-08, 6.8765e-11, 2.8144e-08],\n",
      "        [1.0000e+00, 8.9678e-09, 2.0430e-10, 1.2891e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.0686e-06, 4.9222e-06, 9.9998e-01, 1.5922e-05],\n",
      "        [6.1507e-05, 1.0463e-04, 9.9980e-01, 3.0125e-05],\n",
      "        [1.2814e-06, 8.8556e-06, 9.9999e-01, 3.3014e-06],\n",
      "        [8.3712e-06, 4.0215e-05, 9.9994e-01, 1.3004e-05],\n",
      "        [1.1266e-06, 1.6816e-05, 9.9997e-01, 1.0121e-05],\n",
      "        [9.7844e-07, 1.0908e-05, 9.9999e-01, 1.8425e-06],\n",
      "        [2.2894e-06, 1.5067e-05, 9.9998e-01, 7.5332e-06],\n",
      "        [2.9009e-06, 1.9263e-05, 9.9996e-01, 1.5569e-05],\n",
      "        [5.0538e-06, 2.1111e-05, 9.9997e-01, 3.7519e-06],\n",
      "        [1.7189e-05, 4.3421e-05, 9.9991e-01, 3.1890e-05],\n",
      "        [1.5463e-06, 9.2085e-06, 9.9998e-01, 1.0988e-05],\n",
      "        [6.2198e-06, 4.5267e-05, 9.9992e-01, 3.0286e-05],\n",
      "        [1.8767e-06, 1.3413e-05, 9.9998e-01, 7.0178e-06],\n",
      "        [2.0479e-06, 1.9040e-05, 9.9997e-01, 5.7625e-06],\n",
      "        [2.9845e-06, 1.0338e-04, 9.9987e-01, 2.7425e-05],\n",
      "        [1.4891e-06, 2.6660e-05, 9.9995e-01, 1.6929e-05],\n",
      "        [1.1892e-06, 6.3911e-05, 9.9987e-01, 6.2520e-05],\n",
      "        [6.1814e-06, 4.3243e-05, 9.9994e-01, 8.6102e-06],\n",
      "        [8.7372e-06, 4.3767e-05, 9.9994e-01, 7.6740e-06],\n",
      "        [6.2311e-06, 4.0991e-05, 9.9994e-01, 1.0571e-05],\n",
      "        [2.0277e-06, 1.6634e-05, 9.9997e-01, 1.4120e-05],\n",
      "        [3.3513e-06, 2.1752e-05, 9.9997e-01, 4.5913e-06],\n",
      "        [4.2745e-05, 2.3164e-04, 9.9971e-01, 1.3547e-05],\n",
      "        [4.7430e-05, 9.2044e-05, 9.9983e-01, 3.4546e-05],\n",
      "        [6.5739e-06, 9.3136e-05, 9.9987e-01, 2.6894e-05],\n",
      "        [4.0864e-06, 4.3253e-05, 9.9994e-01, 8.8253e-06],\n",
      "        [2.6019e-04, 6.1978e-04, 9.9903e-01, 8.6360e-05],\n",
      "        [2.4940e-06, 2.9843e-05, 9.9996e-01, 1.1573e-05],\n",
      "        [2.6955e-06, 1.0592e-05, 9.9998e-01, 4.6018e-06],\n",
      "        [1.0965e-05, 1.7518e-04, 9.9979e-01, 2.7413e-05],\n",
      "        [9.4605e-05, 5.7262e-04, 9.9927e-01, 6.7683e-05],\n",
      "        [3.4649e-07, 5.0742e-06, 9.9999e-01, 4.3122e-06],\n",
      "        [1.0732e-06, 1.9265e-05, 9.9997e-01, 5.3990e-06],\n",
      "        [1.3298e-06, 2.3670e-05, 9.9997e-01, 4.1118e-06],\n",
      "        [1.0724e-05, 6.7210e-05, 9.9991e-01, 1.1783e-05],\n",
      "        [5.5667e-06, 4.8736e-05, 9.9993e-01, 1.4030e-05],\n",
      "        [2.6131e-06, 1.2364e-05, 9.9998e-01, 1.2554e-06],\n",
      "        [2.3220e-06, 1.0202e-05, 9.9998e-01, 4.2428e-06],\n",
      "        [1.9998e-05, 4.3234e-05, 9.9993e-01, 5.9834e-06],\n",
      "        [2.5249e-06, 1.3757e-05, 9.9997e-01, 1.0024e-05],\n",
      "        [6.0368e-06, 3.2404e-05, 9.9992e-01, 3.8982e-05],\n",
      "        [3.1895e-06, 7.9604e-05, 9.9990e-01, 2.1332e-05],\n",
      "        [4.2692e-06, 7.9572e-06, 9.9998e-01, 5.3118e-06],\n",
      "        [1.3396e-05, 6.5968e-05, 9.9991e-01, 1.2260e-05],\n",
      "        [2.9262e-06, 2.1042e-05, 9.9996e-01, 1.3830e-05],\n",
      "        [5.0238e-06, 2.9423e-05, 9.9995e-01, 1.4190e-05],\n",
      "        [5.9628e-06, 9.2357e-06, 9.9997e-01, 1.2101e-05],\n",
      "        [6.0630e-05, 1.6053e-04, 9.9969e-01, 8.4385e-05],\n",
      "        [2.0340e-07, 3.7813e-06, 1.0000e+00, 9.0966e-07],\n",
      "        [6.9339e-06, 5.6013e-05, 9.9991e-01, 3.0339e-05],\n",
      "        [2.0288e-06, 2.8272e-05, 9.9995e-01, 1.7185e-05],\n",
      "        [9.2756e-07, 1.4943e-05, 9.9998e-01, 5.5011e-06],\n",
      "        [9.6304e-07, 4.3055e-05, 9.9995e-01, 4.4085e-06],\n",
      "        [3.3368e-06, 1.3946e-05, 9.9998e-01, 3.1431e-06],\n",
      "        [6.6510e-06, 1.5727e-05, 9.9997e-01, 6.3338e-06],\n",
      "        [1.4401e-06, 1.6373e-05, 9.9996e-01, 2.2704e-05],\n",
      "        [1.3042e-07, 1.0663e-05, 9.9999e-01, 2.1980e-06],\n",
      "        [3.9804e-06, 4.3817e-06, 9.9999e-01, 3.4840e-06],\n",
      "        [4.9769e-06, 2.0751e-05, 9.9994e-01, 3.3133e-05],\n",
      "        [1.7831e-05, 1.2063e-04, 9.9984e-01, 1.7974e-05],\n",
      "        [1.1322e-05, 2.1525e-04, 9.9971e-01, 6.2057e-05],\n",
      "        [1.5330e-06, 5.9755e-05, 9.9991e-01, 2.5028e-05],\n",
      "        [5.0948e-06, 5.8544e-05, 9.9992e-01, 1.4701e-05],\n",
      "        [6.4279e-07, 1.2058e-05, 9.9997e-01, 2.0669e-05],\n",
      "        [1.5204e-05, 5.3199e-05, 9.9991e-01, 2.2291e-05],\n",
      "        [1.7483e-05, 2.2078e-04, 9.9975e-01, 1.3626e-05],\n",
      "        [2.4371e-05, 1.3144e-04, 9.9981e-01, 3.2024e-05],\n",
      "        [5.2071e-06, 1.9787e-05, 9.9997e-01, 3.5182e-06],\n",
      "        [3.1551e-06, 3.1238e-05, 9.9995e-01, 1.7077e-05],\n",
      "        [2.3389e-06, 3.0115e-05, 9.9996e-01, 1.1547e-05],\n",
      "        [2.7922e-06, 5.6944e-05, 9.9993e-01, 1.4358e-05],\n",
      "        [1.2497e-05, 4.8054e-05, 9.9994e-01, 4.4017e-06],\n",
      "        [2.7474e-06, 1.9277e-05, 9.9997e-01, 1.1297e-05],\n",
      "        [3.4884e-06, 5.0567e-05, 9.9993e-01, 1.3877e-05],\n",
      "        [1.5192e-06, 2.1212e-05, 9.9997e-01, 9.1047e-06],\n",
      "        [3.2327e-07, 1.4488e-05, 9.9998e-01, 3.4505e-06],\n",
      "        [6.2787e-06, 6.0076e-05, 9.9993e-01, 8.4899e-06],\n",
      "        [1.1331e-05, 7.1303e-05, 9.9990e-01, 2.0435e-05],\n",
      "        [3.7134e-06, 3.2705e-05, 9.9994e-01, 1.8774e-05],\n",
      "        [2.4603e-06, 1.6358e-05, 9.9997e-01, 8.3241e-06],\n",
      "        [3.7292e-07, 5.3045e-05, 9.9994e-01, 5.9443e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.8505e-10, 1.9535e-10, 1.0589e-07, 1.0000e+00],\n",
      "        [3.5278e-10, 6.7985e-10, 2.9127e-07, 1.0000e+00],\n",
      "        [1.7089e-09, 1.4287e-09, 5.6602e-07, 1.0000e+00],\n",
      "        [1.1428e-09, 2.7386e-09, 2.4903e-06, 1.0000e+00],\n",
      "        [1.5153e-09, 1.8243e-09, 7.7672e-07, 1.0000e+00],\n",
      "        [1.5259e-09, 2.4359e-09, 1.2377e-06, 1.0000e+00],\n",
      "        [4.3260e-10, 1.2144e-09, 3.4332e-07, 1.0000e+00],\n",
      "        [9.7499e-10, 4.2371e-10, 1.4088e-06, 1.0000e+00],\n",
      "        [2.4054e-08, 1.0694e-08, 2.4607e-05, 9.9998e-01],\n",
      "        [3.4937e-10, 5.1441e-10, 4.5415e-08, 1.0000e+00],\n",
      "        [1.1454e-09, 2.6744e-10, 6.8713e-08, 1.0000e+00],\n",
      "        [4.8715e-10, 1.3956e-09, 2.1568e-06, 1.0000e+00],\n",
      "        [5.1874e-09, 1.3984e-09, 3.4334e-06, 1.0000e+00],\n",
      "        [9.4039e-10, 2.6443e-10, 1.5999e-07, 1.0000e+00],\n",
      "        [3.2429e-10, 3.9189e-10, 1.4823e-07, 1.0000e+00],\n",
      "        [2.2505e-09, 1.7083e-09, 6.5085e-07, 1.0000e+00],\n",
      "        [1.0901e-10, 1.6863e-10, 1.1075e-08, 1.0000e+00],\n",
      "        [5.4682e-10, 4.4770e-10, 7.7880e-07, 1.0000e+00],\n",
      "        [3.0877e-10, 2.5803e-10, 1.3643e-07, 1.0000e+00],\n",
      "        [3.4272e-10, 4.1693e-10, 1.7413e-07, 1.0000e+00],\n",
      "        [4.8593e-09, 1.1285e-09, 2.0610e-06, 1.0000e+00],\n",
      "        [1.9773e-09, 2.0553e-10, 1.9011e-09, 1.0000e+00],\n",
      "        [1.8931e-09, 3.1957e-09, 4.0735e-07, 1.0000e+00],\n",
      "        [3.5274e-10, 1.8016e-10, 3.6346e-08, 1.0000e+00],\n",
      "        [1.4651e-08, 1.3406e-08, 1.7840e-05, 9.9998e-01],\n",
      "        [3.9292e-10, 9.9396e-10, 2.1532e-07, 1.0000e+00],\n",
      "        [3.1928e-09, 1.5060e-09, 7.9507e-07, 1.0000e+00],\n",
      "        [2.3049e-09, 1.6666e-09, 1.6110e-06, 1.0000e+00],\n",
      "        [1.1421e-09, 7.1695e-10, 9.4738e-08, 1.0000e+00],\n",
      "        [2.9700e-09, 8.3168e-10, 4.8348e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.8911) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.4269e-08, 1.0000e+00, 1.1119e-07, 1.2957e-06],\n",
      "        [2.9905e-08, 1.0000e+00, 4.1075e-07, 2.7500e-06],\n",
      "        [5.9776e-09, 1.0000e+00, 2.0058e-07, 4.1285e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 2.4334e-09, 3.4334e-11, 1.8355e-08],\n",
      "        [1.0000e+00, 5.6922e-10, 1.4575e-11, 8.4305e-09],\n",
      "        [1.0000e+00, 2.3773e-09, 5.4950e-11, 3.3067e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.1627e-08, 6.9611e-04, 9.9929e-01, 1.3284e-05],\n",
      "        [4.2941e-09, 1.3893e-04, 9.9986e-01, 2.1231e-06],\n",
      "        [1.8430e-08, 5.1395e-04, 9.9948e-01, 2.6481e-06],\n",
      "        [2.4123e-08, 1.1146e-03, 9.9886e-01, 2.2036e-05],\n",
      "        [9.3745e-09, 1.3829e-04, 9.9985e-01, 9.6414e-06],\n",
      "        [7.1030e-09, 1.8289e-03, 9.9817e-01, 5.2572e-06],\n",
      "        [7.9329e-09, 2.8861e-04, 9.9971e-01, 3.5926e-06],\n",
      "        [5.6479e-09, 1.4197e-04, 9.9985e-01, 4.6960e-06],\n",
      "        [4.9085e-09, 1.6519e-04, 9.9982e-01, 1.6823e-05],\n",
      "        [8.8300e-09, 1.4243e-04, 9.9985e-01, 3.4795e-06],\n",
      "        [4.5063e-09, 2.8707e-04, 9.9971e-01, 7.2587e-06],\n",
      "        [1.7404e-08, 2.8988e-04, 9.9971e-01, 4.0162e-06],\n",
      "        [1.6478e-08, 3.5103e-03, 9.9647e-01, 2.1122e-05],\n",
      "        [2.7809e-08, 1.4675e-04, 9.9985e-01, 6.7955e-06],\n",
      "        [4.5747e-09, 5.9562e-05, 9.9994e-01, 2.5672e-06],\n",
      "        [1.1571e-08, 5.7220e-04, 9.9942e-01, 5.0760e-06],\n",
      "        [6.1303e-09, 2.5513e-04, 9.9972e-01, 2.6685e-05],\n",
      "        [6.6489e-09, 1.6625e-04, 9.9983e-01, 4.4566e-06],\n",
      "        [7.0453e-09, 3.0617e-04, 9.9969e-01, 1.7217e-06],\n",
      "        [1.5789e-08, 1.0281e-03, 9.9897e-01, 5.8020e-06],\n",
      "        [3.8379e-09, 1.9261e-04, 9.9979e-01, 1.4209e-05],\n",
      "        [7.4288e-09, 2.8875e-04, 9.9971e-01, 1.3965e-06],\n",
      "        [9.9501e-09, 6.0510e-04, 9.9939e-01, 7.8297e-06],\n",
      "        [7.9517e-09, 1.3352e-04, 9.9986e-01, 5.9908e-06],\n",
      "        [6.8960e-08, 2.1393e-03, 9.9785e-01, 9.6486e-06],\n",
      "        [9.1313e-09, 1.3437e-04, 9.9986e-01, 2.0695e-06],\n",
      "        [1.7279e-08, 5.2653e-04, 9.9946e-01, 9.9649e-06],\n",
      "        [5.2189e-09, 9.4553e-05, 9.9989e-01, 1.2975e-05],\n",
      "        [2.3144e-09, 2.4236e-04, 9.9975e-01, 1.1486e-05],\n",
      "        [6.3347e-08, 2.0853e-03, 9.9790e-01, 1.7924e-05],\n",
      "        [1.7014e-08, 2.8801e-04, 9.9970e-01, 8.2046e-06],\n",
      "        [9.7116e-09, 2.4617e-04, 9.9975e-01, 8.2239e-06],\n",
      "        [1.3151e-08, 5.7496e-04, 9.9937e-01, 5.6624e-05],\n",
      "        [7.9139e-09, 4.2667e-04, 9.9957e-01, 5.5219e-06],\n",
      "        [6.8627e-08, 2.4624e-03, 9.9753e-01, 7.9337e-06],\n",
      "        [6.7099e-09, 5.1383e-04, 9.9948e-01, 4.0771e-06],\n",
      "        [8.0366e-09, 3.6158e-04, 9.9963e-01, 1.1141e-05],\n",
      "        [5.0324e-08, 2.7655e-04, 9.9972e-01, 7.8726e-06],\n",
      "        [3.8317e-09, 2.4827e-04, 9.9975e-01, 5.0219e-06],\n",
      "        [3.7279e-08, 4.9275e-03, 9.9506e-01, 8.3390e-06],\n",
      "        [1.7176e-08, 4.0705e-04, 9.9957e-01, 2.3116e-05],\n",
      "        [5.8761e-09, 6.6992e-05, 9.9993e-01, 2.5091e-06],\n",
      "        [1.3529e-08, 8.8588e-04, 9.9910e-01, 1.4369e-05],\n",
      "        [1.4545e-08, 4.4130e-04, 9.9955e-01, 7.2872e-06],\n",
      "        [1.1232e-08, 2.7075e-04, 9.9973e-01, 2.2657e-06],\n",
      "        [3.4848e-09, 1.0842e-04, 9.9989e-01, 3.9720e-06],\n",
      "        [4.2512e-09, 7.3580e-05, 9.9992e-01, 2.1622e-06],\n",
      "        [5.6087e-09, 8.8740e-05, 9.9990e-01, 1.0574e-05],\n",
      "        [2.8324e-09, 3.3696e-05, 9.9996e-01, 3.6197e-06],\n",
      "        [6.4492e-09, 8.4391e-05, 9.9991e-01, 1.9519e-06],\n",
      "        [3.8456e-09, 1.2646e-04, 9.9986e-01, 1.4495e-05],\n",
      "        [5.8359e-09, 7.7403e-05, 9.9992e-01, 6.6326e-06],\n",
      "        [1.1422e-08, 9.8540e-05, 9.9990e-01, 6.8443e-07],\n",
      "        [1.3961e-08, 8.0929e-04, 9.9919e-01, 2.2271e-06],\n",
      "        [1.6640e-08, 1.7498e-03, 9.9824e-01, 6.7844e-06],\n",
      "        [2.6472e-09, 5.9138e-05, 9.9994e-01, 1.5813e-06],\n",
      "        [3.0602e-09, 1.7065e-05, 9.9998e-01, 3.5352e-06],\n",
      "        [1.1327e-08, 1.7694e-04, 9.9982e-01, 6.0801e-06],\n",
      "        [1.0858e-08, 2.0145e-04, 9.9977e-01, 2.8029e-05],\n",
      "        [5.3627e-09, 1.8489e-04, 9.9981e-01, 3.4734e-06],\n",
      "        [4.2387e-09, 1.5536e-04, 9.9984e-01, 3.9007e-06],\n",
      "        [4.3709e-09, 3.7530e-05, 9.9996e-01, 8.5604e-07],\n",
      "        [5.0729e-09, 1.1710e-04, 9.9988e-01, 2.8968e-06],\n",
      "        [9.0349e-09, 1.3274e-04, 9.9986e-01, 6.7697e-06],\n",
      "        [6.2969e-09, 1.0769e-04, 9.9989e-01, 3.9053e-06],\n",
      "        [1.5870e-08, 4.4022e-03, 9.9558e-01, 1.5243e-05],\n",
      "        [1.9491e-08, 1.1006e-04, 9.9989e-01, 2.3336e-06],\n",
      "        [2.8630e-08, 2.9230e-04, 9.9970e-01, 3.4537e-06],\n",
      "        [1.4476e-08, 1.0347e-04, 9.9989e-01, 1.9715e-06],\n",
      "        [2.4717e-08, 1.1177e-03, 9.9888e-01, 3.6466e-06],\n",
      "        [1.6666e-08, 3.5861e-04, 9.9963e-01, 6.7412e-06],\n",
      "        [5.4599e-09, 6.9725e-04, 9.9929e-01, 7.8904e-06],\n",
      "        [1.1168e-08, 1.0613e-04, 9.9989e-01, 3.8312e-06],\n",
      "        [5.5238e-09, 3.7372e-04, 9.9962e-01, 6.5940e-06],\n",
      "        [5.2247e-09, 2.5380e-04, 9.9974e-01, 7.9586e-06],\n",
      "        [1.0878e-08, 2.5335e-04, 9.9974e-01, 2.2179e-06],\n",
      "        [7.3367e-09, 3.4327e-05, 9.9996e-01, 1.2520e-06],\n",
      "        [1.4503e-08, 2.4013e-04, 9.9976e-01, 2.9141e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[3.6613e-12, 1.8684e-11, 3.2202e-12, 1.0000e+00],\n",
      "        [2.6528e-12, 2.4570e-11, 3.0070e-11, 1.0000e+00],\n",
      "        [2.8944e-12, 8.5846e-12, 3.1203e-12, 1.0000e+00],\n",
      "        [1.8578e-12, 5.2268e-11, 3.5650e-12, 1.0000e+00],\n",
      "        [1.0718e-12, 1.5097e-11, 2.2753e-12, 1.0000e+00],\n",
      "        [1.2861e-12, 7.6136e-11, 1.2305e-11, 1.0000e+00],\n",
      "        [1.2748e-12, 2.9066e-11, 7.4925e-12, 1.0000e+00],\n",
      "        [8.3410e-13, 3.9752e-11, 2.0263e-11, 1.0000e+00],\n",
      "        [9.2022e-13, 7.2283e-11, 1.0296e-10, 1.0000e+00],\n",
      "        [1.7031e-12, 1.4513e-11, 1.1580e-11, 1.0000e+00],\n",
      "        [1.5821e-12, 2.8310e-11, 1.2111e-11, 1.0000e+00],\n",
      "        [9.7494e-13, 2.7194e-11, 5.3267e-12, 1.0000e+00],\n",
      "        [1.6158e-12, 1.5326e-11, 6.0944e-13, 1.0000e+00],\n",
      "        [8.3083e-12, 7.8353e-11, 1.6659e-11, 1.0000e+00],\n",
      "        [2.1831e-12, 1.6696e-11, 8.4957e-12, 1.0000e+00],\n",
      "        [8.6412e-13, 1.0835e-11, 1.2054e-11, 1.0000e+00],\n",
      "        [1.3444e-12, 1.4488e-11, 2.7773e-12, 1.0000e+00],\n",
      "        [8.1052e-12, 1.1149e-10, 1.2084e-10, 1.0000e+00],\n",
      "        [1.5354e-12, 2.0369e-10, 4.9481e-10, 1.0000e+00],\n",
      "        [2.2685e-12, 1.3880e-11, 4.3044e-12, 1.0000e+00],\n",
      "        [1.4825e-12, 9.6575e-12, 1.5827e-12, 1.0000e+00],\n",
      "        [1.5814e-12, 7.0646e-11, 4.6261e-12, 1.0000e+00],\n",
      "        [6.9142e-13, 2.0232e-11, 6.0166e-11, 1.0000e+00],\n",
      "        [7.6084e-13, 4.1951e-11, 9.2754e-12, 1.0000e+00],\n",
      "        [1.0978e-12, 7.6747e-11, 8.9991e-12, 1.0000e+00],\n",
      "        [9.0229e-12, 3.1267e-11, 6.1035e-11, 1.0000e+00],\n",
      "        [2.4512e-12, 1.6828e-11, 6.6158e-12, 1.0000e+00],\n",
      "        [6.7069e-13, 3.1152e-11, 1.5217e-11, 1.0000e+00],\n",
      "        [4.3487e-12, 8.5784e-12, 3.4462e-11, 1.0000e+00],\n",
      "        [1.5723e-12, 4.2798e-11, 5.2136e-11, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.1026) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.1588e-04, 9.9900e-01, 7.9689e-04, 8.7865e-05],\n",
      "        [7.2485e-06, 9.9913e-01, 7.7956e-04, 8.7581e-05],\n",
      "        [1.7713e-06, 9.9967e-01, 2.6925e-04, 5.8566e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.5100e-10, 2.6044e-10, 8.1994e-09],\n",
      "        [1.0000e+00, 6.5389e-10, 5.8123e-10, 1.9686e-08],\n",
      "        [1.0000e+00, 5.7927e-10, 6.1406e-10, 5.5458e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[5.3937e-07, 6.3948e-05, 9.9992e-01, 1.2651e-05],\n",
      "        [2.0479e-06, 7.2251e-05, 9.9991e-01, 1.3883e-05],\n",
      "        [7.7274e-07, 3.6607e-05, 9.9995e-01, 1.3625e-05],\n",
      "        [1.9557e-07, 8.8823e-06, 9.9999e-01, 2.7343e-06],\n",
      "        [1.4635e-07, 1.5155e-05, 9.9998e-01, 3.7065e-06],\n",
      "        [5.3071e-06, 7.2374e-05, 9.9991e-01, 1.0253e-05],\n",
      "        [1.4462e-07, 7.5135e-06, 9.9999e-01, 3.5380e-06],\n",
      "        [2.8173e-06, 1.2456e-04, 9.9985e-01, 1.8567e-05],\n",
      "        [3.3736e-07, 2.1142e-05, 9.9997e-01, 9.0624e-06],\n",
      "        [2.5823e-07, 1.0415e-05, 9.9998e-01, 6.1996e-06],\n",
      "        [2.8264e-07, 2.1624e-05, 9.9996e-01, 1.4281e-05],\n",
      "        [7.6046e-07, 9.9680e-06, 9.9998e-01, 7.0105e-06],\n",
      "        [2.7974e-07, 1.9667e-05, 9.9997e-01, 9.5712e-06],\n",
      "        [1.1079e-06, 4.7215e-05, 9.9995e-01, 6.7223e-06],\n",
      "        [2.7651e-07, 6.2853e-06, 9.9999e-01, 5.3738e-06],\n",
      "        [1.3494e-07, 6.3771e-06, 9.9999e-01, 2.8218e-06],\n",
      "        [3.2979e-07, 1.8318e-05, 9.9997e-01, 7.7107e-06],\n",
      "        [6.0090e-07, 1.5043e-05, 9.9998e-01, 5.3093e-06],\n",
      "        [2.9672e-07, 1.2393e-05, 9.9998e-01, 3.5124e-06],\n",
      "        [1.2874e-06, 7.5168e-05, 9.9992e-01, 4.4394e-06],\n",
      "        [5.4203e-07, 2.6786e-05, 9.9997e-01, 4.2211e-06],\n",
      "        [3.0910e-07, 1.1230e-05, 9.9998e-01, 4.1312e-06],\n",
      "        [6.4338e-07, 1.5416e-05, 9.9998e-01, 8.5129e-06],\n",
      "        [4.0481e-07, 4.6659e-05, 9.9994e-01, 1.5425e-05],\n",
      "        [6.1974e-07, 1.0054e-05, 9.9998e-01, 1.0137e-05],\n",
      "        [2.1031e-07, 1.7878e-05, 9.9998e-01, 4.1192e-06],\n",
      "        [2.2110e-07, 1.5347e-05, 9.9998e-01, 3.8840e-06],\n",
      "        [1.4168e-06, 3.3342e-05, 9.9996e-01, 8.3531e-06],\n",
      "        [2.7754e-07, 2.2545e-05, 9.9997e-01, 4.3477e-06],\n",
      "        [6.5638e-07, 2.3342e-05, 9.9997e-01, 5.9164e-06],\n",
      "        [8.7009e-07, 5.9718e-05, 9.9992e-01, 1.6121e-05],\n",
      "        [1.8510e-07, 1.5246e-05, 9.9998e-01, 3.2873e-06],\n",
      "        [3.2522e-07, 1.0822e-05, 9.9998e-01, 1.0787e-05],\n",
      "        [1.2610e-06, 2.1098e-05, 9.9997e-01, 1.0962e-05],\n",
      "        [1.2715e-06, 2.3548e-05, 9.9997e-01, 9.3197e-06],\n",
      "        [5.5796e-07, 2.1586e-05, 9.9997e-01, 7.2333e-06],\n",
      "        [8.3039e-07, 2.6042e-05, 9.9994e-01, 3.2606e-05],\n",
      "        [2.6952e-07, 1.2388e-05, 9.9998e-01, 5.1289e-06],\n",
      "        [1.2476e-06, 1.8759e-05, 9.9997e-01, 5.6827e-06],\n",
      "        [4.5965e-07, 1.0568e-05, 9.9998e-01, 1.0796e-05],\n",
      "        [5.7705e-07, 2.5500e-05, 9.9996e-01, 9.6100e-06],\n",
      "        [3.9442e-07, 1.0077e-05, 9.9999e-01, 2.4186e-06],\n",
      "        [1.9540e-07, 2.0599e-05, 9.9997e-01, 1.2498e-05],\n",
      "        [2.9250e-07, 9.0528e-06, 9.9998e-01, 6.9974e-06],\n",
      "        [3.3969e-07, 1.5614e-05, 9.9998e-01, 7.6447e-06],\n",
      "        [4.9670e-07, 2.2129e-05, 9.9997e-01, 6.8738e-06],\n",
      "        [2.2265e-06, 3.8126e-05, 9.9995e-01, 1.2947e-05],\n",
      "        [1.6227e-06, 8.8992e-05, 9.9990e-01, 4.5312e-06],\n",
      "        [9.2416e-07, 2.7649e-05, 9.9997e-01, 5.3330e-06],\n",
      "        [5.3386e-07, 1.9436e-05, 9.9997e-01, 8.4501e-06],\n",
      "        [2.5174e-07, 2.2503e-05, 9.9997e-01, 3.2362e-06],\n",
      "        [2.4619e-07, 6.6364e-06, 9.9999e-01, 2.8553e-06],\n",
      "        [1.0645e-06, 3.4136e-05, 9.9995e-01, 1.4546e-05],\n",
      "        [2.6827e-07, 1.8367e-05, 9.9998e-01, 2.1935e-06],\n",
      "        [4.7008e-07, 2.5962e-05, 9.9997e-01, 6.5617e-06],\n",
      "        [3.5531e-07, 1.5253e-05, 9.9998e-01, 4.6276e-06],\n",
      "        [1.8595e-07, 1.6047e-05, 9.9997e-01, 1.0581e-05],\n",
      "        [2.5646e-07, 1.8986e-05, 9.9998e-01, 3.3169e-06],\n",
      "        [1.8672e-07, 1.3311e-05, 9.9998e-01, 1.5689e-06],\n",
      "        [2.1414e-07, 2.4177e-05, 9.9997e-01, 7.1586e-06],\n",
      "        [6.4321e-07, 1.4151e-05, 9.9997e-01, 1.2374e-05],\n",
      "        [7.6851e-07, 1.1649e-05, 9.9998e-01, 4.6272e-06],\n",
      "        [2.8115e-07, 1.0886e-05, 9.9999e-01, 3.5737e-06],\n",
      "        [2.2319e-07, 1.0874e-05, 9.9998e-01, 4.1381e-06],\n",
      "        [9.9563e-07, 2.3594e-05, 9.9997e-01, 9.0927e-06],\n",
      "        [1.8120e-07, 1.4649e-05, 9.9998e-01, 8.4620e-06],\n",
      "        [1.2585e-07, 1.0860e-05, 9.9998e-01, 5.6898e-06],\n",
      "        [2.0178e-06, 5.4202e-05, 9.9993e-01, 1.1157e-05],\n",
      "        [3.0836e-07, 1.5185e-05, 9.9998e-01, 7.9931e-06],\n",
      "        [6.9480e-07, 3.6270e-05, 9.9996e-01, 6.5263e-06],\n",
      "        [5.2187e-06, 6.2806e-05, 9.9992e-01, 1.2827e-05],\n",
      "        [9.0383e-07, 3.1381e-05, 9.9995e-01, 2.2005e-05],\n",
      "        [1.9680e-07, 1.1671e-05, 9.9998e-01, 3.6726e-06],\n",
      "        [1.3929e-06, 6.3080e-05, 9.9993e-01, 5.9632e-06],\n",
      "        [6.3401e-07, 2.0299e-05, 9.9997e-01, 4.7252e-06],\n",
      "        [6.4026e-07, 1.5724e-05, 9.9998e-01, 5.9057e-06],\n",
      "        [1.5216e-07, 7.9699e-06, 9.9999e-01, 4.3261e-06],\n",
      "        [3.8375e-07, 4.8024e-05, 9.9995e-01, 4.4743e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.5518e-11, 4.4650e-11, 6.6718e-10, 1.0000e+00],\n",
      "        [3.4030e-11, 4.3638e-11, 1.3071e-09, 1.0000e+00],\n",
      "        [4.7369e-11, 2.0732e-11, 1.7331e-10, 1.0000e+00],\n",
      "        [1.0295e-11, 2.3369e-11, 1.1147e-10, 1.0000e+00],\n",
      "        [3.0696e-11, 2.7541e-11, 4.9397e-10, 1.0000e+00],\n",
      "        [2.3427e-11, 2.4983e-10, 3.4618e-09, 1.0000e+00],\n",
      "        [4.8220e-11, 2.3124e-10, 5.2085e-09, 1.0000e+00],\n",
      "        [2.3378e-10, 8.0917e-10, 1.5096e-07, 1.0000e+00],\n",
      "        [4.4890e-11, 1.0872e-10, 1.9638e-09, 1.0000e+00],\n",
      "        [1.4970e-11, 1.4276e-11, 1.3625e-10, 1.0000e+00],\n",
      "        [1.6622e-11, 2.0334e-11, 4.9477e-11, 1.0000e+00],\n",
      "        [3.2642e-11, 4.5066e-11, 6.0587e-11, 1.0000e+00],\n",
      "        [1.9116e-11, 3.8178e-11, 2.8823e-10, 1.0000e+00],\n",
      "        [1.8775e-10, 2.1602e-10, 3.6716e-09, 1.0000e+00],\n",
      "        [5.4459e-12, 7.0485e-11, 1.2880e-09, 1.0000e+00],\n",
      "        [9.5043e-12, 1.7775e-11, 5.7598e-11, 1.0000e+00],\n",
      "        [2.9910e-11, 3.7060e-11, 4.9504e-10, 1.0000e+00],\n",
      "        [2.7811e-11, 4.2648e-11, 1.3332e-10, 1.0000e+00],\n",
      "        [2.3412e-11, 3.0639e-11, 4.1972e-11, 1.0000e+00],\n",
      "        [3.6064e-11, 7.0735e-11, 8.0681e-10, 1.0000e+00],\n",
      "        [2.6301e-11, 5.4356e-11, 1.7427e-10, 1.0000e+00],\n",
      "        [2.0253e-10, 5.1144e-10, 3.1749e-09, 1.0000e+00],\n",
      "        [2.6115e-11, 9.9189e-11, 4.0293e-09, 1.0000e+00],\n",
      "        [1.8373e-11, 4.9323e-11, 1.1810e-09, 1.0000e+00],\n",
      "        [5.1780e-11, 2.2721e-11, 2.3240e-12, 1.0000e+00],\n",
      "        [1.0075e-11, 1.1349e-11, 7.4458e-11, 1.0000e+00],\n",
      "        [4.7508e-11, 6.6984e-11, 6.0368e-10, 1.0000e+00],\n",
      "        [5.9037e-11, 5.2039e-11, 1.1793e-09, 1.0000e+00],\n",
      "        [3.0207e-11, 6.8121e-11, 8.2107e-10, 1.0000e+00],\n",
      "        [3.3732e-11, 3.0890e-11, 2.3502e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.9340) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.7828e-07, 9.9997e-01, 2.1502e-05, 8.2840e-06],\n",
      "        [2.1003e-07, 9.9999e-01, 3.5106e-06, 7.6448e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 6.9009e-08, 7.1742e-09, 7.9715e-07],\n",
      "        [1.0000e+00, 5.1920e-08, 1.0193e-09, 1.5294e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.0067e-07, 2.0968e-05, 9.9997e-01, 6.7617e-06],\n",
      "        [2.4598e-07, 2.0071e-05, 9.9998e-01, 4.4612e-06],\n",
      "        [4.1422e-07, 2.6061e-05, 9.9997e-01, 6.2561e-06],\n",
      "        [4.8905e-07, 4.1676e-05, 9.9995e-01, 3.5333e-06],\n",
      "        [1.3659e-06, 9.2966e-05, 9.9989e-01, 1.1042e-05],\n",
      "        [1.6031e-06, 5.1880e-05, 9.9993e-01, 1.5015e-05],\n",
      "        [1.4581e-06, 8.7427e-05, 9.9990e-01, 9.4861e-06],\n",
      "        [2.3132e-07, 1.0030e-05, 9.9999e-01, 3.3338e-06],\n",
      "        [8.9452e-07, 3.0374e-05, 9.9996e-01, 8.5071e-06],\n",
      "        [3.6721e-07, 3.6860e-05, 9.9996e-01, 4.4468e-06],\n",
      "        [7.1707e-07, 4.8764e-05, 9.9994e-01, 9.6959e-06],\n",
      "        [8.3453e-07, 1.7790e-05, 9.9998e-01, 6.0308e-06],\n",
      "        [1.6443e-07, 3.8278e-05, 9.9996e-01, 4.8426e-06],\n",
      "        [2.4736e-07, 3.0037e-05, 9.9996e-01, 8.6124e-06],\n",
      "        [1.1030e-07, 3.6110e-05, 9.9996e-01, 4.9516e-06],\n",
      "        [4.9330e-07, 2.2338e-05, 9.9997e-01, 8.4782e-06],\n",
      "        [1.0630e-06, 1.0389e-04, 9.9989e-01, 5.8317e-06],\n",
      "        [2.7139e-07, 4.4769e-05, 9.9995e-01, 5.6062e-06],\n",
      "        [8.2109e-07, 4.9674e-05, 9.9994e-01, 6.8123e-06],\n",
      "        [3.0036e-06, 6.5236e-05, 9.9992e-01, 1.5609e-05],\n",
      "        [1.6079e-07, 1.6121e-05, 9.9998e-01, 5.0302e-06],\n",
      "        [8.7300e-07, 1.5441e-05, 9.9997e-01, 1.0543e-05],\n",
      "        [1.1358e-07, 4.6643e-06, 9.9999e-01, 4.2555e-06],\n",
      "        [6.3929e-07, 3.2072e-05, 9.9994e-01, 2.2712e-05],\n",
      "        [3.5622e-07, 1.7577e-05, 9.9998e-01, 2.3756e-06],\n",
      "        [5.1980e-07, 5.6709e-05, 9.9993e-01, 1.4329e-05],\n",
      "        [1.4069e-07, 2.3484e-05, 9.9997e-01, 5.5957e-06],\n",
      "        [3.0930e-07, 1.7169e-05, 9.9996e-01, 1.8898e-05],\n",
      "        [6.6080e-07, 2.2377e-05, 9.9997e-01, 2.6477e-06],\n",
      "        [1.0100e-06, 4.1511e-05, 9.9994e-01, 1.4511e-05],\n",
      "        [7.7770e-07, 2.5355e-05, 9.9996e-01, 1.4706e-05],\n",
      "        [1.0040e-06, 3.1084e-05, 9.9996e-01, 1.2348e-05],\n",
      "        [4.5919e-07, 4.3824e-05, 9.9994e-01, 1.7343e-05],\n",
      "        [5.8143e-06, 1.2671e-04, 9.9985e-01, 1.6942e-05],\n",
      "        [3.6780e-07, 3.1899e-05, 9.9996e-01, 5.9372e-06],\n",
      "        [9.6285e-07, 2.8371e-05, 9.9996e-01, 1.0216e-05],\n",
      "        [9.9242e-07, 5.5358e-05, 9.9994e-01, 7.3779e-06],\n",
      "        [3.4130e-06, 1.5846e-04, 9.9983e-01, 5.9991e-06],\n",
      "        [5.7332e-07, 3.2737e-05, 9.9996e-01, 4.6917e-06],\n",
      "        [9.0227e-07, 8.8132e-05, 9.9990e-01, 1.2927e-05],\n",
      "        [2.4189e-07, 1.9259e-05, 9.9998e-01, 3.0681e-06],\n",
      "        [4.6697e-07, 2.0086e-05, 9.9997e-01, 9.4019e-06],\n",
      "        [2.4654e-07, 3.8614e-05, 9.9995e-01, 7.0835e-06],\n",
      "        [2.3351e-07, 1.5982e-05, 9.9997e-01, 8.8502e-06],\n",
      "        [2.0801e-07, 2.0978e-05, 9.9997e-01, 6.5914e-06],\n",
      "        [6.7787e-07, 9.3723e-05, 9.9989e-01, 1.7456e-05],\n",
      "        [1.0738e-06, 5.7392e-05, 9.9993e-01, 1.5498e-05],\n",
      "        [1.4669e-07, 1.3175e-05, 9.9998e-01, 7.4985e-06],\n",
      "        [1.1021e-06, 6.5251e-05, 9.9992e-01, 1.2555e-05],\n",
      "        [2.2363e-07, 4.0162e-05, 9.9995e-01, 5.1909e-06],\n",
      "        [1.2105e-06, 3.4034e-05, 9.9996e-01, 6.1121e-06],\n",
      "        [5.6451e-07, 2.1519e-05, 9.9997e-01, 1.0448e-05],\n",
      "        [7.4582e-07, 2.3607e-05, 9.9997e-01, 5.9334e-06],\n",
      "        [1.6113e-06, 5.2010e-05, 9.9993e-01, 1.6328e-05],\n",
      "        [7.2932e-07, 4.9440e-05, 9.9994e-01, 8.1554e-06],\n",
      "        [3.3049e-07, 2.6520e-05, 9.9997e-01, 4.8388e-06],\n",
      "        [2.5302e-06, 1.6612e-04, 9.9982e-01, 7.3728e-06],\n",
      "        [2.0929e-07, 2.6460e-05, 9.9996e-01, 1.4368e-05],\n",
      "        [1.6271e-06, 2.7992e-05, 9.9997e-01, 4.9781e-06],\n",
      "        [6.7875e-07, 2.1561e-05, 9.9996e-01, 1.5301e-05],\n",
      "        [2.9588e-07, 3.5847e-05, 9.9996e-01, 4.9986e-06],\n",
      "        [5.2708e-07, 1.4930e-05, 9.9996e-01, 2.1155e-05],\n",
      "        [9.3202e-07, 2.6852e-05, 9.9997e-01, 5.6446e-06],\n",
      "        [5.6149e-07, 1.4116e-05, 9.9997e-01, 1.1907e-05],\n",
      "        [3.8376e-06, 2.1871e-04, 9.9977e-01, 1.1892e-05],\n",
      "        [6.2436e-07, 4.7980e-05, 9.9993e-01, 2.1003e-05],\n",
      "        [1.7835e-07, 2.7876e-05, 9.9996e-01, 7.6960e-06],\n",
      "        [2.6874e-07, 1.8210e-05, 9.9998e-01, 4.5198e-06],\n",
      "        [4.3826e-07, 2.2552e-05, 9.9997e-01, 5.2451e-06],\n",
      "        [3.1071e-07, 4.0145e-05, 9.9995e-01, 1.2353e-05],\n",
      "        [7.7929e-07, 4.1119e-05, 9.9995e-01, 3.7395e-06],\n",
      "        [1.0694e-06, 8.7476e-05, 9.9988e-01, 2.6462e-05],\n",
      "        [2.2018e-07, 3.2675e-05, 9.9996e-01, 2.5626e-06],\n",
      "        [3.7833e-07, 6.2384e-05, 9.9993e-01, 9.1007e-06],\n",
      "        [2.6117e-06, 9.7900e-05, 9.9987e-01, 2.6141e-05],\n",
      "        [2.4359e-07, 2.0907e-05, 9.9997e-01, 6.2768e-06],\n",
      "        [2.5830e-06, 2.4545e-04, 9.9974e-01, 1.1325e-05],\n",
      "        [1.7205e-06, 4.6173e-05, 9.9994e-01, 1.0236e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[3.8468e-11, 9.8380e-12, 1.7664e-10, 1.0000e+00],\n",
      "        [6.4916e-12, 4.3535e-11, 2.0063e-10, 1.0000e+00],\n",
      "        [1.5811e-11, 6.2923e-11, 9.6206e-10, 1.0000e+00],\n",
      "        [4.9035e-12, 2.0858e-11, 8.8165e-11, 1.0000e+00],\n",
      "        [2.6848e-11, 7.1697e-11, 5.7258e-10, 1.0000e+00],\n",
      "        [9.8582e-12, 1.2418e-11, 7.3795e-11, 1.0000e+00],\n",
      "        [2.0637e-11, 2.6131e-11, 1.1889e-10, 1.0000e+00],\n",
      "        [5.1037e-11, 6.4852e-11, 6.5919e-12, 1.0000e+00],\n",
      "        [1.6113e-11, 3.0019e-11, 1.2631e-09, 1.0000e+00],\n",
      "        [1.4257e-11, 9.8418e-12, 3.0511e-11, 1.0000e+00],\n",
      "        [5.1853e-11, 1.8411e-10, 1.1753e-08, 1.0000e+00],\n",
      "        [1.6020e-11, 2.9352e-11, 1.3069e-10, 1.0000e+00],\n",
      "        [4.9944e-11, 2.0179e-10, 1.9862e-11, 1.0000e+00],\n",
      "        [4.5511e-11, 8.7270e-10, 8.4544e-08, 1.0000e+00],\n",
      "        [1.3715e-11, 6.1143e-11, 6.2322e-10, 1.0000e+00],\n",
      "        [1.0211e-11, 4.6674e-11, 1.3603e-10, 1.0000e+00],\n",
      "        [1.8838e-10, 4.0575e-10, 1.4576e-07, 1.0000e+00],\n",
      "        [1.7561e-11, 6.7859e-11, 1.6345e-09, 1.0000e+00],\n",
      "        [3.2761e-11, 3.4862e-11, 3.2216e-10, 1.0000e+00],\n",
      "        [8.8149e-11, 9.5931e-11, 3.0940e-09, 1.0000e+00],\n",
      "        [4.4696e-11, 1.0766e-10, 2.6276e-10, 1.0000e+00],\n",
      "        [5.7405e-12, 2.5859e-11, 3.0993e-10, 1.0000e+00],\n",
      "        [1.9185e-11, 1.8473e-11, 8.0186e-11, 1.0000e+00],\n",
      "        [3.3774e-11, 1.5354e-10, 3.1783e-09, 1.0000e+00],\n",
      "        [1.8075e-11, 2.0816e-10, 1.8786e-09, 1.0000e+00],\n",
      "        [3.7046e-11, 5.1285e-11, 4.2899e-10, 1.0000e+00],\n",
      "        [3.2536e-11, 5.5660e-10, 6.7391e-08, 1.0000e+00],\n",
      "        [5.5517e-11, 3.5112e-10, 7.7769e-09, 1.0000e+00],\n",
      "        [2.8167e-11, 4.4969e-11, 2.2742e-10, 1.0000e+00],\n",
      "        [4.7461e-11, 7.1517e-11, 5.9154e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(100.9117) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[5.3394e-07, 9.9992e-01, 7.1235e-05, 6.2581e-06],\n",
      "        [1.3936e-07, 9.9997e-01, 1.9392e-05, 8.8123e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.6733e-09, 1.9539e-10, 3.9138e-08],\n",
      "        [1.0000e+00, 4.6382e-09, 2.6144e-10, 5.0771e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[6.1683e-07, 3.9695e-05, 9.9994e-01, 1.7900e-05],\n",
      "        [4.0450e-07, 4.4971e-05, 9.9994e-01, 1.1517e-05],\n",
      "        [5.5101e-07, 2.7610e-05, 9.9996e-01, 1.0130e-05],\n",
      "        [1.0785e-07, 2.5162e-05, 9.9997e-01, 4.4393e-06],\n",
      "        [3.9600e-07, 1.8212e-05, 9.9997e-01, 1.3090e-05],\n",
      "        [1.2729e-06, 2.5974e-05, 9.9995e-01, 1.7718e-05],\n",
      "        [2.2830e-06, 2.5286e-05, 9.9996e-01, 1.3113e-05],\n",
      "        [2.2112e-06, 5.2875e-05, 9.9994e-01, 5.1816e-06],\n",
      "        [1.6594e-07, 2.1035e-05, 9.9998e-01, 1.5530e-06],\n",
      "        [2.3689e-07, 6.7385e-05, 9.9993e-01, 3.7472e-06],\n",
      "        [1.7757e-06, 6.2599e-05, 9.9993e-01, 9.0532e-06],\n",
      "        [3.2670e-07, 2.3749e-05, 9.9997e-01, 4.9682e-06],\n",
      "        [2.2026e-06, 1.0283e-04, 9.9989e-01, 8.8573e-06],\n",
      "        [2.7340e-07, 5.2279e-06, 9.9999e-01, 6.9699e-06],\n",
      "        [1.5321e-06, 6.9141e-05, 9.9991e-01, 1.6320e-05],\n",
      "        [1.2676e-06, 5.8385e-05, 9.9991e-01, 3.0752e-05],\n",
      "        [1.0672e-06, 3.1388e-05, 9.9996e-01, 7.6611e-06],\n",
      "        [8.1982e-07, 4.3421e-05, 9.9994e-01, 1.1579e-05],\n",
      "        [1.9025e-07, 3.3561e-05, 9.9996e-01, 5.0885e-06],\n",
      "        [4.1418e-06, 1.5270e-04, 9.9983e-01, 1.7020e-05],\n",
      "        [2.8098e-07, 1.4924e-05, 9.9998e-01, 7.3383e-06],\n",
      "        [1.2817e-06, 3.4908e-05, 9.9995e-01, 1.0396e-05],\n",
      "        [3.1377e-07, 1.6524e-05, 9.9998e-01, 4.0277e-06],\n",
      "        [8.6798e-07, 2.4045e-05, 9.9997e-01, 5.0439e-06],\n",
      "        [3.5396e-07, 4.6343e-05, 9.9995e-01, 5.3526e-06],\n",
      "        [2.8259e-07, 2.1966e-05, 9.9998e-01, 2.5567e-06],\n",
      "        [5.7856e-07, 2.2994e-05, 9.9997e-01, 8.1561e-06],\n",
      "        [4.6231e-07, 1.6494e-05, 9.9997e-01, 8.0998e-06],\n",
      "        [1.5564e-06, 1.0330e-04, 9.9989e-01, 7.5516e-06],\n",
      "        [8.0982e-07, 4.1855e-05, 9.9993e-01, 2.5991e-05],\n",
      "        [1.8450e-07, 7.8232e-06, 9.9999e-01, 4.5050e-06],\n",
      "        [2.1224e-06, 4.5432e-05, 9.9995e-01, 6.0239e-06],\n",
      "        [6.8750e-07, 3.8128e-05, 9.9996e-01, 4.0029e-06],\n",
      "        [2.9171e-06, 7.4670e-05, 9.9991e-01, 8.3790e-06],\n",
      "        [7.1835e-07, 2.7194e-05, 9.9997e-01, 5.0635e-06],\n",
      "        [5.1757e-07, 2.8880e-05, 9.9996e-01, 6.6545e-06],\n",
      "        [7.3270e-07, 8.0688e-05, 9.9991e-01, 9.6580e-06],\n",
      "        [1.3977e-06, 4.1128e-05, 9.9995e-01, 7.0301e-06],\n",
      "        [3.8956e-07, 2.6632e-05, 9.9997e-01, 7.8613e-06],\n",
      "        [1.6111e-07, 2.6267e-05, 9.9996e-01, 9.8115e-06],\n",
      "        [1.0585e-06, 8.5990e-05, 9.9990e-01, 1.0728e-05],\n",
      "        [5.5081e-07, 1.7970e-05, 9.9998e-01, 3.9564e-06],\n",
      "        [5.4031e-07, 2.2225e-05, 9.9997e-01, 7.3029e-06],\n",
      "        [8.5764e-07, 1.6164e-05, 9.9998e-01, 7.0025e-06],\n",
      "        [1.0525e-06, 1.1559e-04, 9.9988e-01, 7.0752e-06],\n",
      "        [5.1667e-07, 4.9720e-05, 9.9993e-01, 2.1956e-05],\n",
      "        [2.8314e-07, 4.9413e-05, 9.9994e-01, 1.0315e-05],\n",
      "        [2.1517e-07, 4.1936e-05, 9.9996e-01, 2.8151e-06],\n",
      "        [5.7680e-07, 3.1779e-05, 9.9996e-01, 5.0596e-06],\n",
      "        [7.2206e-07, 6.6077e-05, 9.9992e-01, 1.2889e-05],\n",
      "        [4.1434e-07, 1.7471e-05, 9.9998e-01, 6.5159e-06],\n",
      "        [5.9871e-07, 1.4178e-05, 9.9997e-01, 1.1787e-05],\n",
      "        [7.4466e-07, 4.4235e-05, 9.9994e-01, 1.1835e-05],\n",
      "        [8.2790e-07, 2.9733e-05, 9.9996e-01, 7.4007e-06],\n",
      "        [6.1544e-07, 5.2854e-05, 9.9993e-01, 1.7360e-05],\n",
      "        [2.7466e-07, 1.4549e-05, 9.9997e-01, 1.8863e-05],\n",
      "        [9.7549e-07, 2.3908e-05, 9.9997e-01, 9.1212e-06],\n",
      "        [4.1085e-07, 1.2570e-05, 9.9998e-01, 8.9092e-06],\n",
      "        [3.9072e-07, 2.9748e-05, 9.9997e-01, 4.8675e-06],\n",
      "        [5.2743e-07, 7.7023e-05, 9.9992e-01, 7.4413e-06],\n",
      "        [1.6829e-07, 3.1959e-05, 9.9996e-01, 6.4667e-06],\n",
      "        [2.1118e-06, 2.2993e-05, 9.9996e-01, 1.3529e-05],\n",
      "        [3.7331e-07, 5.8733e-05, 9.9992e-01, 2.1553e-05],\n",
      "        [4.0007e-07, 1.4455e-05, 9.9997e-01, 1.1610e-05],\n",
      "        [7.4466e-07, 4.6801e-05, 9.9994e-01, 1.4076e-05],\n",
      "        [1.2129e-06, 6.8878e-05, 9.9992e-01, 8.9081e-06],\n",
      "        [6.1683e-07, 2.7124e-05, 9.9996e-01, 1.1049e-05],\n",
      "        [1.4839e-06, 5.5227e-05, 9.9993e-01, 1.5864e-05],\n",
      "        [9.4110e-07, 2.0190e-04, 9.9979e-01, 6.7324e-06],\n",
      "        [3.4488e-07, 4.0413e-05, 9.9995e-01, 4.6038e-06],\n",
      "        [5.4638e-07, 4.4457e-05, 9.9994e-01, 1.1042e-05],\n",
      "        [6.6057e-07, 1.4644e-05, 9.9997e-01, 1.2407e-05],\n",
      "        [1.7825e-06, 8.9287e-05, 9.9990e-01, 1.0827e-05],\n",
      "        [3.6717e-06, 1.4752e-04, 9.9983e-01, 1.3933e-05],\n",
      "        [3.9471e-07, 1.2166e-05, 9.9998e-01, 3.1640e-06],\n",
      "        [4.8538e-07, 1.1003e-04, 9.9988e-01, 5.4821e-06],\n",
      "        [4.8957e-07, 2.1731e-05, 9.9997e-01, 8.3670e-06],\n",
      "        [7.1895e-07, 7.8205e-05, 9.9989e-01, 3.0039e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.6698e-11, 2.0569e-11, 1.5065e-10, 1.0000e+00],\n",
      "        [4.5158e-11, 2.2241e-11, 2.2558e-10, 1.0000e+00],\n",
      "        [1.2218e-11, 1.6184e-11, 1.4780e-10, 1.0000e+00],\n",
      "        [1.1834e-11, 5.5460e-11, 1.9684e-10, 1.0000e+00],\n",
      "        [1.4097e-11, 8.5713e-11, 6.8455e-10, 1.0000e+00],\n",
      "        [6.5148e-11, 3.9895e-10, 3.1076e-08, 1.0000e+00],\n",
      "        [3.9830e-11, 1.8236e-10, 3.2437e-09, 1.0000e+00],\n",
      "        [2.7933e-11, 1.8047e-11, 4.5442e-11, 1.0000e+00],\n",
      "        [1.1629e-11, 9.8986e-12, 1.0618e-10, 1.0000e+00],\n",
      "        [1.9927e-11, 1.3100e-11, 3.6447e-11, 1.0000e+00],\n",
      "        [7.1952e-11, 5.3242e-10, 2.7993e-08, 1.0000e+00],\n",
      "        [3.1500e-11, 9.7385e-11, 2.0672e-09, 1.0000e+00],\n",
      "        [2.5687e-11, 6.2197e-11, 8.9490e-10, 1.0000e+00],\n",
      "        [2.9710e-11, 4.7334e-11, 9.4219e-10, 1.0000e+00],\n",
      "        [3.6254e-11, 1.1823e-11, 6.9971e-12, 1.0000e+00],\n",
      "        [6.8056e-12, 1.3600e-10, 6.6640e-10, 1.0000e+00],\n",
      "        [8.7075e-11, 6.7991e-11, 1.3572e-09, 1.0000e+00],\n",
      "        [2.5718e-10, 1.0924e-09, 3.7685e-07, 1.0000e+00],\n",
      "        [2.4596e-11, 8.7312e-11, 9.2415e-10, 1.0000e+00],\n",
      "        [5.1940e-11, 1.1548e-10, 2.1744e-10, 1.0000e+00],\n",
      "        [4.4169e-11, 7.6465e-12, 4.9255e-12, 1.0000e+00],\n",
      "        [7.3315e-12, 1.5475e-11, 2.1975e-10, 1.0000e+00],\n",
      "        [1.4031e-11, 4.6168e-11, 6.3595e-10, 1.0000e+00],\n",
      "        [1.8790e-11, 3.7654e-11, 1.1860e-09, 1.0000e+00],\n",
      "        [1.4331e-11, 2.0006e-11, 3.1716e-11, 1.0000e+00],\n",
      "        [1.3176e-11, 3.0798e-11, 1.0412e-10, 1.0000e+00],\n",
      "        [1.5284e-11, 2.2036e-11, 2.4150e-10, 1.0000e+00],\n",
      "        [3.1934e-11, 5.0952e-11, 4.9604e-10, 1.0000e+00],\n",
      "        [4.6763e-12, 1.2080e-11, 4.9726e-11, 1.0000e+00],\n",
      "        [7.6534e-12, 7.6018e-11, 1.7826e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.0432) tokens processed per second.\n",
      "Discriminator loss: tensor([[1.0984e-07, 9.9999e-01, 4.6236e-07, 5.6160e-06],\n",
      "        [3.4321e-07, 9.9999e-01, 1.0450e-06, 5.2115e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.4001e-10, 1.1708e-11, 6.8303e-09],\n",
      "        [1.0000e+00, 4.0434e-09, 1.5265e-10, 2.9774e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[9.3213e-08, 9.4611e-08, 1.0000e+00, 2.1946e-06],\n",
      "        [1.5669e-07, 7.4051e-08, 1.0000e+00, 2.6459e-06],\n",
      "        [9.2247e-08, 6.3618e-08, 1.0000e+00, 1.3142e-06],\n",
      "        [4.2762e-07, 9.8423e-08, 1.0000e+00, 1.8941e-06],\n",
      "        [4.3154e-08, 7.7134e-08, 1.0000e+00, 9.2159e-07],\n",
      "        [9.1097e-08, 9.2760e-08, 1.0000e+00, 9.9122e-07],\n",
      "        [1.8098e-07, 2.6090e-07, 1.0000e+00, 1.3503e-06],\n",
      "        [1.7032e-07, 2.6687e-08, 1.0000e+00, 1.9471e-06],\n",
      "        [1.0908e-07, 6.6075e-08, 1.0000e+00, 1.3717e-06],\n",
      "        [2.9764e-08, 5.7188e-08, 1.0000e+00, 1.4442e-06],\n",
      "        [3.2945e-08, 2.9506e-08, 1.0000e+00, 6.9059e-07],\n",
      "        [1.4283e-07, 8.8909e-08, 1.0000e+00, 9.5508e-07],\n",
      "        [1.9166e-07, 5.8318e-08, 1.0000e+00, 2.6060e-06],\n",
      "        [1.2122e-07, 1.1577e-07, 1.0000e+00, 1.3835e-06],\n",
      "        [2.6910e-07, 5.0895e-08, 1.0000e+00, 1.0017e-06],\n",
      "        [6.7969e-08, 3.6217e-08, 1.0000e+00, 1.4776e-06],\n",
      "        [2.2527e-07, 1.2488e-07, 1.0000e+00, 3.0019e-06],\n",
      "        [9.5703e-08, 3.8431e-08, 1.0000e+00, 1.8867e-06],\n",
      "        [1.9998e-07, 2.1133e-07, 1.0000e+00, 1.0162e-06],\n",
      "        [6.7456e-08, 8.3495e-08, 1.0000e+00, 9.8633e-07],\n",
      "        [8.5714e-08, 5.7746e-08, 1.0000e+00, 1.2656e-06],\n",
      "        [2.3450e-08, 3.5599e-08, 1.0000e+00, 1.4504e-06],\n",
      "        [1.8465e-07, 1.1317e-07, 1.0000e+00, 1.5977e-06],\n",
      "        [1.0806e-07, 8.8494e-08, 1.0000e+00, 2.7864e-06],\n",
      "        [7.4926e-08, 1.1635e-07, 1.0000e+00, 8.1982e-07],\n",
      "        [3.8411e-08, 6.1839e-08, 1.0000e+00, 3.2951e-06],\n",
      "        [9.1882e-08, 1.3791e-07, 1.0000e+00, 1.1690e-06],\n",
      "        [7.5702e-08, 4.4071e-08, 1.0000e+00, 1.0023e-06],\n",
      "        [8.1792e-08, 1.7482e-07, 1.0000e+00, 2.4184e-06],\n",
      "        [8.0491e-08, 9.7157e-08, 1.0000e+00, 9.7632e-07],\n",
      "        [7.8553e-08, 7.2137e-08, 9.9999e-01, 9.4810e-06],\n",
      "        [1.2786e-07, 9.1780e-08, 1.0000e+00, 1.6768e-06],\n",
      "        [8.8812e-08, 1.0041e-07, 1.0000e+00, 7.1366e-07],\n",
      "        [9.8189e-08, 3.6776e-08, 1.0000e+00, 2.7628e-06],\n",
      "        [4.0658e-07, 3.3263e-07, 1.0000e+00, 1.0212e-06],\n",
      "        [2.9658e-08, 6.4828e-08, 1.0000e+00, 2.7901e-07],\n",
      "        [1.8041e-07, 7.8369e-08, 1.0000e+00, 2.7280e-06],\n",
      "        [2.7159e-07, 1.1425e-07, 1.0000e+00, 2.6900e-06],\n",
      "        [1.9373e-07, 8.2076e-08, 1.0000e+00, 2.7327e-06],\n",
      "        [1.1885e-07, 5.8714e-08, 1.0000e+00, 1.3907e-06],\n",
      "        [3.9797e-08, 8.1381e-08, 1.0000e+00, 4.7114e-07],\n",
      "        [1.7131e-07, 1.4018e-07, 1.0000e+00, 1.0010e-06],\n",
      "        [1.6961e-07, 7.7486e-08, 1.0000e+00, 3.8238e-06],\n",
      "        [4.1243e-08, 6.7855e-08, 9.9999e-01, 5.0780e-06],\n",
      "        [5.7442e-08, 6.4992e-08, 1.0000e+00, 7.4996e-07],\n",
      "        [1.6988e-07, 2.5335e-07, 1.0000e+00, 3.0795e-06],\n",
      "        [1.1298e-07, 4.7618e-08, 1.0000e+00, 7.6481e-07],\n",
      "        [1.2719e-07, 1.9597e-07, 1.0000e+00, 3.0707e-06],\n",
      "        [2.0773e-07, 4.6834e-08, 1.0000e+00, 1.2287e-06],\n",
      "        [1.1816e-07, 1.6354e-07, 1.0000e+00, 1.8665e-06],\n",
      "        [1.2642e-07, 7.0554e-08, 1.0000e+00, 9.1552e-07],\n",
      "        [1.7780e-07, 5.3713e-08, 1.0000e+00, 4.4865e-07],\n",
      "        [3.7483e-07, 1.4366e-07, 1.0000e+00, 2.7452e-06],\n",
      "        [1.5773e-07, 1.5071e-07, 1.0000e+00, 2.3941e-06],\n",
      "        [5.1520e-07, 5.3770e-07, 1.0000e+00, 1.5030e-06],\n",
      "        [3.8571e-08, 5.3916e-08, 1.0000e+00, 2.7946e-06],\n",
      "        [8.0340e-08, 1.0495e-07, 1.0000e+00, 1.5159e-06],\n",
      "        [7.4432e-07, 2.3338e-07, 1.0000e+00, 1.0149e-06],\n",
      "        [9.3170e-08, 7.7433e-08, 1.0000e+00, 3.1233e-06],\n",
      "        [5.6617e-08, 5.8845e-08, 1.0000e+00, 8.6129e-07],\n",
      "        [2.9804e-08, 4.0813e-08, 1.0000e+00, 1.2063e-06],\n",
      "        [1.6669e-07, 1.2768e-07, 1.0000e+00, 4.0940e-07],\n",
      "        [7.0511e-08, 3.8529e-08, 1.0000e+00, 7.6513e-07],\n",
      "        [5.3739e-07, 2.2194e-07, 1.0000e+00, 5.7814e-07],\n",
      "        [3.8922e-08, 4.7680e-08, 1.0000e+00, 2.0415e-06],\n",
      "        [4.3830e-07, 8.3617e-08, 1.0000e+00, 3.6428e-06],\n",
      "        [1.6745e-07, 6.5530e-08, 1.0000e+00, 5.3737e-07],\n",
      "        [1.0414e-06, 1.1055e-06, 1.0000e+00, 1.9990e-06],\n",
      "        [4.1265e-07, 1.4629e-07, 9.9999e-01, 6.3097e-06],\n",
      "        [4.3961e-08, 4.1728e-08, 1.0000e+00, 5.1706e-07],\n",
      "        [8.5308e-08, 5.7893e-08, 9.9999e-01, 5.7458e-06],\n",
      "        [4.4362e-07, 1.2824e-07, 1.0000e+00, 5.3372e-07],\n",
      "        [1.2214e-07, 4.4915e-08, 1.0000e+00, 1.5410e-06],\n",
      "        [5.1960e-08, 4.0868e-08, 1.0000e+00, 1.0778e-06],\n",
      "        [9.0170e-08, 9.2611e-08, 1.0000e+00, 4.8533e-07],\n",
      "        [7.6326e-07, 2.0757e-07, 1.0000e+00, 9.9904e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.2260e-10, 1.4269e-11, 1.5194e-10, 1.0000e+00],\n",
      "        [3.5577e-11, 3.4984e-12, 2.7335e-09, 1.0000e+00],\n",
      "        [4.5696e-11, 3.5707e-12, 4.1502e-10, 1.0000e+00],\n",
      "        [3.7647e-11, 2.2087e-12, 2.5157e-11, 1.0000e+00],\n",
      "        [8.5574e-12, 2.4081e-12, 1.0692e-09, 1.0000e+00],\n",
      "        [1.6326e-11, 4.0806e-12, 7.0479e-10, 1.0000e+00],\n",
      "        [9.3977e-11, 2.4897e-11, 8.1753e-08, 1.0000e+00],\n",
      "        [2.6392e-11, 3.0364e-12, 1.0785e-09, 1.0000e+00],\n",
      "        [7.5538e-11, 2.5257e-11, 2.5387e-07, 1.0000e+00],\n",
      "        [2.6782e-11, 1.4364e-12, 2.0951e-11, 1.0000e+00],\n",
      "        [4.5204e-11, 4.4010e-12, 3.3484e-10, 1.0000e+00],\n",
      "        [9.3599e-11, 5.3993e-12, 1.6775e-09, 1.0000e+00],\n",
      "        [9.6813e-12, 5.3006e-12, 3.0991e-10, 1.0000e+00],\n",
      "        [9.9288e-11, 5.6438e-12, 9.2656e-10, 1.0000e+00],\n",
      "        [9.6343e-11, 1.6261e-11, 6.4083e-09, 1.0000e+00],\n",
      "        [2.8518e-11, 5.1939e-12, 5.2413e-10, 1.0000e+00],\n",
      "        [5.4309e-11, 7.2284e-12, 1.8183e-09, 1.0000e+00],\n",
      "        [1.6871e-11, 1.4730e-11, 5.0403e-09, 1.0000e+00],\n",
      "        [2.4843e-10, 7.1312e-12, 7.0720e-09, 1.0000e+00],\n",
      "        [1.6746e-11, 9.8141e-12, 2.2950e-09, 1.0000e+00],\n",
      "        [3.9297e-11, 4.5394e-12, 1.2788e-09, 1.0000e+00],\n",
      "        [9.9808e-12, 8.6627e-12, 3.1184e-09, 1.0000e+00],\n",
      "        [8.8693e-12, 1.8388e-12, 4.9438e-10, 1.0000e+00],\n",
      "        [3.5677e-11, 3.5607e-12, 1.0471e-10, 1.0000e+00],\n",
      "        [2.1645e-11, 2.5297e-12, 1.8558e-09, 1.0000e+00],\n",
      "        [8.0726e-12, 4.6354e-12, 1.9080e-09, 1.0000e+00],\n",
      "        [2.2409e-11, 1.6026e-12, 3.9962e-11, 1.0000e+00],\n",
      "        [5.5655e-11, 4.7747e-12, 2.7379e-09, 1.0000e+00],\n",
      "        [6.0159e-11, 1.0013e-11, 1.0693e-10, 1.0000e+00],\n",
      "        [1.4706e-11, 2.0650e-12, 2.4085e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.5793) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[4.5009e-07, 9.9999e-01, 2.2784e-06, 5.3158e-06],\n",
      "        [3.5325e-07, 1.0000e+00, 2.8663e-07, 3.2551e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.7913e-09, 1.2760e-11, 2.6804e-08],\n",
      "        [1.0000e+00, 8.1104e-11, 1.0841e-11, 7.6067e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[4.2265e-08, 5.6110e-08, 1.0000e+00, 4.4615e-07],\n",
      "        [2.9141e-08, 3.0254e-08, 1.0000e+00, 4.9823e-07],\n",
      "        [1.1807e-07, 1.9260e-07, 1.0000e+00, 1.6950e-06],\n",
      "        [1.4918e-07, 1.3168e-07, 1.0000e+00, 2.1325e-06],\n",
      "        [2.0306e-07, 1.8515e-07, 1.0000e+00, 2.1617e-06],\n",
      "        [1.7925e-08, 4.2046e-08, 1.0000e+00, 1.0065e-06],\n",
      "        [3.1420e-08, 5.4772e-08, 1.0000e+00, 7.3724e-07],\n",
      "        [1.2076e-07, 9.2450e-08, 1.0000e+00, 2.4963e-06],\n",
      "        [1.4499e-07, 1.2620e-07, 9.9999e-01, 5.1398e-06],\n",
      "        [3.2992e-08, 6.4124e-08, 1.0000e+00, 2.0726e-06],\n",
      "        [8.5420e-08, 6.6458e-08, 1.0000e+00, 2.5501e-06],\n",
      "        [1.6062e-07, 1.5114e-07, 1.0000e+00, 1.6301e-06],\n",
      "        [1.4428e-07, 9.9450e-08, 1.0000e+00, 1.7951e-06],\n",
      "        [5.1002e-08, 5.2650e-08, 1.0000e+00, 1.7101e-06],\n",
      "        [7.0995e-08, 4.1350e-08, 1.0000e+00, 8.0234e-07],\n",
      "        [5.5335e-08, 3.6685e-08, 1.0000e+00, 1.8774e-06],\n",
      "        [2.8627e-07, 1.3438e-07, 1.0000e+00, 1.4157e-06],\n",
      "        [1.9962e-07, 8.7160e-08, 1.0000e+00, 1.1989e-06],\n",
      "        [4.0529e-07, 4.6103e-07, 1.0000e+00, 3.1133e-06],\n",
      "        [1.0703e-07, 5.0713e-08, 1.0000e+00, 1.5559e-06],\n",
      "        [2.1296e-07, 2.3826e-07, 9.9999e-01, 6.3236e-06],\n",
      "        [9.9087e-08, 2.9177e-07, 1.0000e+00, 2.3932e-06],\n",
      "        [1.3887e-06, 4.6224e-07, 1.0000e+00, 9.2420e-07],\n",
      "        [3.6103e-07, 2.3837e-07, 1.0000e+00, 1.1192e-06],\n",
      "        [3.9690e-08, 3.1767e-08, 1.0000e+00, 4.7953e-07],\n",
      "        [5.5659e-08, 4.9909e-08, 1.0000e+00, 1.2665e-06],\n",
      "        [7.4179e-08, 7.7229e-08, 1.0000e+00, 1.1585e-06],\n",
      "        [1.9408e-07, 5.9537e-08, 1.0000e+00, 2.5959e-06],\n",
      "        [1.7749e-08, 3.9234e-08, 1.0000e+00, 2.7752e-07],\n",
      "        [3.1145e-07, 1.1024e-07, 9.9999e-01, 9.7804e-06],\n",
      "        [5.7199e-08, 2.6279e-07, 1.0000e+00, 1.6738e-06],\n",
      "        [6.3944e-08, 2.9926e-08, 1.0000e+00, 3.4415e-06],\n",
      "        [4.8345e-07, 2.7306e-07, 1.0000e+00, 5.7082e-07],\n",
      "        [1.3955e-07, 3.1675e-07, 1.0000e+00, 9.4008e-07],\n",
      "        [7.2840e-08, 7.7274e-08, 1.0000e+00, 4.8858e-07],\n",
      "        [1.4617e-07, 1.2365e-07, 1.0000e+00, 1.7417e-06],\n",
      "        [1.7420e-07, 8.5949e-08, 1.0000e+00, 1.0542e-06],\n",
      "        [3.6075e-08, 2.6438e-08, 1.0000e+00, 6.0910e-07],\n",
      "        [3.8875e-08, 4.5554e-08, 1.0000e+00, 1.2814e-06],\n",
      "        [9.4955e-08, 1.3533e-07, 1.0000e+00, 2.5706e-06],\n",
      "        [7.7641e-08, 9.4586e-08, 1.0000e+00, 1.2776e-06],\n",
      "        [4.9084e-08, 8.4449e-08, 1.0000e+00, 1.4309e-06],\n",
      "        [2.2843e-07, 2.1605e-07, 1.0000e+00, 1.4432e-06],\n",
      "        [2.2227e-08, 2.9517e-08, 1.0000e+00, 4.1705e-07],\n",
      "        [2.6402e-08, 6.1652e-08, 1.0000e+00, 6.1418e-07],\n",
      "        [1.8516e-07, 1.6224e-07, 1.0000e+00, 2.4093e-06],\n",
      "        [1.0264e-07, 5.4651e-08, 1.0000e+00, 3.9960e-06],\n",
      "        [9.9562e-08, 1.0159e-07, 1.0000e+00, 1.4931e-06],\n",
      "        [2.0054e-07, 6.6781e-08, 9.9999e-01, 4.8236e-06],\n",
      "        [1.2990e-07, 1.2229e-07, 1.0000e+00, 7.0489e-07],\n",
      "        [1.2106e-07, 5.8498e-08, 1.0000e+00, 9.3450e-07],\n",
      "        [4.7556e-08, 7.0270e-08, 1.0000e+00, 4.4136e-06],\n",
      "        [7.1742e-08, 1.0672e-07, 1.0000e+00, 6.8023e-07],\n",
      "        [1.4097e-07, 7.4568e-08, 1.0000e+00, 1.3564e-06],\n",
      "        [1.0471e-07, 2.6153e-07, 1.0000e+00, 3.7530e-06],\n",
      "        [5.1627e-08, 2.3427e-07, 9.9999e-01, 7.4115e-06],\n",
      "        [4.9973e-07, 1.4843e-07, 1.0000e+00, 1.0132e-06],\n",
      "        [5.3584e-08, 6.0047e-08, 1.0000e+00, 8.6573e-07],\n",
      "        [6.6892e-08, 6.0693e-08, 1.0000e+00, 2.2745e-06],\n",
      "        [1.2911e-07, 1.1588e-07, 1.0000e+00, 1.6251e-06],\n",
      "        [1.8311e-07, 1.3412e-07, 1.0000e+00, 1.6205e-06],\n",
      "        [2.7375e-07, 1.0812e-07, 1.0000e+00, 1.2210e-06],\n",
      "        [3.2951e-08, 1.0274e-07, 1.0000e+00, 3.9090e-07],\n",
      "        [1.2827e-07, 3.9349e-08, 1.0000e+00, 2.8579e-06],\n",
      "        [3.3733e-07, 2.5746e-07, 1.0000e+00, 3.8256e-06],\n",
      "        [2.3231e-07, 1.5868e-07, 1.0000e+00, 2.5656e-06],\n",
      "        [1.4805e-07, 8.2145e-08, 1.0000e+00, 1.8575e-06],\n",
      "        [5.1455e-08, 8.5548e-08, 1.0000e+00, 9.5742e-07],\n",
      "        [2.1660e-07, 9.3953e-08, 1.0000e+00, 1.4715e-06],\n",
      "        [2.9731e-07, 7.7720e-08, 9.9999e-01, 8.1554e-06],\n",
      "        [4.5073e-08, 3.6953e-08, 1.0000e+00, 1.4166e-06],\n",
      "        [5.6680e-08, 2.6110e-08, 1.0000e+00, 2.9580e-06],\n",
      "        [6.1161e-08, 1.7076e-07, 1.0000e+00, 1.4757e-06],\n",
      "        [1.0223e-07, 6.1561e-08, 1.0000e+00, 1.5048e-06],\n",
      "        [7.4068e-08, 8.8387e-08, 1.0000e+00, 3.2932e-06],\n",
      "        [4.5887e-08, 5.5473e-08, 1.0000e+00, 1.5389e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[7.3839e-12, 8.1046e-13, 1.8557e-11, 1.0000e+00],\n",
      "        [4.3692e-11, 3.2862e-12, 2.5744e-10, 1.0000e+00],\n",
      "        [4.7683e-11, 4.9145e-12, 1.7066e-10, 1.0000e+00],\n",
      "        [1.5069e-11, 8.5230e-13, 3.8120e-11, 1.0000e+00],\n",
      "        [3.6144e-11, 1.1881e-11, 6.9364e-09, 1.0000e+00],\n",
      "        [1.1085e-10, 1.3048e-11, 7.6045e-08, 1.0000e+00],\n",
      "        [3.7660e-11, 9.3932e-12, 1.9218e-09, 1.0000e+00],\n",
      "        [5.5902e-11, 6.3755e-12, 1.1952e-09, 1.0000e+00],\n",
      "        [6.3079e-11, 3.6989e-12, 1.9445e-09, 1.0000e+00],\n",
      "        [1.2716e-11, 2.6375e-12, 1.8106e-10, 1.0000e+00],\n",
      "        [6.6910e-11, 1.5572e-11, 5.6309e-09, 1.0000e+00],\n",
      "        [2.5144e-11, 1.4360e-12, 2.0341e-10, 1.0000e+00],\n",
      "        [1.8962e-11, 4.8026e-12, 2.8659e-09, 1.0000e+00],\n",
      "        [1.8709e-11, 2.6409e-12, 3.8968e-10, 1.0000e+00],\n",
      "        [1.0650e-11, 1.9280e-12, 2.9855e-10, 1.0000e+00],\n",
      "        [2.7483e-11, 2.6521e-12, 3.7701e-10, 1.0000e+00],\n",
      "        [3.8874e-10, 3.3717e-11, 7.6168e-08, 1.0000e+00],\n",
      "        [1.3445e-11, 2.2532e-12, 1.1268e-09, 1.0000e+00],\n",
      "        [1.4158e-11, 2.4335e-12, 1.5488e-10, 1.0000e+00],\n",
      "        [2.8544e-10, 1.1855e-10, 3.9950e-08, 1.0000e+00],\n",
      "        [1.4395e-11, 2.0002e-12, 1.0487e-10, 1.0000e+00],\n",
      "        [7.2258e-11, 8.5058e-12, 6.6268e-09, 1.0000e+00],\n",
      "        [1.9090e-10, 2.2281e-11, 6.8205e-08, 1.0000e+00],\n",
      "        [3.0215e-11, 4.3537e-12, 1.8420e-09, 1.0000e+00],\n",
      "        [2.0680e-11, 3.3591e-12, 4.1205e-09, 1.0000e+00],\n",
      "        [1.8436e-11, 5.5497e-12, 8.0469e-10, 1.0000e+00],\n",
      "        [1.3385e-11, 3.0403e-12, 5.8159e-10, 1.0000e+00],\n",
      "        [5.0470e-11, 3.0339e-12, 2.9209e-09, 1.0000e+00],\n",
      "        [2.5577e-11, 1.8758e-11, 3.0249e-08, 1.0000e+00],\n",
      "        [1.5909e-11, 2.7573e-12, 4.6515e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.7103) tokens processed per second.\n",
      "Discriminator loss: tensor([[3.1235e-07, 9.9999e-01, 9.9583e-07, 7.4074e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 4.5735e-09, 1.1524e-10, 3.1359e-08]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[3.0128e-07, 1.1094e-07, 1.0000e+00, 3.9164e-06],\n",
      "        [4.5219e-08, 2.2260e-08, 1.0000e+00, 5.0440e-07],\n",
      "        [2.9832e-08, 5.9869e-08, 1.0000e+00, 2.6760e-06],\n",
      "        [9.1812e-08, 8.4988e-08, 1.0000e+00, 3.8153e-06],\n",
      "        [4.7098e-08, 7.3874e-08, 1.0000e+00, 3.5176e-07],\n",
      "        [2.9097e-06, 3.6467e-07, 9.9999e-01, 1.8407e-06],\n",
      "        [1.4083e-07, 1.2321e-07, 1.0000e+00, 1.0430e-06],\n",
      "        [2.0989e-07, 2.0622e-07, 1.0000e+00, 1.3645e-06],\n",
      "        [1.0368e-07, 4.2125e-08, 1.0000e+00, 1.4343e-06],\n",
      "        [1.3324e-07, 1.5972e-07, 1.0000e+00, 1.7771e-06],\n",
      "        [6.7597e-08, 1.0006e-07, 1.0000e+00, 1.0959e-06],\n",
      "        [1.0075e-07, 3.4807e-07, 1.0000e+00, 4.8408e-07],\n",
      "        [1.0853e-07, 1.1377e-07, 1.0000e+00, 1.5859e-06],\n",
      "        [1.8476e-07, 7.6039e-08, 1.0000e+00, 1.3650e-06],\n",
      "        [8.9008e-07, 2.9584e-07, 9.9999e-01, 5.0114e-06],\n",
      "        [9.6897e-08, 6.4152e-08, 1.0000e+00, 8.7346e-07],\n",
      "        [2.1881e-07, 1.1109e-07, 1.0000e+00, 8.6512e-07],\n",
      "        [1.3864e-07, 2.9719e-07, 1.0000e+00, 3.3147e-06],\n",
      "        [4.9012e-08, 2.9421e-08, 1.0000e+00, 7.7996e-07],\n",
      "        [5.4125e-08, 1.7944e-08, 1.0000e+00, 6.6177e-07],\n",
      "        [4.0926e-08, 7.3248e-08, 1.0000e+00, 1.3944e-06],\n",
      "        [7.3030e-08, 6.1324e-08, 1.0000e+00, 2.5770e-06],\n",
      "        [7.0925e-08, 5.6085e-08, 1.0000e+00, 1.4721e-06],\n",
      "        [1.8138e-07, 6.5924e-08, 1.0000e+00, 1.3127e-06],\n",
      "        [9.9875e-08, 7.7131e-08, 1.0000e+00, 8.0722e-07],\n",
      "        [9.1849e-08, 1.4116e-07, 1.0000e+00, 1.0269e-06],\n",
      "        [4.3258e-08, 1.2182e-07, 9.9999e-01, 7.6222e-06],\n",
      "        [9.2381e-08, 1.1427e-07, 1.0000e+00, 3.5540e-06],\n",
      "        [1.7820e-07, 2.1852e-07, 1.0000e+00, 7.5038e-07],\n",
      "        [1.1801e-07, 3.5796e-08, 1.0000e+00, 2.2118e-06],\n",
      "        [1.8378e-07, 6.6870e-08, 1.0000e+00, 1.7194e-06],\n",
      "        [7.9901e-08, 1.4048e-07, 1.0000e+00, 1.0758e-06],\n",
      "        [2.5355e-07, 1.3725e-07, 1.0000e+00, 8.4743e-07],\n",
      "        [1.6095e-07, 1.0017e-07, 1.0000e+00, 3.5332e-06],\n",
      "        [9.5672e-08, 9.4414e-08, 1.0000e+00, 1.8166e-06],\n",
      "        [8.8626e-08, 6.7562e-08, 1.0000e+00, 7.6532e-07],\n",
      "        [6.5524e-08, 7.0205e-08, 1.0000e+00, 8.7694e-07],\n",
      "        [2.0298e-07, 1.9459e-07, 1.0000e+00, 7.4312e-07],\n",
      "        [4.8663e-08, 3.7247e-08, 1.0000e+00, 1.7279e-06],\n",
      "        [8.9403e-08, 9.7317e-08, 1.0000e+00, 1.5164e-06],\n",
      "        [3.3277e-07, 9.3901e-08, 9.9999e-01, 8.5714e-06],\n",
      "        [5.8383e-08, 1.0200e-07, 1.0000e+00, 5.8493e-07],\n",
      "        [9.9403e-08, 8.7142e-08, 1.0000e+00, 2.4283e-06],\n",
      "        [2.7380e-07, 1.8508e-07, 1.0000e+00, 2.1875e-06],\n",
      "        [1.8532e-07, 6.1013e-08, 1.0000e+00, 1.8922e-06],\n",
      "        [2.5670e-07, 7.5477e-08, 1.0000e+00, 1.7085e-06],\n",
      "        [1.0345e-07, 3.7824e-07, 1.0000e+00, 4.5157e-07],\n",
      "        [6.4943e-08, 1.1479e-07, 1.0000e+00, 6.3992e-07],\n",
      "        [2.0384e-07, 1.3090e-07, 9.9999e-01, 5.2902e-06],\n",
      "        [2.5935e-07, 5.0189e-08, 1.0000e+00, 6.5998e-07],\n",
      "        [4.6161e-07, 8.7822e-08, 1.0000e+00, 3.3060e-06],\n",
      "        [1.2338e-07, 1.0612e-07, 1.0000e+00, 9.4339e-07],\n",
      "        [2.5090e-07, 9.2083e-08, 1.0000e+00, 1.3689e-06],\n",
      "        [3.8543e-08, 3.3300e-08, 1.0000e+00, 1.0548e-06],\n",
      "        [2.1465e-07, 1.0858e-07, 1.0000e+00, 3.5927e-06],\n",
      "        [4.6836e-07, 8.0675e-08, 9.9999e-01, 8.8013e-06],\n",
      "        [1.5898e-07, 5.6745e-08, 1.0000e+00, 2.4782e-06],\n",
      "        [9.6736e-08, 1.1797e-07, 1.0000e+00, 1.4050e-06],\n",
      "        [1.6498e-07, 8.7598e-08, 1.0000e+00, 1.4900e-06],\n",
      "        [1.0729e-07, 1.2992e-07, 1.0000e+00, 8.5415e-07],\n",
      "        [9.1282e-08, 3.5943e-08, 1.0000e+00, 1.0560e-06],\n",
      "        [1.9274e-07, 6.3845e-08, 1.0000e+00, 1.5978e-06],\n",
      "        [3.4037e-08, 5.6989e-08, 1.0000e+00, 1.3360e-06],\n",
      "        [3.5028e-08, 8.8574e-08, 1.0000e+00, 5.8234e-07],\n",
      "        [8.2785e-08, 2.0962e-07, 1.0000e+00, 2.1055e-06],\n",
      "        [1.3963e-06, 5.2082e-07, 1.0000e+00, 1.9922e-06],\n",
      "        [1.1987e-07, 8.9243e-08, 9.9999e-01, 6.2194e-06],\n",
      "        [4.2185e-07, 2.6398e-07, 1.0000e+00, 2.0258e-06],\n",
      "        [1.4910e-07, 1.1696e-07, 9.9999e-01, 6.2714e-06],\n",
      "        [1.4468e-07, 2.0073e-07, 1.0000e+00, 5.9253e-07],\n",
      "        [3.5258e-07, 1.2966e-07, 9.9999e-01, 8.4817e-06],\n",
      "        [9.7271e-08, 7.1146e-08, 1.0000e+00, 1.8153e-06],\n",
      "        [3.5188e-08, 7.0567e-08, 1.0000e+00, 6.4506e-07],\n",
      "        [2.3283e-07, 2.3353e-07, 9.9999e-01, 5.4918e-06],\n",
      "        [3.2883e-08, 1.0195e-07, 1.0000e+00, 8.9058e-07],\n",
      "        [6.6762e-08, 1.0018e-07, 1.0000e+00, 2.7123e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.5841e-11, 4.4109e-12, 1.0350e-09, 1.0000e+00],\n",
      "        [6.2877e-11, 2.7910e-12, 5.2211e-10, 1.0000e+00],\n",
      "        [1.9483e-11, 4.2881e-12, 8.7537e-10, 1.0000e+00],\n",
      "        [2.5187e-10, 8.4320e-11, 4.4788e-07, 1.0000e+00],\n",
      "        [1.3077e-10, 2.2353e-12, 1.4213e-09, 1.0000e+00],\n",
      "        [2.5471e-11, 1.2132e-12, 2.9392e-10, 1.0000e+00],\n",
      "        [2.4176e-11, 7.3690e-12, 2.1749e-09, 1.0000e+00],\n",
      "        [2.3727e-11, 7.6397e-12, 1.5055e-10, 1.0000e+00],\n",
      "        [1.1584e-11, 1.5167e-12, 9.1603e-11, 1.0000e+00],\n",
      "        [7.1271e-11, 9.5199e-12, 1.2536e-09, 1.0000e+00],\n",
      "        [5.2968e-11, 2.7157e-12, 4.5421e-11, 1.0000e+00],\n",
      "        [2.1996e-11, 8.9084e-12, 7.9186e-09, 1.0000e+00],\n",
      "        [7.4015e-11, 1.7566e-12, 4.5235e-10, 1.0000e+00],\n",
      "        [4.8771e-11, 1.9411e-11, 7.6706e-08, 1.0000e+00],\n",
      "        [5.4668e-11, 3.3109e-12, 2.7700e-10, 1.0000e+00],\n",
      "        [2.4919e-11, 3.4745e-12, 4.3292e-10, 1.0000e+00],\n",
      "        [5.6406e-11, 1.4390e-11, 1.0657e-08, 1.0000e+00],\n",
      "        [1.8035e-11, 2.8372e-12, 3.2593e-10, 1.0000e+00],\n",
      "        [2.9209e-11, 4.5394e-12, 2.9478e-10, 1.0000e+00],\n",
      "        [1.2978e-11, 2.2798e-12, 1.2660e-09, 1.0000e+00],\n",
      "        [6.2199e-11, 4.5891e-12, 3.9281e-10, 1.0000e+00],\n",
      "        [1.8140e-11, 9.9136e-12, 5.8825e-09, 1.0000e+00],\n",
      "        [7.3750e-11, 1.0275e-11, 4.9011e-09, 1.0000e+00],\n",
      "        [4.1803e-12, 1.1860e-12, 1.6656e-10, 1.0000e+00],\n",
      "        [4.3173e-11, 1.1962e-11, 2.1241e-09, 1.0000e+00],\n",
      "        [1.0945e-11, 5.1819e-12, 1.8032e-09, 1.0000e+00],\n",
      "        [2.3432e-11, 9.8144e-12, 7.6431e-10, 1.0000e+00],\n",
      "        [1.6840e-11, 1.5924e-12, 1.1085e-10, 1.0000e+00],\n",
      "        [1.4950e-10, 2.4218e-11, 2.4081e-08, 1.0000e+00],\n",
      "        [3.4026e-11, 1.1792e-11, 2.9391e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.9777) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.4248e-04, 9.9972e-01, 5.8430e-05, 7.9935e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.2423e-10, 3.2512e-11, 5.4499e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[4.6059e-08, 6.0817e-08, 1.0000e+00, 7.6750e-07],\n",
      "        [5.4015e-07, 1.6273e-07, 1.0000e+00, 1.5122e-06],\n",
      "        [6.7776e-08, 4.1190e-08, 1.0000e+00, 9.4586e-07],\n",
      "        [5.6934e-08, 1.9349e-07, 1.0000e+00, 7.1039e-07],\n",
      "        [2.3994e-08, 3.7517e-08, 1.0000e+00, 5.3623e-07],\n",
      "        [1.0730e-07, 6.6338e-08, 1.0000e+00, 1.4116e-06],\n",
      "        [5.9108e-08, 1.0095e-07, 1.0000e+00, 2.2330e-06],\n",
      "        [1.0951e-07, 3.7494e-08, 1.0000e+00, 6.1720e-07],\n",
      "        [5.3857e-08, 5.6998e-08, 1.0000e+00, 1.3046e-06],\n",
      "        [4.9382e-08, 5.8478e-08, 1.0000e+00, 1.0739e-06],\n",
      "        [5.1606e-08, 8.6939e-08, 1.0000e+00, 8.0598e-07],\n",
      "        [1.8418e-08, 3.4589e-08, 1.0000e+00, 3.8497e-07],\n",
      "        [9.5076e-07, 6.4364e-07, 1.0000e+00, 1.2091e-06],\n",
      "        [3.8880e-08, 1.1529e-07, 1.0000e+00, 1.6051e-06],\n",
      "        [1.9901e-07, 2.0687e-07, 1.0000e+00, 1.1357e-06],\n",
      "        [1.7859e-07, 1.3186e-07, 1.0000e+00, 1.3198e-06],\n",
      "        [3.9970e-08, 3.6507e-08, 1.0000e+00, 6.3724e-07],\n",
      "        [1.0521e-07, 9.4151e-08, 1.0000e+00, 2.0839e-06],\n",
      "        [8.4678e-08, 6.1794e-08, 1.0000e+00, 2.7477e-06],\n",
      "        [1.1745e-07, 5.6271e-08, 1.0000e+00, 1.8992e-06],\n",
      "        [2.1575e-07, 2.9301e-07, 1.0000e+00, 2.1410e-06],\n",
      "        [4.4441e-08, 5.2560e-08, 1.0000e+00, 8.9763e-07],\n",
      "        [3.5180e-08, 1.2018e-07, 1.0000e+00, 6.1419e-07],\n",
      "        [2.8234e-08, 4.7984e-08, 1.0000e+00, 1.9657e-06],\n",
      "        [9.8741e-08, 8.0216e-08, 1.0000e+00, 1.9456e-06],\n",
      "        [9.4868e-08, 7.5432e-08, 1.0000e+00, 1.0771e-06],\n",
      "        [8.6449e-08, 2.7104e-07, 1.0000e+00, 1.2389e-06],\n",
      "        [8.2481e-08, 8.6908e-08, 1.0000e+00, 4.4260e-07],\n",
      "        [6.6566e-08, 7.6927e-08, 1.0000e+00, 9.4763e-07],\n",
      "        [7.6736e-08, 6.1231e-08, 1.0000e+00, 9.2042e-07],\n",
      "        [3.0431e-07, 2.7622e-07, 1.0000e+00, 1.0086e-06],\n",
      "        [1.3839e-07, 5.7731e-08, 1.0000e+00, 1.9647e-06],\n",
      "        [1.3496e-07, 1.4058e-07, 1.0000e+00, 7.4128e-07],\n",
      "        [1.1764e-07, 1.7759e-07, 1.0000e+00, 1.1987e-06],\n",
      "        [1.5286e-08, 1.6613e-07, 1.0000e+00, 3.8621e-07],\n",
      "        [3.0215e-07, 1.2686e-07, 1.0000e+00, 7.7930e-07],\n",
      "        [6.8666e-08, 7.9038e-08, 1.0000e+00, 1.4182e-06],\n",
      "        [7.0590e-07, 3.3108e-07, 1.0000e+00, 1.8482e-06],\n",
      "        [6.2451e-08, 5.1887e-08, 1.0000e+00, 8.2003e-07],\n",
      "        [2.7446e-08, 4.0003e-08, 1.0000e+00, 1.4274e-06],\n",
      "        [2.5837e-06, 1.0921e-06, 9.9998e-01, 1.9023e-05],\n",
      "        [2.2677e-07, 1.4110e-07, 9.9999e-01, 8.9397e-06],\n",
      "        [4.3265e-08, 3.9292e-08, 1.0000e+00, 8.6969e-07],\n",
      "        [1.2952e-07, 1.0347e-07, 1.0000e+00, 1.8796e-06],\n",
      "        [3.5738e-08, 6.1306e-08, 1.0000e+00, 2.3202e-06],\n",
      "        [9.6108e-08, 4.2499e-08, 1.0000e+00, 2.6248e-06],\n",
      "        [2.5800e-08, 5.9292e-08, 1.0000e+00, 4.2265e-07],\n",
      "        [6.4712e-08, 6.5275e-08, 1.0000e+00, 1.1465e-06],\n",
      "        [1.4626e-07, 8.2969e-08, 1.0000e+00, 9.5787e-07],\n",
      "        [9.1772e-08, 1.0822e-07, 1.0000e+00, 1.0502e-06],\n",
      "        [1.3552e-07, 7.7893e-08, 1.0000e+00, 2.4392e-06],\n",
      "        [2.8952e-08, 4.5374e-08, 1.0000e+00, 5.1765e-07],\n",
      "        [1.4725e-06, 1.4335e-06, 9.9999e-01, 2.2845e-06],\n",
      "        [1.8326e-08, 9.9776e-08, 1.0000e+00, 4.9049e-07],\n",
      "        [3.1364e-08, 5.1653e-08, 1.0000e+00, 6.4726e-07],\n",
      "        [1.4019e-07, 1.3366e-07, 1.0000e+00, 7.9480e-07],\n",
      "        [1.4335e-07, 7.7777e-08, 1.0000e+00, 2.3205e-06],\n",
      "        [8.9361e-07, 4.7908e-07, 1.0000e+00, 4.8157e-07],\n",
      "        [1.0281e-07, 1.6818e-07, 1.0000e+00, 5.4895e-07],\n",
      "        [2.0478e-07, 1.4604e-07, 1.0000e+00, 1.3141e-06],\n",
      "        [5.0995e-08, 5.9372e-08, 1.0000e+00, 6.3829e-07],\n",
      "        [3.2888e-08, 4.6393e-08, 1.0000e+00, 1.0288e-06],\n",
      "        [3.9826e-08, 4.7140e-08, 1.0000e+00, 2.4297e-06],\n",
      "        [2.0149e-08, 8.8154e-08, 1.0000e+00, 8.6171e-07],\n",
      "        [9.4612e-08, 5.2391e-08, 1.0000e+00, 9.8036e-07],\n",
      "        [2.2827e-07, 1.5436e-07, 1.0000e+00, 1.8705e-06],\n",
      "        [6.0953e-08, 1.3285e-07, 1.0000e+00, 1.8560e-06],\n",
      "        [9.7759e-08, 1.5418e-07, 1.0000e+00, 1.5001e-06],\n",
      "        [1.1482e-07, 2.0095e-07, 1.0000e+00, 1.9556e-06],\n",
      "        [6.5559e-08, 1.2245e-07, 1.0000e+00, 5.9236e-07],\n",
      "        [2.3023e-07, 1.7301e-07, 1.0000e+00, 1.7571e-06],\n",
      "        [4.5536e-08, 6.5905e-08, 1.0000e+00, 6.9228e-07],\n",
      "        [5.2783e-08, 1.3374e-07, 1.0000e+00, 5.9804e-07],\n",
      "        [3.6184e-08, 5.1603e-08, 1.0000e+00, 3.0988e-06],\n",
      "        [8.9867e-08, 2.0466e-07, 1.0000e+00, 3.1489e-06],\n",
      "        [4.7937e-08, 1.3291e-07, 1.0000e+00, 2.2695e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.7536e-11, 3.8361e-12, 1.7725e-10, 1.0000e+00],\n",
      "        [1.9352e-11, 1.1857e-12, 1.6314e-10, 1.0000e+00],\n",
      "        [7.1308e-11, 1.6953e-12, 3.8085e-12, 1.0000e+00],\n",
      "        [7.4948e-11, 8.8888e-12, 4.5414e-09, 1.0000e+00],\n",
      "        [8.2174e-12, 2.0337e-12, 9.1630e-10, 1.0000e+00],\n",
      "        [7.7159e-11, 1.4705e-11, 1.3032e-07, 1.0000e+00],\n",
      "        [2.0880e-11, 6.6647e-12, 1.0422e-09, 1.0000e+00],\n",
      "        [2.7414e-11, 3.7996e-12, 8.7159e-12, 1.0000e+00],\n",
      "        [1.9936e-11, 4.9743e-12, 1.6624e-09, 1.0000e+00],\n",
      "        [3.6361e-11, 8.9264e-12, 3.1085e-09, 1.0000e+00],\n",
      "        [1.5076e-11, 1.7321e-12, 3.7269e-10, 1.0000e+00],\n",
      "        [1.7155e-11, 2.8596e-12, 2.1034e-09, 1.0000e+00],\n",
      "        [2.8759e-11, 2.9643e-12, 4.2931e-10, 1.0000e+00],\n",
      "        [2.3376e-11, 6.4860e-12, 1.2251e-09, 1.0000e+00],\n",
      "        [6.4877e-11, 2.7544e-11, 2.4816e-08, 1.0000e+00],\n",
      "        [1.4533e-10, 7.6960e-12, 3.3817e-10, 1.0000e+00],\n",
      "        [2.1008e-11, 5.6321e-12, 2.1361e-09, 1.0000e+00],\n",
      "        [1.6003e-11, 1.5117e-12, 5.8031e-10, 1.0000e+00],\n",
      "        [3.5356e-11, 5.0531e-12, 2.3400e-09, 1.0000e+00],\n",
      "        [2.5473e-11, 1.2140e-12, 6.8217e-12, 1.0000e+00],\n",
      "        [2.1015e-11, 3.8791e-12, 2.3140e-09, 1.0000e+00],\n",
      "        [3.7087e-11, 2.4652e-12, 3.3644e-10, 1.0000e+00],\n",
      "        [7.1681e-12, 1.5918e-12, 1.1540e-10, 1.0000e+00],\n",
      "        [1.1748e-11, 1.0145e-11, 2.2391e-09, 1.0000e+00],\n",
      "        [1.6914e-11, 1.5246e-12, 1.7894e-10, 1.0000e+00],\n",
      "        [2.2605e-10, 1.1774e-11, 1.4640e-08, 1.0000e+00],\n",
      "        [5.1170e-11, 6.3000e-12, 7.0940e-09, 1.0000e+00],\n",
      "        [1.1818e-11, 4.3084e-12, 6.5652e-10, 1.0000e+00],\n",
      "        [3.4062e-11, 5.9146e-12, 2.1420e-09, 1.0000e+00],\n",
      "        [3.7735e-11, 7.0732e-12, 4.2153e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.0655) tokens processed per second.\n",
      "Discriminator loss: tensor([[4.7884e-06, 9.9997e-01, 8.4442e-06, 1.2860e-05],\n",
      "        [3.5241e-05, 9.9995e-01, 1.0886e-06, 1.1251e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.3234e-10, 1.7193e-11, 6.0822e-09],\n",
      "        [1.0000e+00, 4.3741e-10, 2.9940e-11, 6.8771e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.8270e-08, 4.3606e-08, 1.0000e+00, 7.0606e-07],\n",
      "        [5.7827e-08, 9.9928e-08, 1.0000e+00, 7.3132e-07],\n",
      "        [3.2976e-08, 3.2191e-08, 1.0000e+00, 9.7438e-07],\n",
      "        [8.4389e-08, 8.1930e-08, 1.0000e+00, 7.4638e-07],\n",
      "        [2.2598e-08, 3.2873e-08, 1.0000e+00, 2.4074e-06],\n",
      "        [2.4933e-08, 9.4363e-08, 1.0000e+00, 5.9270e-07],\n",
      "        [6.2039e-08, 8.6027e-08, 1.0000e+00, 8.0519e-07],\n",
      "        [8.0446e-08, 1.6019e-07, 9.9999e-01, 8.1243e-06],\n",
      "        [2.4977e-08, 1.3033e-07, 1.0000e+00, 5.7961e-07],\n",
      "        [6.6980e-08, 6.4913e-08, 1.0000e+00, 8.6921e-07],\n",
      "        [2.8948e-08, 6.0981e-08, 1.0000e+00, 5.3600e-07],\n",
      "        [1.0957e-07, 1.4469e-07, 1.0000e+00, 1.5205e-06],\n",
      "        [4.7092e-08, 8.1359e-08, 1.0000e+00, 6.4197e-07],\n",
      "        [2.2797e-08, 5.8453e-08, 1.0000e+00, 1.2869e-06],\n",
      "        [5.0305e-08, 7.1191e-08, 1.0000e+00, 7.2650e-07],\n",
      "        [1.1102e-07, 8.2270e-08, 1.0000e+00, 1.0534e-06],\n",
      "        [1.0889e-07, 2.6549e-07, 1.0000e+00, 1.0032e-06],\n",
      "        [5.1489e-08, 4.9224e-08, 1.0000e+00, 2.0420e-06],\n",
      "        [2.0709e-07, 5.1569e-08, 1.0000e+00, 2.1957e-06],\n",
      "        [6.9213e-08, 8.4382e-08, 1.0000e+00, 7.9276e-07],\n",
      "        [1.3280e-07, 2.6982e-07, 1.0000e+00, 1.5330e-06],\n",
      "        [3.9309e-08, 1.0018e-07, 1.0000e+00, 5.1435e-07],\n",
      "        [8.2119e-08, 9.1650e-08, 1.0000e+00, 3.2270e-06],\n",
      "        [6.8806e-08, 4.4229e-08, 1.0000e+00, 2.5360e-07],\n",
      "        [1.4870e-08, 4.3292e-08, 1.0000e+00, 9.5044e-07],\n",
      "        [2.7090e-08, 1.0864e-07, 1.0000e+00, 2.0049e-06],\n",
      "        [1.2175e-07, 7.9099e-08, 1.0000e+00, 3.8077e-06],\n",
      "        [3.8266e-08, 6.2139e-08, 1.0000e+00, 3.3158e-06],\n",
      "        [5.4703e-08, 5.7652e-08, 1.0000e+00, 1.6075e-06],\n",
      "        [6.0717e-08, 1.3125e-07, 1.0000e+00, 4.3027e-07],\n",
      "        [9.1944e-08, 8.2154e-08, 1.0000e+00, 1.3607e-06],\n",
      "        [3.5706e-08, 6.7674e-08, 1.0000e+00, 1.0641e-06],\n",
      "        [8.9236e-08, 8.3221e-08, 1.0000e+00, 4.1148e-06],\n",
      "        [6.6034e-08, 1.0082e-07, 1.0000e+00, 8.8454e-07],\n",
      "        [9.8372e-08, 7.1431e-08, 1.0000e+00, 1.1290e-06],\n",
      "        [6.6712e-08, 9.3602e-08, 1.0000e+00, 7.2940e-07],\n",
      "        [2.3628e-07, 2.9812e-07, 1.0000e+00, 2.7621e-06],\n",
      "        [2.1785e-07, 8.8000e-08, 1.0000e+00, 7.8315e-07],\n",
      "        [7.6415e-09, 5.3489e-08, 1.0000e+00, 2.4642e-07],\n",
      "        [3.2861e-08, 9.6861e-08, 1.0000e+00, 5.7819e-07],\n",
      "        [4.1591e-08, 1.1070e-07, 1.0000e+00, 2.5726e-06],\n",
      "        [1.2854e-07, 2.0424e-07, 1.0000e+00, 2.0440e-06],\n",
      "        [1.3071e-07, 1.2107e-07, 1.0000e+00, 1.3104e-06],\n",
      "        [4.3737e-08, 5.9369e-08, 1.0000e+00, 1.6509e-06],\n",
      "        [4.3143e-08, 7.7312e-08, 1.0000e+00, 1.1875e-06],\n",
      "        [6.0537e-08, 6.4489e-08, 1.0000e+00, 1.0855e-06],\n",
      "        [3.8053e-08, 5.8177e-08, 1.0000e+00, 6.4200e-07],\n",
      "        [8.3715e-08, 8.1044e-08, 1.0000e+00, 2.9975e-07],\n",
      "        [6.3043e-08, 2.3300e-07, 1.0000e+00, 8.3979e-07],\n",
      "        [2.4008e-08, 5.5194e-08, 1.0000e+00, 2.0422e-07],\n",
      "        [1.9315e-06, 6.1400e-07, 9.9999e-01, 5.9149e-06],\n",
      "        [4.0148e-08, 4.3371e-08, 1.0000e+00, 7.4140e-07],\n",
      "        [5.7862e-08, 1.0472e-07, 1.0000e+00, 4.5353e-07],\n",
      "        [2.8779e-07, 4.1753e-07, 1.0000e+00, 3.6114e-07],\n",
      "        [2.8859e-08, 9.7712e-08, 1.0000e+00, 1.9216e-06],\n",
      "        [2.2976e-08, 2.2359e-08, 1.0000e+00, 6.0880e-07],\n",
      "        [4.5001e-08, 4.4896e-08, 1.0000e+00, 2.1560e-06],\n",
      "        [1.2792e-07, 7.0716e-08, 1.0000e+00, 1.1871e-06],\n",
      "        [4.9517e-08, 6.1655e-08, 1.0000e+00, 4.1172e-07],\n",
      "        [1.0099e-07, 5.9224e-08, 1.0000e+00, 1.0492e-06],\n",
      "        [3.2191e-08, 5.3316e-08, 1.0000e+00, 1.0346e-06],\n",
      "        [1.8398e-08, 2.2330e-08, 1.0000e+00, 5.5345e-07],\n",
      "        [6.3709e-07, 4.6316e-07, 9.9999e-01, 4.1944e-06],\n",
      "        [5.6279e-08, 1.1556e-07, 1.0000e+00, 1.6361e-06],\n",
      "        [2.9990e-08, 3.6215e-08, 1.0000e+00, 1.0482e-06],\n",
      "        [9.7646e-08, 1.1500e-07, 1.0000e+00, 1.4251e-06],\n",
      "        [2.8945e-08, 7.0257e-08, 1.0000e+00, 7.2619e-07],\n",
      "        [5.8138e-08, 7.1580e-08, 1.0000e+00, 3.8764e-06],\n",
      "        [3.7784e-08, 2.8031e-08, 1.0000e+00, 7.0305e-07],\n",
      "        [8.5167e-08, 1.2012e-07, 1.0000e+00, 3.4651e-07],\n",
      "        [7.5694e-08, 1.1258e-07, 1.0000e+00, 1.2478e-06],\n",
      "        [3.4002e-08, 7.5118e-08, 1.0000e+00, 6.0913e-07],\n",
      "        [7.6324e-07, 5.2200e-07, 9.9999e-01, 4.0878e-06],\n",
      "        [5.3417e-08, 8.7187e-08, 1.0000e+00, 8.7298e-07],\n",
      "        [6.0717e-08, 6.1776e-08, 1.0000e+00, 1.7929e-06],\n",
      "        [6.3489e-08, 1.9432e-07, 1.0000e+00, 3.7203e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[6.5779e-11, 4.2752e-12, 2.4579e-09, 1.0000e+00],\n",
      "        [2.1293e-11, 9.2032e-12, 1.1637e-09, 1.0000e+00],\n",
      "        [1.9838e-11, 1.3206e-11, 1.4464e-08, 1.0000e+00],\n",
      "        [1.1875e-10, 2.1353e-11, 5.0415e-08, 1.0000e+00],\n",
      "        [3.6341e-11, 4.3160e-12, 7.3021e-10, 1.0000e+00],\n",
      "        [1.7682e-11, 2.1203e-12, 1.4996e-09, 1.0000e+00],\n",
      "        [1.7026e-11, 1.2271e-12, 1.1311e-10, 1.0000e+00],\n",
      "        [2.4973e-11, 4.0009e-12, 4.1816e-09, 1.0000e+00],\n",
      "        [2.4384e-11, 3.5491e-12, 5.2391e-09, 1.0000e+00],\n",
      "        [8.2696e-11, 1.4526e-11, 4.6466e-09, 1.0000e+00],\n",
      "        [1.2461e-11, 2.2767e-12, 6.1655e-10, 1.0000e+00],\n",
      "        [3.0850e-11, 2.0416e-12, 3.9736e-10, 1.0000e+00],\n",
      "        [5.3266e-11, 9.9967e-13, 6.1197e-10, 1.0000e+00],\n",
      "        [1.6424e-11, 3.5086e-12, 4.4688e-09, 1.0000e+00],\n",
      "        [1.6237e-11, 1.4204e-12, 5.1935e-10, 1.0000e+00],\n",
      "        [1.9123e-11, 5.4599e-12, 8.4107e-10, 1.0000e+00],\n",
      "        [1.1493e-11, 5.7667e-12, 9.8238e-10, 1.0000e+00],\n",
      "        [1.3060e-11, 4.3240e-12, 8.8608e-10, 1.0000e+00],\n",
      "        [8.7022e-11, 3.8878e-12, 2.0119e-08, 1.0000e+00],\n",
      "        [5.0812e-11, 3.2003e-12, 1.9442e-10, 1.0000e+00],\n",
      "        [7.0608e-12, 9.1185e-13, 7.6303e-11, 1.0000e+00],\n",
      "        [3.9533e-11, 4.0048e-12, 1.3025e-09, 1.0000e+00],\n",
      "        [4.9564e-11, 4.2717e-12, 1.0574e-09, 1.0000e+00],\n",
      "        [3.0264e-11, 6.0126e-12, 2.7726e-09, 1.0000e+00],\n",
      "        [1.3957e-11, 2.0994e-12, 1.5629e-10, 1.0000e+00],\n",
      "        [4.0747e-11, 2.6085e-11, 4.7319e-08, 1.0000e+00],\n",
      "        [1.8514e-10, 2.1112e-11, 2.4447e-08, 1.0000e+00],\n",
      "        [3.2733e-11, 3.1877e-12, 5.5945e-09, 1.0000e+00],\n",
      "        [3.0109e-11, 3.1398e-12, 2.9654e-10, 1.0000e+00],\n",
      "        [5.6289e-11, 3.7871e-12, 5.4059e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.0782) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[4.7269e-06, 9.9998e-01, 3.5309e-07, 1.3602e-05],\n",
      "        [1.4645e-06, 9.9999e-01, 3.5923e-07, 3.2764e-06],\n",
      "        [2.0089e-07, 1.0000e+00, 1.9280e-06, 1.7012e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 7.4186e-12, 9.3044e-12, 1.4971e-09],\n",
      "        [1.0000e+00, 4.7642e-11, 6.6758e-12, 1.0112e-08],\n",
      "        [1.0000e+00, 1.0024e-10, 6.1001e-12, 5.4647e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[4.9394e-07, 5.0346e-07, 9.9999e-01, 4.8297e-06],\n",
      "        [5.9197e-08, 9.4650e-08, 1.0000e+00, 1.3271e-06],\n",
      "        [2.7995e-08, 5.5543e-08, 1.0000e+00, 1.3369e-06],\n",
      "        [5.9779e-08, 8.3317e-08, 1.0000e+00, 1.9869e-06],\n",
      "        [4.3427e-08, 5.8876e-08, 1.0000e+00, 7.6465e-07],\n",
      "        [1.2849e-07, 2.6227e-07, 1.0000e+00, 2.8429e-06],\n",
      "        [5.4323e-08, 6.8787e-08, 1.0000e+00, 7.1887e-07],\n",
      "        [1.9902e-07, 1.8888e-07, 1.0000e+00, 4.1629e-06],\n",
      "        [2.0032e-07, 1.9627e-07, 1.0000e+00, 3.4902e-06],\n",
      "        [1.1241e-07, 5.7819e-08, 1.0000e+00, 3.2228e-06],\n",
      "        [7.0480e-08, 1.6471e-07, 1.0000e+00, 2.0116e-06],\n",
      "        [6.0396e-08, 7.0299e-08, 1.0000e+00, 4.6402e-07],\n",
      "        [8.5216e-08, 2.0245e-07, 9.9998e-01, 1.7143e-05],\n",
      "        [6.3290e-08, 1.2396e-07, 1.0000e+00, 1.2013e-06],\n",
      "        [7.8405e-08, 1.0826e-07, 1.0000e+00, 1.4846e-06],\n",
      "        [7.2761e-08, 3.8306e-08, 1.0000e+00, 2.7177e-06],\n",
      "        [4.1764e-08, 6.1215e-08, 1.0000e+00, 2.0850e-06],\n",
      "        [5.3152e-08, 4.5571e-07, 9.9999e-01, 4.5164e-06],\n",
      "        [4.3785e-08, 1.3556e-07, 1.0000e+00, 2.3134e-06],\n",
      "        [2.1673e-08, 4.2050e-08, 1.0000e+00, 5.0831e-07],\n",
      "        [6.8507e-08, 9.5906e-08, 1.0000e+00, 1.0708e-06],\n",
      "        [3.8492e-07, 8.1636e-08, 9.9998e-01, 1.7810e-05],\n",
      "        [1.3090e-07, 2.0030e-07, 1.0000e+00, 3.6881e-06],\n",
      "        [4.0802e-08, 1.3141e-07, 1.0000e+00, 1.0886e-06],\n",
      "        [3.3945e-07, 1.4513e-07, 1.0000e+00, 2.0258e-06],\n",
      "        [1.5317e-07, 8.3225e-08, 1.0000e+00, 3.0320e-06],\n",
      "        [8.1428e-08, 1.6378e-07, 1.0000e+00, 3.7420e-06],\n",
      "        [4.3955e-08, 5.4310e-08, 1.0000e+00, 2.3636e-06],\n",
      "        [5.6338e-07, 3.8432e-07, 1.0000e+00, 1.3475e-06],\n",
      "        [1.7997e-08, 5.2108e-08, 1.0000e+00, 4.7394e-07],\n",
      "        [8.2386e-07, 1.7064e-07, 9.9999e-01, 4.8844e-06],\n",
      "        [8.0199e-08, 8.0543e-08, 1.0000e+00, 4.4679e-07],\n",
      "        [5.8670e-07, 9.0456e-07, 9.9999e-01, 8.5096e-06],\n",
      "        [4.5160e-08, 9.7997e-08, 1.0000e+00, 1.5504e-06],\n",
      "        [7.1167e-08, 6.8702e-08, 1.0000e+00, 2.6592e-06],\n",
      "        [1.0933e-07, 9.6155e-08, 1.0000e+00, 2.2406e-06],\n",
      "        [2.7852e-07, 1.3766e-07, 9.9999e-01, 9.5260e-06],\n",
      "        [1.2412e-07, 7.3911e-08, 1.0000e+00, 8.1712e-07],\n",
      "        [1.2070e-07, 5.6261e-08, 9.9999e-01, 5.4145e-06],\n",
      "        [4.6824e-07, 1.0047e-06, 1.0000e+00, 2.1941e-06],\n",
      "        [1.6605e-07, 1.1618e-07, 1.0000e+00, 3.9689e-06],\n",
      "        [9.9638e-08, 1.9747e-07, 1.0000e+00, 2.3775e-06],\n",
      "        [2.5563e-07, 1.3936e-07, 1.0000e+00, 1.6502e-06],\n",
      "        [2.9911e-07, 1.6398e-07, 1.0000e+00, 3.5628e-06],\n",
      "        [1.8944e-07, 7.8355e-08, 1.0000e+00, 1.2090e-06],\n",
      "        [9.7260e-08, 2.4885e-07, 9.9999e-01, 6.2302e-06],\n",
      "        [4.6438e-08, 6.3874e-08, 9.9999e-01, 8.9459e-06],\n",
      "        [8.1741e-08, 1.2204e-07, 9.9999e-01, 4.8299e-06],\n",
      "        [9.5165e-08, 7.7031e-08, 1.0000e+00, 3.0621e-06],\n",
      "        [8.6726e-08, 1.5328e-07, 1.0000e+00, 3.1923e-07],\n",
      "        [1.2877e-07, 2.0343e-07, 1.0000e+00, 9.7248e-07],\n",
      "        [9.1673e-08, 1.3277e-07, 1.0000e+00, 2.9389e-06],\n",
      "        [1.4266e-07, 1.3650e-07, 1.0000e+00, 2.7958e-06],\n",
      "        [1.4264e-07, 1.2086e-07, 1.0000e+00, 5.5229e-07],\n",
      "        [1.1795e-07, 8.9317e-08, 1.0000e+00, 8.2875e-07],\n",
      "        [1.2257e-07, 1.1427e-07, 1.0000e+00, 2.4426e-06],\n",
      "        [3.1968e-07, 2.2745e-07, 1.0000e+00, 4.1447e-06],\n",
      "        [5.8628e-08, 1.5204e-07, 1.0000e+00, 1.8490e-06],\n",
      "        [4.0956e-08, 9.2720e-08, 1.0000e+00, 9.5593e-07],\n",
      "        [4.2573e-08, 6.4156e-08, 1.0000e+00, 1.2993e-06],\n",
      "        [7.1454e-08, 1.2886e-07, 1.0000e+00, 1.5721e-06],\n",
      "        [5.6327e-07, 1.8310e-07, 1.0000e+00, 3.2692e-06],\n",
      "        [1.5590e-07, 2.0953e-07, 1.0000e+00, 2.2526e-06],\n",
      "        [1.0978e-07, 9.2920e-08, 1.0000e+00, 2.0869e-06],\n",
      "        [4.1789e-08, 5.2693e-08, 1.0000e+00, 5.8418e-07],\n",
      "        [4.6149e-08, 8.1820e-08, 1.0000e+00, 8.9353e-07],\n",
      "        [1.0728e-07, 6.5770e-08, 1.0000e+00, 2.2874e-06],\n",
      "        [2.0311e-07, 8.7300e-08, 1.0000e+00, 3.7310e-06],\n",
      "        [8.8982e-08, 1.3942e-07, 1.0000e+00, 1.0442e-06],\n",
      "        [1.0026e-06, 7.2734e-07, 9.9999e-01, 3.6021e-06],\n",
      "        [5.0727e-08, 9.9428e-08, 1.0000e+00, 2.0211e-06],\n",
      "        [3.5708e-08, 1.8072e-07, 1.0000e+00, 6.4581e-07],\n",
      "        [4.6905e-08, 5.6523e-08, 1.0000e+00, 4.0110e-06],\n",
      "        [6.3122e-07, 2.2446e-07, 9.9999e-01, 5.9731e-06],\n",
      "        [2.0300e-07, 4.8441e-07, 1.0000e+00, 1.3345e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[7.1452e-11, 5.0110e-12, 5.3831e-10, 1.0000e+00],\n",
      "        [2.3271e-11, 2.0317e-12, 4.9825e-10, 1.0000e+00],\n",
      "        [1.0525e-10, 4.1132e-12, 2.6134e-09, 1.0000e+00],\n",
      "        [9.1690e-12, 2.2831e-12, 3.4234e-10, 1.0000e+00],\n",
      "        [2.9353e-11, 1.8155e-11, 2.5213e-09, 1.0000e+00],\n",
      "        [5.2627e-11, 1.8001e-12, 1.7376e-10, 1.0000e+00],\n",
      "        [2.5104e-11, 2.1399e-12, 1.5600e-09, 1.0000e+00],\n",
      "        [2.0099e-11, 1.3020e-12, 1.1215e-10, 1.0000e+00],\n",
      "        [3.2838e-11, 7.2062e-13, 2.0551e-10, 1.0000e+00],\n",
      "        [3.4694e-11, 2.8469e-12, 2.1031e-10, 1.0000e+00],\n",
      "        [3.3255e-11, 2.1752e-12, 3.3240e-10, 1.0000e+00],\n",
      "        [3.2784e-11, 9.8770e-12, 2.3357e-09, 1.0000e+00],\n",
      "        [4.4590e-11, 4.5543e-12, 7.6331e-10, 1.0000e+00],\n",
      "        [3.8611e-11, 1.5921e-12, 1.4277e-10, 1.0000e+00],\n",
      "        [3.4275e-11, 2.9389e-12, 2.0735e-09, 1.0000e+00],\n",
      "        [1.5350e-11, 4.0198e-12, 1.0815e-09, 1.0000e+00],\n",
      "        [5.5530e-11, 3.4499e-12, 1.6560e-10, 1.0000e+00],\n",
      "        [1.4543e-11, 2.9928e-12, 2.1747e-10, 1.0000e+00],\n",
      "        [1.3564e-11, 2.9543e-12, 1.3771e-09, 1.0000e+00],\n",
      "        [1.8058e-11, 3.0239e-12, 5.1338e-10, 1.0000e+00],\n",
      "        [1.3255e-11, 4.7195e-12, 7.7311e-10, 1.0000e+00],\n",
      "        [3.5631e-11, 4.2795e-12, 1.9253e-09, 1.0000e+00],\n",
      "        [5.7396e-11, 2.0049e-12, 1.2007e-10, 1.0000e+00],\n",
      "        [7.0963e-11, 6.0600e-12, 4.0718e-10, 1.0000e+00],\n",
      "        [3.3732e-11, 2.5785e-12, 5.3403e-10, 1.0000e+00],\n",
      "        [3.8935e-11, 5.2725e-12, 3.9421e-09, 1.0000e+00],\n",
      "        [1.5405e-11, 1.5483e-12, 8.8406e-11, 1.0000e+00],\n",
      "        [1.0834e-11, 1.9913e-12, 1.5856e-10, 1.0000e+00],\n",
      "        [2.3482e-11, 3.0185e-12, 1.6013e-09, 1.0000e+00],\n",
      "        [1.1616e-11, 9.1009e-13, 1.0078e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.8428) tokens processed per second.\n",
      "Discriminator loss: tensor([[4.1039e-06, 9.9999e-01, 1.7804e-07, 7.4315e-07],\n",
      "        [3.4790e-06, 9.9999e-01, 4.3748e-07, 1.3866e-06],\n",
      "        [4.6721e-04, 9.9948e-01, 3.6881e-05, 1.8949e-05],\n",
      "        [7.7654e-06, 9.9999e-01, 2.9703e-07, 2.9425e-06],\n",
      "        [1.0342e-05, 9.9999e-01, 7.7392e-07, 1.8529e-06],\n",
      "        [4.4804e-06, 9.9999e-01, 4.2222e-07, 1.9676e-06],\n",
      "        [5.5030e-06, 9.9999e-01, 1.2044e-06, 2.9563e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 3.9594e-08, 7.5662e-09, 3.1388e-08],\n",
      "        [1.0000e+00, 2.8157e-07, 2.6696e-08, 6.2659e-08],\n",
      "        [1.0000e+00, 1.7417e-06, 3.0336e-08, 8.4315e-08],\n",
      "        [1.0000e+00, 1.1907e-08, 7.8333e-09, 1.0981e-08],\n",
      "        [1.0000e+00, 9.5495e-08, 2.3077e-08, 6.3106e-08],\n",
      "        [1.0000e+00, 4.1290e-07, 1.7038e-07, 2.1344e-07],\n",
      "        [1.0000e+00, 2.9880e-06, 3.9320e-07, 7.2447e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[9.8245e-05, 1.2536e-03, 9.9856e-01, 9.1731e-05],\n",
      "        [2.9637e-05, 1.5575e-03, 9.9827e-01, 1.4721e-04],\n",
      "        [6.7321e-05, 5.8919e-04, 9.9884e-01, 5.0743e-04],\n",
      "        [9.4023e-06, 3.3825e-04, 9.9938e-01, 2.6881e-04],\n",
      "        [9.3144e-06, 1.3831e-04, 9.9965e-01, 2.0233e-04],\n",
      "        [7.7017e-05, 1.4915e-03, 9.9826e-01, 1.7129e-04],\n",
      "        [6.3682e-05, 1.2492e-03, 9.9838e-01, 3.0688e-04],\n",
      "        [7.1948e-05, 7.0444e-04, 9.9906e-01, 1.6295e-04],\n",
      "        [5.3864e-05, 5.3041e-04, 9.9926e-01, 1.5704e-04],\n",
      "        [1.6963e-05, 3.5754e-04, 9.9948e-01, 1.4452e-04],\n",
      "        [4.1849e-05, 8.4943e-04, 9.9897e-01, 1.3666e-04],\n",
      "        [2.8833e-04, 1.7010e-03, 9.9792e-01, 9.2494e-05],\n",
      "        [2.3435e-04, 9.6440e-04, 9.9839e-01, 4.1380e-04],\n",
      "        [1.1259e-04, 3.4978e-03, 9.9533e-01, 1.0569e-03],\n",
      "        [2.0009e-04, 1.8170e-03, 9.9596e-01, 2.0248e-03],\n",
      "        [2.2256e-04, 1.2732e-03, 9.9824e-01, 2.6202e-04],\n",
      "        [4.2435e-05, 4.6535e-04, 9.9934e-01, 1.4757e-04],\n",
      "        [2.7048e-05, 4.4088e-04, 9.9935e-01, 1.8553e-04],\n",
      "        [3.7598e-05, 3.6281e-04, 9.9947e-01, 1.3020e-04],\n",
      "        [1.5510e-05, 6.4206e-04, 9.9912e-01, 2.1798e-04],\n",
      "        [5.0019e-05, 4.3984e-04, 9.9928e-01, 2.3051e-04],\n",
      "        [3.1332e-05, 1.4770e-03, 9.9806e-01, 4.2930e-04],\n",
      "        [8.6336e-05, 7.5778e-04, 9.9863e-01, 5.2513e-04],\n",
      "        [1.1576e-05, 5.8686e-04, 9.9932e-01, 8.0024e-05],\n",
      "        [4.2295e-05, 1.1021e-03, 9.9851e-01, 3.4337e-04],\n",
      "        [2.7857e-05, 4.0141e-04, 9.9931e-01, 2.6277e-04],\n",
      "        [1.2349e-04, 8.2158e-04, 9.9871e-01, 3.4199e-04],\n",
      "        [2.2730e-04, 1.0049e-03, 9.9822e-01, 5.4426e-04],\n",
      "        [5.1641e-05, 9.4594e-04, 9.9874e-01, 2.5912e-04],\n",
      "        [2.1502e-04, 1.7541e-03, 9.9673e-01, 1.2984e-03],\n",
      "        [5.6817e-05, 5.1088e-04, 9.9916e-01, 2.6963e-04],\n",
      "        [1.4815e-04, 2.2373e-03, 9.9744e-01, 1.7481e-04],\n",
      "        [3.4800e-05, 7.2400e-04, 9.9864e-01, 5.9825e-04],\n",
      "        [1.6515e-05, 7.1345e-04, 9.9910e-01, 1.6839e-04],\n",
      "        [3.7666e-05, 5.6935e-04, 9.9917e-01, 2.2514e-04],\n",
      "        [6.2327e-05, 6.5017e-04, 9.9877e-01, 5.2043e-04],\n",
      "        [8.2338e-06, 3.4666e-04, 9.9948e-01, 1.6233e-04],\n",
      "        [2.4911e-05, 4.9853e-04, 9.9938e-01, 9.4048e-05],\n",
      "        [6.0173e-05, 7.8463e-04, 9.9906e-01, 9.9869e-05],\n",
      "        [1.4749e-05, 7.3685e-04, 9.9915e-01, 1.0052e-04],\n",
      "        [3.0246e-05, 7.2817e-04, 9.9912e-01, 1.1864e-04],\n",
      "        [1.4074e-05, 2.6920e-04, 9.9963e-01, 8.5596e-05],\n",
      "        [3.5302e-04, 2.7355e-03, 9.9668e-01, 2.2897e-04],\n",
      "        [4.5168e-05, 7.1145e-04, 9.9908e-01, 1.6531e-04],\n",
      "        [2.9038e-05, 4.7363e-04, 9.9942e-01, 7.5206e-05],\n",
      "        [2.8469e-05, 8.3471e-04, 9.9855e-01, 5.8436e-04],\n",
      "        [4.2769e-05, 1.5130e-03, 9.9787e-01, 5.7691e-04],\n",
      "        [3.8482e-05, 8.7591e-04, 9.9887e-01, 2.1402e-04],\n",
      "        [8.3298e-05, 7.3446e-04, 9.9870e-01, 4.8199e-04],\n",
      "        [7.1377e-05, 2.0009e-03, 9.9776e-01, 1.6515e-04],\n",
      "        [3.1285e-05, 2.4454e-04, 9.9939e-01, 3.3149e-04],\n",
      "        [3.5733e-05, 9.1245e-04, 9.9894e-01, 1.1038e-04],\n",
      "        [3.3021e-05, 6.8943e-04, 9.9909e-01, 1.8410e-04],\n",
      "        [7.1888e-05, 7.2614e-04, 9.9905e-01, 1.5105e-04],\n",
      "        [5.6306e-05, 6.2330e-04, 9.9818e-01, 1.1415e-03],\n",
      "        [1.1685e-05, 5.4958e-04, 9.9918e-01, 2.5399e-04],\n",
      "        [2.1524e-05, 6.0318e-04, 9.9921e-01, 1.6449e-04],\n",
      "        [4.4084e-05, 5.9787e-04, 9.9912e-01, 2.3650e-04],\n",
      "        [5.2992e-05, 9.8493e-04, 9.9838e-01, 5.8008e-04],\n",
      "        [3.7627e-04, 1.4839e-03, 9.9751e-01, 6.2547e-04],\n",
      "        [5.0797e-05, 5.5417e-04, 9.9917e-01, 2.2623e-04],\n",
      "        [4.3092e-04, 1.3435e-03, 9.9702e-01, 1.2070e-03],\n",
      "        [2.6703e-05, 4.7568e-04, 9.9884e-01, 6.6018e-04],\n",
      "        [5.9987e-05, 1.8148e-03, 9.9746e-01, 6.6829e-04],\n",
      "        [1.1750e-04, 2.4843e-03, 9.9676e-01, 6.3441e-04],\n",
      "        [1.3615e-05, 5.5906e-04, 9.9920e-01, 2.2611e-04],\n",
      "        [1.3213e-04, 1.3721e-03, 9.9760e-01, 9.0003e-04],\n",
      "        [3.2559e-05, 5.5369e-04, 9.9927e-01, 1.4339e-04],\n",
      "        [3.1727e-05, 8.3902e-04, 9.9894e-01, 1.8746e-04],\n",
      "        [4.0666e-05, 3.8090e-04, 9.9945e-01, 1.2767e-04],\n",
      "        [9.4973e-06, 4.2748e-04, 9.9945e-01, 1.1701e-04],\n",
      "        [2.5047e-05, 5.0623e-04, 9.9908e-01, 3.9162e-04],\n",
      "        [4.9993e-05, 9.9891e-04, 9.9825e-01, 6.9893e-04],\n",
      "        [1.9462e-05, 9.6638e-04, 9.9891e-01, 1.0019e-04],\n",
      "        [2.5486e-05, 5.0706e-04, 9.9937e-01, 9.3870e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[3.5635e-10, 6.6405e-11, 1.7633e-11, 1.0000e+00],\n",
      "        [1.1715e-10, 9.8914e-11, 1.3568e-10, 1.0000e+00],\n",
      "        [2.0969e-10, 2.8078e-10, 6.9969e-10, 1.0000e+00],\n",
      "        [1.9015e-10, 6.4870e-11, 5.3304e-10, 1.0000e+00],\n",
      "        [3.1642e-10, 5.0654e-10, 2.9195e-08, 1.0000e+00],\n",
      "        [2.8325e-10, 5.1144e-11, 1.9045e-10, 1.0000e+00],\n",
      "        [1.5351e-10, 1.0021e-10, 4.2091e-10, 1.0000e+00],\n",
      "        [7.2776e-10, 1.4652e-10, 1.7059e-10, 1.0000e+00],\n",
      "        [2.4895e-10, 9.2769e-11, 9.9316e-11, 1.0000e+00],\n",
      "        [6.8067e-11, 1.5070e-10, 4.8095e-10, 1.0000e+00],\n",
      "        [3.7935e-10, 2.2729e-10, 2.5418e-09, 1.0000e+00],\n",
      "        [9.2108e-11, 2.5569e-10, 2.8635e-10, 1.0000e+00],\n",
      "        [2.0058e-10, 9.5873e-11, 8.6972e-10, 1.0000e+00],\n",
      "        [3.1318e-10, 3.8287e-10, 9.0862e-10, 1.0000e+00],\n",
      "        [3.9944e-10, 1.3609e-10, 7.6983e-10, 1.0000e+00],\n",
      "        [2.8406e-10, 5.3974e-11, 1.8350e-11, 1.0000e+00],\n",
      "        [2.5080e-10, 2.3810e-11, 3.3033e-12, 1.0000e+00],\n",
      "        [2.5026e-10, 6.0940e-11, 1.6985e-10, 1.0000e+00],\n",
      "        [3.3107e-10, 5.1648e-10, 1.1531e-09, 1.0000e+00],\n",
      "        [7.1914e-11, 3.6175e-11, 1.1463e-10, 1.0000e+00],\n",
      "        [7.6306e-11, 3.0666e-11, 6.9636e-11, 1.0000e+00],\n",
      "        [7.8240e-11, 1.5179e-10, 1.6864e-10, 1.0000e+00],\n",
      "        [4.6842e-10, 1.3583e-10, 6.7690e-10, 1.0000e+00],\n",
      "        [1.4309e-10, 5.2538e-11, 2.7930e-11, 1.0000e+00],\n",
      "        [2.3366e-10, 7.5882e-11, 1.0300e-10, 1.0000e+00],\n",
      "        [4.9584e-10, 3.6939e-10, 1.9446e-09, 1.0000e+00],\n",
      "        [3.3731e-10, 4.6285e-10, 4.6332e-09, 1.0000e+00],\n",
      "        [5.1019e-10, 1.1988e-10, 1.1503e-09, 1.0000e+00],\n",
      "        [6.2140e-11, 7.4989e-11, 5.3675e-11, 1.0000e+00],\n",
      "        [4.1185e-10, 2.1361e-10, 1.5023e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.0100) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[5.2095e-07, 9.9999e-01, 1.8046e-06, 3.6355e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.6103e-10, 4.4605e-11, 8.8813e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[8.4751e-06, 1.3468e-04, 9.9972e-01, 1.3399e-04],\n",
      "        [8.9186e-06, 1.9929e-04, 9.9972e-01, 6.8610e-05],\n",
      "        [1.1092e-05, 4.3977e-04, 9.9951e-01, 4.2837e-05],\n",
      "        [2.0118e-05, 3.9566e-04, 9.9951e-01, 7.1567e-05],\n",
      "        [9.2637e-06, 4.4976e-04, 9.9949e-01, 5.5932e-05],\n",
      "        [2.4086e-05, 2.4586e-04, 9.9965e-01, 7.8611e-05],\n",
      "        [1.6969e-05, 1.4872e-04, 9.9980e-01, 3.7534e-05],\n",
      "        [5.4942e-06, 3.5548e-04, 9.9961e-01, 2.7844e-05],\n",
      "        [1.9884e-05, 1.6892e-04, 9.9969e-01, 1.2142e-04],\n",
      "        [1.6485e-05, 5.7311e-04, 9.9933e-01, 8.4492e-05],\n",
      "        [1.1201e-05, 2.5575e-04, 9.9968e-01, 5.2174e-05],\n",
      "        [3.6477e-05, 5.0739e-04, 9.9936e-01, 9.7788e-05],\n",
      "        [1.1794e-05, 2.9955e-04, 9.9966e-01, 2.9781e-05],\n",
      "        [1.6586e-06, 6.4949e-05, 9.9992e-01, 1.4648e-05],\n",
      "        [6.7854e-06, 2.4753e-04, 9.9969e-01, 5.7927e-05],\n",
      "        [1.4604e-05, 1.9827e-04, 9.9977e-01, 1.6950e-05],\n",
      "        [5.0051e-06, 6.4489e-05, 9.9991e-01, 2.1793e-05],\n",
      "        [4.0247e-05, 1.0245e-03, 9.9873e-01, 2.0034e-04],\n",
      "        [1.6258e-05, 2.1587e-04, 9.9971e-01, 5.9379e-05],\n",
      "        [2.5101e-05, 3.1835e-04, 9.9962e-01, 3.2087e-05],\n",
      "        [1.1157e-05, 2.5574e-04, 9.9965e-01, 8.0308e-05],\n",
      "        [1.8086e-05, 1.9898e-04, 9.9972e-01, 6.1168e-05],\n",
      "        [1.2436e-04, 2.9718e-04, 9.9947e-01, 1.0574e-04],\n",
      "        [1.7765e-05, 1.3577e-04, 9.9980e-01, 4.7169e-05],\n",
      "        [1.5321e-05, 2.5531e-04, 9.9964e-01, 9.2278e-05],\n",
      "        [1.7773e-05, 1.9701e-04, 9.9975e-01, 3.9578e-05],\n",
      "        [9.5335e-06, 9.2844e-05, 9.9985e-01, 5.1383e-05],\n",
      "        [1.1884e-05, 3.2920e-04, 9.9958e-01, 7.4621e-05],\n",
      "        [4.8584e-05, 5.4137e-04, 9.9916e-01, 2.4790e-04],\n",
      "        [3.0183e-05, 4.7973e-04, 9.9940e-01, 9.4206e-05],\n",
      "        [3.7887e-06, 5.4578e-05, 9.9992e-01, 2.2122e-05],\n",
      "        [1.8348e-05, 1.8674e-04, 9.9978e-01, 1.1372e-05],\n",
      "        [2.9234e-05, 2.7873e-04, 9.9955e-01, 1.4296e-04],\n",
      "        [2.2315e-05, 6.9373e-04, 9.9923e-01, 5.4115e-05],\n",
      "        [7.0007e-06, 1.3647e-04, 9.9984e-01, 1.4524e-05],\n",
      "        [1.6363e-05, 3.1631e-04, 9.9957e-01, 9.9168e-05],\n",
      "        [1.3478e-05, 1.4693e-04, 9.9979e-01, 4.5551e-05],\n",
      "        [1.0977e-05, 1.8992e-04, 9.9967e-01, 1.2786e-04],\n",
      "        [4.8016e-05, 1.8243e-04, 9.9969e-01, 8.0130e-05],\n",
      "        [6.4464e-05, 9.6901e-04, 9.9880e-01, 1.6292e-04],\n",
      "        [5.9355e-06, 2.3083e-04, 9.9973e-01, 3.0076e-05],\n",
      "        [3.9377e-06, 8.9034e-05, 9.9985e-01, 6.1605e-05],\n",
      "        [1.3207e-05, 3.0061e-04, 9.9962e-01, 6.7827e-05],\n",
      "        [5.1692e-06, 1.1496e-04, 9.9986e-01, 2.4892e-05],\n",
      "        [1.3906e-05, 1.5421e-04, 9.9978e-01, 4.7042e-05],\n",
      "        [2.1891e-05, 2.1445e-04, 9.9968e-01, 8.3272e-05],\n",
      "        [2.4816e-05, 1.7140e-04, 9.9978e-01, 2.7984e-05],\n",
      "        [1.2044e-04, 4.6351e-04, 9.9930e-01, 1.1189e-04],\n",
      "        [1.4833e-05, 1.3015e-04, 9.9983e-01, 2.9810e-05],\n",
      "        [6.1145e-06, 1.2133e-04, 9.9986e-01, 1.6930e-05],\n",
      "        [1.7427e-05, 1.9259e-04, 9.9975e-01, 3.9031e-05],\n",
      "        [5.4835e-06, 1.8184e-04, 9.9974e-01, 6.8212e-05],\n",
      "        [5.3230e-05, 8.0017e-04, 9.9905e-01, 9.2977e-05],\n",
      "        [1.9068e-05, 5.9104e-05, 9.9988e-01, 4.5180e-05],\n",
      "        [6.9321e-06, 6.4074e-05, 9.9989e-01, 4.1719e-05],\n",
      "        [1.7358e-05, 1.9472e-04, 9.9973e-01, 5.7526e-05],\n",
      "        [4.8647e-06, 9.6625e-05, 9.9986e-01, 3.8576e-05],\n",
      "        [2.8031e-05, 4.4100e-04, 9.9948e-01, 5.1679e-05],\n",
      "        [1.0500e-05, 8.2095e-05, 9.9989e-01, 2.2173e-05],\n",
      "        [8.4359e-06, 1.3805e-04, 9.9978e-01, 7.8444e-05],\n",
      "        [1.7389e-05, 1.7616e-04, 9.9968e-01, 1.2686e-04],\n",
      "        [5.0128e-06, 1.4158e-04, 9.9982e-01, 3.1109e-05],\n",
      "        [1.0201e-05, 1.0137e-04, 9.9985e-01, 3.3438e-05],\n",
      "        [9.5873e-06, 1.0417e-04, 9.9984e-01, 4.3777e-05],\n",
      "        [4.9082e-06, 1.1687e-04, 9.9983e-01, 4.5123e-05],\n",
      "        [1.0238e-05, 2.1585e-04, 9.9975e-01, 1.9648e-05],\n",
      "        [6.4431e-06, 1.3085e-04, 9.9982e-01, 4.6057e-05],\n",
      "        [1.1838e-05, 1.7557e-04, 9.9973e-01, 8.7421e-05],\n",
      "        [4.4774e-05, 8.7547e-04, 9.9902e-01, 6.0067e-05],\n",
      "        [5.3457e-06, 8.2536e-05, 9.9986e-01, 4.9631e-05],\n",
      "        [7.7414e-06, 1.8554e-04, 9.9975e-01, 5.7574e-05],\n",
      "        [1.4932e-05, 4.8759e-04, 9.9944e-01, 6.0538e-05],\n",
      "        [7.5944e-06, 1.8849e-04, 9.9971e-01, 9.3158e-05],\n",
      "        [1.2941e-05, 5.5986e-04, 9.9938e-01, 4.5938e-05],\n",
      "        [2.3126e-05, 3.3171e-04, 9.9958e-01, 6.0529e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[2.7512e-10, 7.5404e-11, 6.1300e-09, 1.0000e+00],\n",
      "        [1.0097e-10, 4.8605e-11, 5.6000e-11, 1.0000e+00],\n",
      "        [7.9960e-11, 3.0970e-11, 1.7076e-10, 1.0000e+00],\n",
      "        [4.4826e-10, 1.7603e-10, 8.8866e-10, 1.0000e+00],\n",
      "        [1.1214e-10, 5.0606e-11, 1.7434e-10, 1.0000e+00],\n",
      "        [1.1302e-10, 7.0961e-11, 2.3230e-09, 1.0000e+00],\n",
      "        [1.4605e-09, 1.2982e-10, 7.6484e-10, 1.0000e+00],\n",
      "        [1.1091e-10, 1.0278e-10, 2.6977e-10, 1.0000e+00],\n",
      "        [4.6397e-11, 2.8383e-11, 2.1168e-10, 1.0000e+00],\n",
      "        [2.1978e-10, 9.8384e-11, 7.7456e-10, 1.0000e+00],\n",
      "        [9.0207e-10, 5.3284e-10, 1.2899e-08, 1.0000e+00],\n",
      "        [1.1513e-10, 6.3912e-10, 7.6416e-09, 1.0000e+00],\n",
      "        [1.1389e-10, 9.9541e-11, 1.6881e-09, 1.0000e+00],\n",
      "        [2.2197e-10, 1.7873e-10, 4.8317e-09, 1.0000e+00],\n",
      "        [5.8673e-10, 6.0218e-10, 3.4797e-09, 1.0000e+00],\n",
      "        [7.1497e-10, 1.7799e-10, 6.3736e-10, 1.0000e+00],\n",
      "        [8.2044e-11, 1.2778e-10, 2.3957e-09, 1.0000e+00],\n",
      "        [3.4871e-10, 2.2037e-10, 4.6713e-09, 1.0000e+00],\n",
      "        [1.6537e-10, 3.2022e-10, 1.8495e-09, 1.0000e+00],\n",
      "        [5.0698e-10, 2.0508e-10, 2.6597e-09, 1.0000e+00],\n",
      "        [6.8909e-11, 2.5583e-10, 1.1388e-08, 1.0000e+00],\n",
      "        [1.7120e-10, 3.9654e-10, 9.6928e-09, 1.0000e+00],\n",
      "        [4.6850e-11, 3.2833e-11, 3.0435e-10, 1.0000e+00],\n",
      "        [6.5826e-11, 1.0167e-10, 3.8556e-10, 1.0000e+00],\n",
      "        [3.9736e-10, 6.5581e-11, 1.0675e-09, 1.0000e+00],\n",
      "        [5.5156e-11, 1.8401e-11, 2.2291e-11, 1.0000e+00],\n",
      "        [1.3718e-10, 2.0856e-10, 9.2862e-09, 1.0000e+00],\n",
      "        [7.9000e-11, 3.1515e-11, 2.9270e-10, 1.0000e+00],\n",
      "        [4.4637e-10, 2.4004e-10, 1.8502e-09, 1.0000e+00],\n",
      "        [4.6628e-11, 4.4474e-11, 5.9236e-10, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.2637) tokens processed per second.\n",
      "Discriminator loss: tensor([[6.8389e-05, 9.9991e-01, 1.3241e-05, 4.8882e-06],\n",
      "        [3.3036e-07, 1.0000e+00, 2.8974e-06, 1.6912e-06],\n",
      "        [1.1502e-05, 9.9989e-01, 9.1823e-05, 1.0714e-05],\n",
      "        [1.4633e-07, 1.0000e+00, 9.5277e-07, 2.3435e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 3.2748e-09, 2.0054e-10, 1.0062e-08],\n",
      "        [1.0000e+00, 8.9733e-11, 6.9309e-11, 2.2535e-09],\n",
      "        [1.0000e+00, 7.6856e-11, 4.9519e-11, 2.2214e-09],\n",
      "        [1.0000e+00, 7.1639e-09, 6.5493e-10, 4.1675e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.6143e-05, 2.4444e-04, 9.9965e-01, 8.0582e-05],\n",
      "        [1.6038e-05, 2.2073e-04, 9.9975e-01, 1.4716e-05],\n",
      "        [3.6131e-06, 7.7008e-05, 9.9990e-01, 1.8525e-05],\n",
      "        [9.9616e-05, 8.8785e-04, 9.9881e-01, 2.0574e-04],\n",
      "        [8.4805e-07, 3.9895e-05, 9.9994e-01, 1.7171e-05],\n",
      "        [3.1730e-06, 9.7052e-05, 9.9986e-01, 4.3001e-05],\n",
      "        [5.5872e-05, 4.5305e-04, 9.9937e-01, 1.2262e-04],\n",
      "        [6.0087e-06, 1.2680e-04, 9.9984e-01, 3.0316e-05],\n",
      "        [9.1484e-06, 1.3772e-04, 9.9983e-01, 2.0187e-05],\n",
      "        [1.0425e-04, 7.7902e-04, 9.9899e-01, 1.2890e-04],\n",
      "        [1.3320e-05, 1.6366e-04, 9.9976e-01, 6.0597e-05],\n",
      "        [4.9659e-05, 4.0756e-04, 9.9945e-01, 9.2430e-05],\n",
      "        [5.4336e-06, 1.3034e-04, 9.9984e-01, 2.3280e-05],\n",
      "        [3.7800e-06, 5.8063e-05, 9.9993e-01, 3.5584e-06],\n",
      "        [8.5346e-07, 4.8607e-05, 9.9995e-01, 4.6713e-06],\n",
      "        [6.3831e-05, 3.3998e-04, 9.9952e-01, 7.1314e-05],\n",
      "        [5.8721e-06, 7.1370e-05, 9.9989e-01, 3.4072e-05],\n",
      "        [3.0321e-06, 1.0227e-04, 9.9987e-01, 1.9756e-05],\n",
      "        [2.4149e-06, 5.8849e-05, 9.9991e-01, 2.6360e-05],\n",
      "        [3.0374e-06, 2.3947e-05, 9.9997e-01, 5.0243e-06],\n",
      "        [3.5201e-06, 8.8229e-05, 9.9988e-01, 2.9609e-05],\n",
      "        [1.0548e-05, 9.7087e-05, 9.9987e-01, 2.6330e-05],\n",
      "        [3.2305e-06, 1.4156e-04, 9.9982e-01, 3.0918e-05],\n",
      "        [6.5506e-06, 1.3249e-04, 9.9985e-01, 9.6755e-06],\n",
      "        [2.4659e-06, 1.0786e-04, 9.9988e-01, 9.0090e-06],\n",
      "        [8.8494e-06, 1.2146e-04, 9.9982e-01, 4.6919e-05],\n",
      "        [1.6217e-05, 3.8958e-04, 9.9945e-01, 1.4031e-04],\n",
      "        [3.5880e-06, 4.7162e-05, 9.9994e-01, 1.2365e-05],\n",
      "        [2.7851e-06, 4.2823e-05, 9.9993e-01, 2.0395e-05],\n",
      "        [2.7652e-06, 8.7593e-05, 9.9990e-01, 1.2360e-05],\n",
      "        [7.9062e-05, 4.7834e-04, 9.9940e-01, 4.0654e-05],\n",
      "        [2.6296e-06, 1.1165e-04, 9.9987e-01, 1.7463e-05],\n",
      "        [6.1013e-06, 8.4588e-05, 9.9988e-01, 2.6347e-05],\n",
      "        [1.3818e-05, 1.1067e-04, 9.9982e-01, 5.3188e-05],\n",
      "        [1.5505e-05, 8.9105e-05, 9.9988e-01, 1.8266e-05],\n",
      "        [8.2454e-07, 2.5147e-05, 9.9997e-01, 4.3813e-06],\n",
      "        [1.5683e-06, 7.0258e-05, 9.9992e-01, 1.3065e-05],\n",
      "        [4.1520e-06, 3.3047e-05, 9.9994e-01, 1.8748e-05],\n",
      "        [8.0566e-06, 4.6083e-05, 9.9993e-01, 1.2715e-05],\n",
      "        [2.8813e-06, 3.0210e-05, 9.9996e-01, 6.9717e-06],\n",
      "        [2.3370e-05, 1.0610e-03, 9.9887e-01, 4.9691e-05],\n",
      "        [2.3371e-06, 8.9228e-05, 9.9990e-01, 4.8375e-06],\n",
      "        [4.4903e-05, 8.1050e-04, 9.9907e-01, 7.5722e-05],\n",
      "        [5.2489e-06, 1.0735e-04, 9.9985e-01, 4.2090e-05],\n",
      "        [1.4272e-05, 1.4650e-04, 9.9981e-01, 2.6196e-05],\n",
      "        [1.4609e-05, 2.5205e-05, 9.9994e-01, 1.9642e-05],\n",
      "        [2.4068e-05, 3.7504e-04, 9.9957e-01, 3.4232e-05],\n",
      "        [1.1070e-05, 1.8357e-04, 9.9967e-01, 1.3578e-04],\n",
      "        [4.1005e-06, 8.6982e-05, 9.9990e-01, 5.0488e-06],\n",
      "        [6.4612e-06, 1.0192e-04, 9.9987e-01, 2.2420e-05],\n",
      "        [7.7620e-06, 1.2093e-04, 9.9986e-01, 1.1080e-05],\n",
      "        [4.3412e-06, 2.5896e-05, 9.9994e-01, 2.6909e-05],\n",
      "        [6.0888e-06, 3.8873e-05, 9.9995e-01, 8.6313e-06],\n",
      "        [2.3204e-06, 5.2857e-05, 9.9994e-01, 8.2145e-06],\n",
      "        [9.0757e-06, 7.1680e-05, 9.9988e-01, 3.5799e-05],\n",
      "        [2.0107e-05, 1.8952e-04, 9.9976e-01, 3.4297e-05],\n",
      "        [1.3305e-05, 3.0755e-04, 9.9959e-01, 9.1013e-05],\n",
      "        [2.7132e-06, 3.6869e-05, 9.9992e-01, 3.7049e-05],\n",
      "        [5.0625e-05, 9.2096e-04, 9.9899e-01, 3.6153e-05],\n",
      "        [6.2345e-06, 7.8351e-05, 9.9990e-01, 1.8228e-05],\n",
      "        [2.8007e-06, 1.0545e-04, 9.9988e-01, 1.5519e-05],\n",
      "        [5.5367e-05, 4.2377e-04, 9.9933e-01, 1.8764e-04],\n",
      "        [1.1611e-05, 1.0191e-04, 9.9987e-01, 2.1119e-05],\n",
      "        [2.6721e-05, 5.1638e-04, 9.9892e-01, 5.3223e-04],\n",
      "        [1.5050e-05, 1.5029e-04, 9.9978e-01, 5.7008e-05],\n",
      "        [6.2540e-06, 1.1279e-04, 9.9985e-01, 3.1658e-05],\n",
      "        [1.1800e-06, 9.7344e-05, 9.9988e-01, 1.8519e-05],\n",
      "        [1.5572e-06, 2.8597e-05, 9.9996e-01, 6.0447e-06],\n",
      "        [4.1536e-06, 5.1681e-05, 9.9993e-01, 1.1881e-05],\n",
      "        [3.0769e-05, 2.0078e-04, 9.9975e-01, 1.7923e-05],\n",
      "        [2.3054e-06, 1.9975e-04, 9.9974e-01, 5.2998e-05],\n",
      "        [9.9872e-06, 4.6651e-05, 9.9992e-01, 2.4545e-05],\n",
      "        [2.8855e-06, 7.4237e-05, 9.9989e-01, 3.4224e-05],\n",
      "        [5.0873e-06, 5.2828e-05, 9.9992e-01, 1.7897e-05],\n",
      "        [4.6014e-06, 5.1628e-05, 9.9992e-01, 2.1940e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[9.9006e-11, 2.8004e-11, 7.3216e-10, 1.0000e+00],\n",
      "        [2.5215e-10, 5.9410e-11, 6.9639e-10, 1.0000e+00],\n",
      "        [1.7354e-10, 8.5884e-11, 4.0555e-09, 1.0000e+00],\n",
      "        [3.3239e-10, 3.4162e-11, 3.1869e-09, 1.0000e+00],\n",
      "        [1.1434e-10, 8.2899e-11, 2.7466e-10, 1.0000e+00],\n",
      "        [2.7860e-10, 5.1917e-11, 4.5489e-09, 1.0000e+00],\n",
      "        [2.2329e-10, 1.2313e-10, 3.3470e-10, 1.0000e+00],\n",
      "        [2.0214e-10, 3.8570e-10, 1.8791e-08, 1.0000e+00],\n",
      "        [1.1627e-10, 1.9084e-10, 2.2607e-08, 1.0000e+00],\n",
      "        [3.5880e-10, 3.4425e-11, 4.1414e-10, 1.0000e+00],\n",
      "        [6.2803e-11, 9.8283e-11, 2.4823e-09, 1.0000e+00],\n",
      "        [2.1004e-10, 9.9656e-11, 2.6248e-09, 1.0000e+00],\n",
      "        [2.8476e-10, 1.1887e-10, 1.9348e-09, 1.0000e+00],\n",
      "        [1.6343e-10, 1.0879e-10, 3.3240e-09, 1.0000e+00],\n",
      "        [2.7192e-10, 5.4844e-11, 1.3045e-09, 1.0000e+00],\n",
      "        [3.5265e-10, 4.5111e-11, 3.1445e-10, 1.0000e+00],\n",
      "        [2.2606e-10, 6.0970e-11, 1.4833e-09, 1.0000e+00],\n",
      "        [1.4624e-10, 1.2035e-10, 8.5580e-09, 1.0000e+00],\n",
      "        [1.7615e-10, 8.3038e-11, 1.0285e-09, 1.0000e+00],\n",
      "        [9.1392e-11, 7.9280e-11, 4.6402e-09, 1.0000e+00],\n",
      "        [2.7935e-10, 8.7514e-11, 9.0205e-10, 1.0000e+00],\n",
      "        [9.7485e-11, 4.7055e-11, 1.5082e-09, 1.0000e+00],\n",
      "        [1.6979e-10, 1.0461e-10, 1.5951e-09, 1.0000e+00],\n",
      "        [1.6496e-09, 2.0488e-10, 2.3704e-08, 1.0000e+00],\n",
      "        [1.4318e-10, 3.7740e-11, 1.5666e-09, 1.0000e+00],\n",
      "        [6.5208e-11, 7.1724e-11, 4.8308e-09, 1.0000e+00],\n",
      "        [5.1631e-11, 7.3155e-11, 8.6664e-10, 1.0000e+00],\n",
      "        [2.3340e-10, 5.3272e-11, 1.0269e-09, 1.0000e+00],\n",
      "        [5.6112e-10, 2.4848e-10, 3.2923e-08, 1.0000e+00],\n",
      "        [8.2937e-11, 3.3379e-11, 1.5696e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.5163) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[1.1070e-06, 1.0000e+00, 3.2225e-07, 1.8137e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.7630e-10, 5.1918e-11, 2.4248e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.1476e-06, 2.6608e-05, 9.9997e-01, 3.4912e-06],\n",
      "        [7.9701e-06, 9.3104e-05, 9.9989e-01, 1.2094e-05],\n",
      "        [4.7126e-06, 5.0973e-05, 9.9994e-01, 3.8268e-06],\n",
      "        [1.6626e-05, 1.9080e-04, 9.9977e-01, 1.9525e-05],\n",
      "        [1.6310e-06, 3.6919e-05, 9.9995e-01, 7.5080e-06],\n",
      "        [1.5118e-05, 2.4007e-04, 9.9966e-01, 8.6256e-05],\n",
      "        [2.3570e-06, 2.0429e-05, 9.9996e-01, 2.1814e-05],\n",
      "        [1.3578e-05, 7.2134e-05, 9.9989e-01, 2.2338e-05],\n",
      "        [5.7694e-06, 5.6295e-05, 9.9993e-01, 1.2578e-05],\n",
      "        [1.8940e-05, 2.1279e-04, 9.9971e-01, 5.9244e-05],\n",
      "        [1.3792e-06, 1.2921e-05, 9.9998e-01, 8.2097e-06],\n",
      "        [2.6287e-07, 1.9577e-05, 9.9998e-01, 1.4305e-06],\n",
      "        [2.4899e-06, 3.2272e-05, 9.9996e-01, 8.2375e-06],\n",
      "        [1.2663e-06, 7.2946e-05, 9.9992e-01, 6.3691e-06],\n",
      "        [2.4943e-06, 4.0076e-05, 9.9993e-01, 3.0562e-05],\n",
      "        [4.9784e-06, 8.5360e-05, 9.9988e-01, 3.0545e-05],\n",
      "        [4.1550e-06, 1.5838e-04, 9.9983e-01, 8.2553e-06],\n",
      "        [5.2404e-06, 3.3624e-05, 9.9994e-01, 2.4456e-05],\n",
      "        [1.6613e-05, 1.2160e-04, 9.9984e-01, 1.9242e-05],\n",
      "        [1.7436e-05, 1.4968e-04, 9.9964e-01, 1.8810e-04],\n",
      "        [9.5982e-07, 2.0700e-05, 9.9997e-01, 6.7418e-06],\n",
      "        [2.2713e-06, 6.1239e-05, 9.9993e-01, 1.1469e-05],\n",
      "        [1.7188e-06, 9.9075e-05, 9.9989e-01, 9.2583e-06],\n",
      "        [7.0220e-07, 1.8796e-05, 9.9998e-01, 5.4606e-06],\n",
      "        [1.4943e-05, 6.2071e-05, 9.9989e-01, 3.6019e-05],\n",
      "        [2.3610e-05, 1.1673e-04, 9.9985e-01, 9.2097e-06],\n",
      "        [5.0871e-06, 8.6788e-05, 9.9986e-01, 4.3981e-05],\n",
      "        [2.9775e-06, 4.8982e-05, 9.9992e-01, 2.5363e-05],\n",
      "        [2.3979e-06, 3.0032e-05, 9.9996e-01, 9.6412e-06],\n",
      "        [2.0134e-06, 6.3886e-05, 9.9992e-01, 1.2350e-05],\n",
      "        [5.1215e-06, 5.9077e-05, 9.9991e-01, 2.3685e-05],\n",
      "        [2.9018e-05, 8.5697e-05, 9.9988e-01, 7.7547e-06],\n",
      "        [1.1046e-05, 3.2100e-05, 9.9995e-01, 6.9107e-06],\n",
      "        [2.3905e-06, 5.4822e-05, 9.9993e-01, 9.4097e-06],\n",
      "        [6.8970e-07, 2.6035e-05, 9.9996e-01, 1.0897e-05],\n",
      "        [1.0100e-05, 3.3113e-05, 9.9993e-01, 2.2121e-05],\n",
      "        [1.8081e-06, 3.6500e-05, 9.9996e-01, 4.8611e-06],\n",
      "        [1.4763e-06, 1.7626e-05, 9.9997e-01, 1.1990e-05],\n",
      "        [3.5676e-05, 3.7267e-04, 9.9942e-01, 1.7048e-04],\n",
      "        [1.3875e-06, 3.4411e-05, 9.9995e-01, 1.8252e-05],\n",
      "        [1.4960e-06, 3.5532e-05, 9.9995e-01, 1.1291e-05],\n",
      "        [1.4218e-06, 1.3571e-05, 9.9998e-01, 3.4235e-06],\n",
      "        [2.9355e-05, 1.3178e-04, 9.9978e-01, 6.0319e-05],\n",
      "        [7.7536e-05, 1.8860e-04, 9.9971e-01, 2.0317e-05],\n",
      "        [5.8135e-06, 7.5356e-05, 9.9991e-01, 7.1666e-06],\n",
      "        [2.5354e-06, 7.0717e-05, 9.9992e-01, 5.8376e-06],\n",
      "        [3.4988e-06, 6.0717e-05, 9.9990e-01, 3.1686e-05],\n",
      "        [1.6446e-06, 3.8842e-05, 9.9996e-01, 2.8135e-06],\n",
      "        [3.0869e-06, 3.0429e-05, 9.9995e-01, 1.1814e-05],\n",
      "        [4.8918e-07, 3.4401e-05, 9.9996e-01, 4.0272e-06],\n",
      "        [1.4730e-05, 4.8992e-05, 9.9993e-01, 9.5210e-06],\n",
      "        [4.8148e-06, 2.8829e-05, 9.9995e-01, 1.9095e-05],\n",
      "        [7.4993e-06, 6.9339e-05, 9.9990e-01, 2.0880e-05],\n",
      "        [1.0669e-06, 1.8643e-05, 9.9997e-01, 1.0896e-05],\n",
      "        [2.2967e-06, 2.4347e-05, 9.9996e-01, 1.3698e-05],\n",
      "        [8.4062e-07, 3.1867e-05, 9.9996e-01, 1.0791e-05],\n",
      "        [1.6250e-04, 8.4325e-04, 9.9870e-01, 2.9787e-04],\n",
      "        [6.3893e-06, 5.4750e-05, 9.9992e-01, 1.4324e-05],\n",
      "        [3.8051e-06, 5.8704e-05, 9.9993e-01, 6.2536e-06],\n",
      "        [1.8801e-05, 6.1969e-05, 9.9989e-01, 2.9529e-05],\n",
      "        [5.9321e-07, 8.4903e-05, 9.9991e-01, 5.5939e-06],\n",
      "        [6.3880e-06, 3.2176e-05, 9.9995e-01, 1.2505e-05],\n",
      "        [1.4729e-05, 1.0407e-04, 9.9987e-01, 1.4954e-05],\n",
      "        [1.9625e-06, 3.6284e-05, 9.9995e-01, 1.6167e-05],\n",
      "        [2.6207e-06, 3.2845e-05, 9.9996e-01, 7.9871e-06],\n",
      "        [1.0655e-06, 4.5007e-05, 9.9995e-01, 5.9862e-06],\n",
      "        [2.7386e-06, 1.8589e-05, 9.9997e-01, 6.6400e-06],\n",
      "        [8.5443e-06, 4.1357e-04, 9.9953e-01, 4.9127e-05],\n",
      "        [1.4246e-06, 5.8591e-05, 9.9994e-01, 4.4270e-06],\n",
      "        [2.4787e-06, 3.5788e-05, 9.9995e-01, 1.0496e-05],\n",
      "        [1.0676e-06, 7.2848e-05, 9.9991e-01, 1.3675e-05],\n",
      "        [4.8781e-06, 5.7509e-05, 9.9993e-01, 7.4467e-06],\n",
      "        [1.8489e-06, 6.0110e-05, 9.9991e-01, 2.6706e-05],\n",
      "        [9.3229e-07, 1.7913e-05, 9.9998e-01, 3.7536e-06],\n",
      "        [8.7768e-06, 1.6537e-04, 9.9981e-01, 1.9397e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[9.5755e-11, 2.3168e-11, 1.0088e-09, 1.0000e+00],\n",
      "        [4.7574e-11, 5.4612e-11, 1.1769e-09, 1.0000e+00],\n",
      "        [1.0957e-10, 3.2087e-11, 2.3151e-10, 1.0000e+00],\n",
      "        [1.4342e-10, 6.0390e-11, 7.4231e-10, 1.0000e+00],\n",
      "        [1.7183e-10, 1.7448e-10, 1.0560e-08, 1.0000e+00],\n",
      "        [4.9235e-11, 4.5975e-11, 1.9642e-09, 1.0000e+00],\n",
      "        [2.0276e-10, 3.4114e-11, 2.4800e-09, 1.0000e+00],\n",
      "        [3.1501e-10, 4.0044e-10, 2.4458e-08, 1.0000e+00],\n",
      "        [5.8033e-11, 5.4538e-11, 1.1945e-09, 1.0000e+00],\n",
      "        [9.5446e-11, 7.4109e-11, 5.4290e-09, 1.0000e+00],\n",
      "        [1.3204e-10, 1.0691e-10, 3.8967e-09, 1.0000e+00],\n",
      "        [1.9355e-10, 5.1225e-11, 3.2020e-09, 1.0000e+00],\n",
      "        [3.1742e-10, 9.0908e-11, 7.6419e-10, 1.0000e+00],\n",
      "        [5.0634e-10, 1.8515e-10, 1.4898e-08, 1.0000e+00],\n",
      "        [8.2808e-10, 1.7147e-09, 3.7397e-07, 1.0000e+00],\n",
      "        [3.8073e-10, 7.1094e-11, 3.9155e-09, 1.0000e+00],\n",
      "        [7.7882e-11, 2.4003e-11, 6.0500e-11, 1.0000e+00],\n",
      "        [8.0285e-11, 7.6691e-11, 2.9627e-09, 1.0000e+00],\n",
      "        [9.7643e-11, 8.1918e-11, 1.1173e-09, 1.0000e+00],\n",
      "        [1.2765e-10, 2.1698e-10, 1.6930e-08, 1.0000e+00],\n",
      "        [4.0846e-10, 1.7922e-10, 6.6275e-09, 1.0000e+00],\n",
      "        [1.6196e-10, 3.0617e-11, 2.7451e-10, 1.0000e+00],\n",
      "        [1.6562e-10, 1.4772e-10, 2.7816e-09, 1.0000e+00],\n",
      "        [5.9829e-10, 2.4756e-10, 2.3899e-08, 1.0000e+00],\n",
      "        [3.9013e-10, 3.6238e-11, 1.5452e-10, 1.0000e+00],\n",
      "        [6.0445e-11, 2.7378e-11, 1.2927e-09, 1.0000e+00],\n",
      "        [6.4882e-11, 5.4340e-11, 6.6534e-10, 1.0000e+00],\n",
      "        [2.2752e-10, 1.4238e-10, 1.5117e-08, 1.0000e+00],\n",
      "        [6.6742e-10, 5.4656e-11, 1.4291e-10, 1.0000e+00],\n",
      "        [1.7172e-10, 7.4038e-11, 2.7508e-09, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.4171) tokens processed per second.\n",
      "Discriminator loss: tensor([[2.4894e-05, 9.9997e-01, 2.4205e-06, 6.5807e-06],\n",
      "        [9.2274e-06, 9.9994e-01, 4.5933e-05, 5.7521e-07],\n",
      "        [4.6227e-07, 1.0000e+00, 2.2594e-06, 2.6964e-07],\n",
      "        [8.2691e-08, 1.0000e+00, 2.2220e-06, 1.4727e-07],\n",
      "        [1.3863e-06, 9.9999e-01, 3.3617e-06, 1.6844e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 1.1076e-08, 1.2744e-08, 3.4041e-08],\n",
      "        [1.0000e+00, 2.6560e-08, 8.8060e-10, 8.1695e-09],\n",
      "        [1.0000e+00, 3.8898e-09, 1.4494e-09, 8.3214e-09],\n",
      "        [1.0000e+00, 3.3496e-08, 6.2015e-09, 3.5932e-08],\n",
      "        [1.0000e+00, 2.2541e-09, 4.3992e-10, 3.1713e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[2.1453e-07, 1.2527e-05, 9.9998e-01, 4.7021e-06],\n",
      "        [7.1865e-07, 1.7974e-05, 9.9998e-01, 2.8791e-06],\n",
      "        [9.7101e-07, 1.1857e-05, 9.9999e-01, 1.7967e-06],\n",
      "        [8.2637e-06, 3.3661e-05, 9.9994e-01, 1.4537e-05],\n",
      "        [3.2379e-06, 1.1071e-05, 9.9998e-01, 5.1567e-06],\n",
      "        [8.0264e-06, 2.7313e-04, 9.9970e-01, 2.3577e-05],\n",
      "        [4.4077e-06, 1.8874e-05, 9.9997e-01, 7.4507e-06],\n",
      "        [4.4796e-06, 9.4671e-05, 9.9989e-01, 1.1482e-05],\n",
      "        [1.3285e-05, 2.8793e-04, 9.9955e-01, 1.4530e-04],\n",
      "        [2.4555e-06, 2.4312e-05, 9.9996e-01, 1.0297e-05],\n",
      "        [1.4551e-05, 1.2594e-04, 9.9982e-01, 4.2924e-05],\n",
      "        [2.1027e-06, 1.6881e-05, 9.9998e-01, 5.5045e-06],\n",
      "        [2.6023e-07, 9.3104e-06, 9.9999e-01, 2.0474e-06],\n",
      "        [1.6129e-06, 3.1562e-05, 9.9996e-01, 9.1363e-06],\n",
      "        [2.5525e-06, 3.2238e-05, 9.9996e-01, 4.5495e-06],\n",
      "        [3.7041e-06, 5.4165e-05, 9.9994e-01, 4.5407e-06],\n",
      "        [7.9594e-07, 4.4055e-05, 9.9995e-01, 6.9712e-06],\n",
      "        [2.8698e-05, 3.0804e-04, 9.9960e-01, 5.8356e-05],\n",
      "        [9.6668e-06, 8.0830e-05, 9.9989e-01, 1.7114e-05],\n",
      "        [4.1631e-06, 7.4793e-05, 9.9991e-01, 6.8948e-06],\n",
      "        [7.5184e-07, 1.1385e-05, 9.9998e-01, 5.5006e-06],\n",
      "        [1.1632e-06, 1.7261e-05, 9.9998e-01, 3.2211e-06],\n",
      "        [6.6663e-07, 2.8195e-05, 9.9997e-01, 2.3473e-06],\n",
      "        [8.7626e-07, 1.5099e-05, 9.9998e-01, 3.4085e-06],\n",
      "        [1.3507e-05, 1.8882e-04, 9.9977e-01, 2.3407e-05],\n",
      "        [7.5734e-06, 7.3928e-05, 9.9990e-01, 2.1741e-05],\n",
      "        [4.6990e-06, 7.7044e-05, 9.9992e-01, 2.8642e-06],\n",
      "        [6.6760e-06, 5.0037e-05, 9.9991e-01, 3.1377e-05],\n",
      "        [1.6429e-06, 3.4760e-05, 9.9996e-01, 3.3217e-06],\n",
      "        [5.9990e-06, 3.7016e-05, 9.9995e-01, 1.0976e-05],\n",
      "        [1.0541e-06, 4.1877e-05, 9.9995e-01, 7.0239e-06],\n",
      "        [1.8555e-05, 3.9929e-04, 9.9926e-01, 3.1870e-04],\n",
      "        [1.0768e-06, 4.2518e-05, 9.9995e-01, 2.8218e-06],\n",
      "        [1.7509e-05, 5.6206e-05, 9.9992e-01, 6.4513e-06],\n",
      "        [3.3015e-07, 1.4709e-05, 9.9998e-01, 2.5349e-06],\n",
      "        [4.0409e-06, 8.1970e-05, 9.9990e-01, 1.8137e-05],\n",
      "        [4.2395e-06, 4.1370e-05, 9.9995e-01, 4.6853e-06],\n",
      "        [3.3372e-06, 3.4252e-05, 9.9995e-01, 9.9048e-06],\n",
      "        [2.1863e-05, 3.2648e-04, 9.9958e-01, 6.9877e-05],\n",
      "        [7.8642e-06, 2.7195e-05, 9.9993e-01, 3.2206e-05],\n",
      "        [1.9972e-06, 2.9238e-05, 9.9996e-01, 4.8141e-06],\n",
      "        [5.9913e-07, 2.4144e-05, 9.9997e-01, 5.2884e-06],\n",
      "        [7.9579e-07, 2.8508e-05, 9.9997e-01, 2.1245e-06],\n",
      "        [2.5685e-06, 3.7844e-05, 9.9996e-01, 3.1886e-06],\n",
      "        [3.9223e-06, 5.4184e-05, 9.9993e-01, 1.4282e-05],\n",
      "        [2.0864e-06, 2.8185e-05, 9.9996e-01, 6.2738e-06],\n",
      "        [2.0919e-06, 4.0267e-05, 9.9994e-01, 1.3114e-05],\n",
      "        [4.8855e-06, 3.6911e-05, 9.9995e-01, 5.0759e-06],\n",
      "        [4.3746e-07, 1.8692e-05, 9.9998e-01, 9.3808e-07],\n",
      "        [9.7514e-07, 1.3591e-05, 9.9998e-01, 7.5660e-06],\n",
      "        [2.5835e-06, 2.3767e-05, 9.9996e-01, 1.1277e-05],\n",
      "        [2.1238e-06, 1.8707e-05, 9.9997e-01, 5.5882e-06],\n",
      "        [1.0362e-06, 2.5907e-05, 9.9997e-01, 5.2137e-06],\n",
      "        [4.2100e-05, 1.5481e-04, 9.9978e-01, 2.6423e-05],\n",
      "        [8.1387e-07, 1.4098e-05, 9.9998e-01, 3.7412e-06],\n",
      "        [1.6542e-05, 3.7968e-04, 9.9955e-01, 5.7138e-05],\n",
      "        [7.2601e-07, 2.1612e-05, 9.9997e-01, 2.7309e-06],\n",
      "        [7.9549e-07, 1.1348e-05, 9.9998e-01, 5.3801e-06],\n",
      "        [2.2052e-05, 2.5670e-04, 9.9970e-01, 2.0716e-05],\n",
      "        [4.1252e-06, 1.1307e-04, 9.9987e-01, 9.5329e-06],\n",
      "        [4.0109e-07, 1.0737e-05, 9.9999e-01, 2.1528e-06],\n",
      "        [1.7287e-06, 2.5530e-05, 9.9997e-01, 5.0675e-06],\n",
      "        [1.3504e-05, 9.2979e-05, 9.9988e-01, 1.0564e-05],\n",
      "        [4.8522e-06, 3.2810e-05, 9.9992e-01, 3.8044e-05],\n",
      "        [5.6380e-07, 1.4256e-05, 9.9998e-01, 3.7778e-06],\n",
      "        [3.3552e-06, 8.3961e-05, 9.9990e-01, 1.1305e-05],\n",
      "        [8.7056e-07, 1.7640e-05, 9.9998e-01, 5.8640e-06],\n",
      "        [3.2571e-07, 2.4445e-05, 9.9997e-01, 2.7630e-06],\n",
      "        [1.5195e-06, 3.3072e-05, 9.9996e-01, 3.7014e-06],\n",
      "        [4.1840e-07, 1.7294e-05, 9.9998e-01, 1.8299e-06],\n",
      "        [5.8103e-07, 2.3803e-05, 9.9997e-01, 3.3072e-06],\n",
      "        [1.7998e-06, 1.7096e-05, 9.9997e-01, 1.4813e-05],\n",
      "        [2.0942e-06, 1.4376e-05, 9.9998e-01, 5.1263e-06],\n",
      "        [1.5879e-06, 1.7653e-05, 9.9998e-01, 4.3571e-06],\n",
      "        [1.6693e-06, 3.0186e-05, 9.9995e-01, 1.7920e-05]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[1.7599e-10, 2.7779e-11, 2.2990e-09, 1.0000e+00],\n",
      "        [5.5871e-11, 1.5098e-11, 3.2660e-10, 1.0000e+00],\n",
      "        [5.2148e-11, 6.8095e-11, 4.0661e-09, 1.0000e+00],\n",
      "        [7.7717e-11, 1.2046e-10, 1.0006e-08, 1.0000e+00],\n",
      "        [6.4363e-11, 7.1405e-12, 1.0371e-10, 1.0000e+00],\n",
      "        [5.4378e-10, 1.1628e-10, 3.0390e-09, 1.0000e+00],\n",
      "        [1.4982e-10, 1.3765e-10, 8.3364e-09, 1.0000e+00],\n",
      "        [5.7318e-11, 1.4138e-11, 2.7514e-10, 1.0000e+00],\n",
      "        [1.2542e-10, 6.7922e-11, 1.5854e-09, 1.0000e+00],\n",
      "        [6.4312e-10, 1.2494e-09, 2.7660e-07, 1.0000e+00],\n",
      "        [1.0413e-10, 9.9947e-11, 9.7727e-09, 1.0000e+00],\n",
      "        [5.6327e-11, 9.6015e-11, 3.8482e-09, 1.0000e+00],\n",
      "        [4.4993e-11, 6.0654e-11, 1.7253e-09, 1.0000e+00],\n",
      "        [7.1065e-10, 2.9796e-10, 1.6233e-08, 1.0000e+00],\n",
      "        [5.5328e-10, 1.7163e-10, 8.4806e-09, 1.0000e+00],\n",
      "        [5.6998e-11, 2.3166e-11, 1.1635e-09, 1.0000e+00],\n",
      "        [4.3942e-11, 2.5035e-11, 8.6405e-10, 1.0000e+00],\n",
      "        [2.9126e-10, 8.5274e-10, 5.0073e-09, 1.0000e+00],\n",
      "        [1.6201e-10, 4.4198e-11, 1.9115e-09, 1.0000e+00],\n",
      "        [6.0848e-11, 1.9861e-11, 1.4311e-10, 1.0000e+00],\n",
      "        [6.8337e-11, 4.0277e-11, 1.2356e-10, 1.0000e+00],\n",
      "        [1.2110e-10, 1.9849e-10, 2.9984e-09, 1.0000e+00],\n",
      "        [1.6758e-10, 1.8283e-10, 4.5946e-08, 1.0000e+00],\n",
      "        [3.0848e-10, 1.8694e-10, 1.3474e-09, 1.0000e+00],\n",
      "        [4.9300e-11, 2.0990e-10, 6.3562e-09, 1.0000e+00],\n",
      "        [2.8786e-10, 9.3052e-11, 5.0137e-09, 1.0000e+00],\n",
      "        [1.5682e-10, 9.8883e-11, 7.6093e-09, 1.0000e+00],\n",
      "        [9.6572e-11, 2.1990e-11, 9.0138e-10, 1.0000e+00],\n",
      "        [1.8642e-10, 1.4707e-10, 1.1744e-08, 1.0000e+00],\n",
      "        [5.4563e-10, 5.1334e-10, 1.2944e-08, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.4871) tokens processed per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[6.5964e-06, 9.9999e-01, 1.0020e-06, 4.3576e-06],\n",
      "        [1.2198e-07, 1.0000e+00, 8.5718e-07, 5.1309e-07],\n",
      "        [7.5644e-07, 9.9999e-01, 1.1730e-05, 3.2769e-07],\n",
      "        [1.3659e-07, 9.9997e-01, 2.7431e-05, 1.1061e-06],\n",
      "        [2.7320e-06, 9.9999e-01, 5.2171e-06, 3.6604e-07],\n",
      "        [5.4293e-07, 9.9999e-01, 5.5642e-06, 5.4437e-07],\n",
      "        [9.7248e-06, 9.9995e-01, 3.7482e-05, 1.3198e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 3.3162e-06, 2.2240e-07, 5.4766e-08],\n",
      "        [1.0000e+00, 1.2546e-08, 2.0772e-08, 4.2853e-09],\n",
      "        [1.0000e+00, 1.3654e-08, 2.8900e-09, 4.5572e-09],\n",
      "        [1.0000e+00, 1.5778e-07, 7.2570e-08, 1.5378e-08],\n",
      "        [1.0000e+00, 1.3705e-06, 1.7641e-07, 8.5396e-08],\n",
      "        [1.0000e+00, 1.1220e-07, 5.4359e-08, 3.3153e-08],\n",
      "        [1.0000e+00, 1.6533e-06, 3.3109e-08, 1.5325e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[1.1370e-07, 2.4390e-05, 9.9997e-01, 2.1818e-06],\n",
      "        [2.3117e-06, 2.9804e-05, 9.9996e-01, 6.1584e-06],\n",
      "        [5.9131e-07, 2.4336e-05, 9.9997e-01, 6.4977e-06],\n",
      "        [1.0423e-06, 1.4637e-04, 9.9985e-01, 3.6264e-06],\n",
      "        [7.0050e-07, 2.9466e-05, 9.9996e-01, 5.0142e-06],\n",
      "        [1.0674e-06, 3.2060e-05, 9.9996e-01, 2.4975e-06],\n",
      "        [3.7598e-06, 1.0111e-04, 9.9989e-01, 2.7700e-06],\n",
      "        [6.3604e-07, 6.5982e-05, 9.9993e-01, 4.5546e-06],\n",
      "        [1.4354e-06, 3.7830e-05, 9.9995e-01, 9.4241e-06],\n",
      "        [1.0919e-06, 4.0493e-05, 9.9995e-01, 5.7097e-06],\n",
      "        [7.5379e-07, 3.9939e-05, 9.9995e-01, 1.0486e-05],\n",
      "        [3.8940e-06, 3.8220e-05, 9.9994e-01, 1.3454e-05],\n",
      "        [1.9394e-06, 3.7629e-05, 9.9995e-01, 8.8830e-06],\n",
      "        [9.0792e-07, 3.2044e-05, 9.9996e-01, 3.8347e-06],\n",
      "        [2.4211e-06, 4.9328e-05, 9.9994e-01, 7.7872e-06],\n",
      "        [6.4692e-07, 2.5191e-05, 9.9997e-01, 5.5173e-06],\n",
      "        [1.0894e-05, 1.3711e-04, 9.9984e-01, 1.4348e-05],\n",
      "        [8.3046e-07, 6.6364e-05, 9.9993e-01, 5.4076e-06],\n",
      "        [7.2366e-07, 2.2485e-05, 9.9997e-01, 7.8496e-06],\n",
      "        [6.2018e-06, 1.0703e-04, 9.9988e-01, 6.7981e-06],\n",
      "        [1.1150e-06, 5.2815e-05, 9.9994e-01, 3.8546e-06],\n",
      "        [7.5084e-07, 7.4528e-05, 9.9992e-01, 5.7624e-06],\n",
      "        [6.7937e-07, 7.8135e-05, 9.9991e-01, 7.5450e-06],\n",
      "        [3.0148e-06, 3.1645e-04, 9.9966e-01, 2.0913e-05],\n",
      "        [2.5884e-06, 9.2888e-05, 9.9987e-01, 3.2378e-05],\n",
      "        [6.0652e-07, 4.2543e-05, 9.9995e-01, 3.5743e-06],\n",
      "        [4.9971e-06, 1.2305e-04, 9.9986e-01, 7.1429e-06],\n",
      "        [2.3724e-07, 1.2477e-05, 9.9998e-01, 7.3751e-06],\n",
      "        [9.4194e-07, 3.5460e-05, 9.9996e-01, 2.6339e-06],\n",
      "        [5.7581e-06, 9.0942e-05, 9.9989e-01, 1.7328e-05],\n",
      "        [4.2660e-07, 1.5848e-05, 9.9998e-01, 5.7029e-06],\n",
      "        [9.1244e-07, 3.1783e-05, 9.9996e-01, 4.5750e-06],\n",
      "        [2.5225e-06, 4.0349e-05, 9.9995e-01, 3.0044e-06],\n",
      "        [1.2961e-05, 1.4534e-04, 9.9983e-01, 1.1066e-05],\n",
      "        [1.2607e-06, 7.9915e-05, 9.9991e-01, 8.8304e-06],\n",
      "        [4.7227e-07, 1.1706e-05, 9.9999e-01, 2.4082e-06],\n",
      "        [1.8745e-07, 3.6426e-05, 9.9996e-01, 2.3293e-06],\n",
      "        [4.6740e-07, 3.6350e-05, 9.9996e-01, 4.8186e-06],\n",
      "        [4.1635e-06, 4.2517e-05, 9.9994e-01, 1.0331e-05],\n",
      "        [3.4611e-07, 2.5355e-05, 9.9997e-01, 4.6461e-06],\n",
      "        [1.8686e-06, 4.2454e-05, 9.9995e-01, 4.4752e-06],\n",
      "        [8.4050e-07, 6.0345e-05, 9.9993e-01, 5.3968e-06],\n",
      "        [5.1577e-07, 7.0518e-05, 9.9993e-01, 3.1033e-06],\n",
      "        [2.8795e-07, 2.7931e-05, 9.9997e-01, 1.5271e-06],\n",
      "        [1.5818e-06, 1.6752e-05, 9.9998e-01, 4.5392e-06],\n",
      "        [7.8751e-07, 6.1341e-05, 9.9993e-01, 5.8600e-06],\n",
      "        [3.7264e-06, 1.3122e-04, 9.9984e-01, 2.0497e-05],\n",
      "        [1.0134e-06, 6.3665e-05, 9.9993e-01, 3.0091e-06],\n",
      "        [7.0898e-07, 1.3727e-05, 9.9998e-01, 2.1380e-06],\n",
      "        [2.1915e-06, 3.8643e-04, 9.9958e-01, 2.8336e-05],\n",
      "        [5.2473e-06, 1.0863e-04, 9.9987e-01, 1.4458e-05],\n",
      "        [8.9328e-07, 2.5775e-05, 9.9997e-01, 4.3600e-06],\n",
      "        [6.7441e-07, 5.1791e-05, 9.9994e-01, 5.0329e-06],\n",
      "        [1.3503e-06, 4.3429e-05, 9.9994e-01, 1.3793e-05],\n",
      "        [1.2385e-06, 2.4483e-05, 9.9997e-01, 4.5767e-06],\n",
      "        [7.2549e-07, 4.3293e-05, 9.9995e-01, 3.9900e-06],\n",
      "        [2.0627e-07, 1.4764e-05, 9.9998e-01, 2.5503e-06],\n",
      "        [1.3350e-06, 3.4440e-05, 9.9996e-01, 7.0546e-06],\n",
      "        [1.5707e-06, 6.2692e-05, 9.9993e-01, 7.4599e-06],\n",
      "        [3.2045e-06, 3.0549e-05, 9.9996e-01, 6.7057e-06],\n",
      "        [9.0025e-07, 2.2539e-05, 9.9997e-01, 4.6046e-06],\n",
      "        [7.6045e-07, 3.5815e-05, 9.9995e-01, 1.5426e-05],\n",
      "        [1.3760e-06, 2.0997e-05, 9.9996e-01, 1.3472e-05],\n",
      "        [1.2395e-06, 2.9529e-05, 9.9996e-01, 6.9923e-06],\n",
      "        [1.3328e-06, 4.6679e-05, 9.9995e-01, 4.2978e-06],\n",
      "        [4.8699e-06, 7.2337e-05, 9.9991e-01, 9.9286e-06],\n",
      "        [1.7753e-06, 5.9540e-05, 9.9993e-01, 4.2253e-06],\n",
      "        [2.0360e-06, 1.1699e-05, 9.9998e-01, 2.9389e-06],\n",
      "        [1.0934e-06, 4.6778e-05, 9.9994e-01, 7.3205e-06],\n",
      "        [6.5337e-07, 2.6202e-05, 9.9997e-01, 4.0200e-06],\n",
      "        [6.6265e-07, 2.2362e-05, 9.9997e-01, 2.9754e-06],\n",
      "        [8.9813e-07, 3.1135e-05, 9.9996e-01, 8.9928e-06],\n",
      "        [9.9718e-07, 7.8586e-05, 9.9992e-01, 1.8874e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.7864e-09, 5.1654e-09, 1.1851e-06, 1.0000e+00],\n",
      "        [4.7517e-10, 4.3345e-10, 2.8301e-07, 1.0000e+00],\n",
      "        [1.1339e-09, 6.6566e-11, 2.0842e-08, 1.0000e+00],\n",
      "        [8.4725e-09, 1.0072e-09, 4.2856e-08, 1.0000e+00],\n",
      "        [1.3906e-09, 4.7884e-10, 9.3949e-08, 1.0000e+00],\n",
      "        [1.8920e-09, 5.9214e-10, 5.1640e-08, 1.0000e+00],\n",
      "        [1.0006e-09, 5.9310e-10, 3.3359e-07, 1.0000e+00],\n",
      "        [1.7303e-09, 3.5153e-09, 9.1942e-07, 1.0000e+00],\n",
      "        [1.1317e-09, 1.6705e-10, 3.1487e-08, 1.0000e+00],\n",
      "        [7.7277e-10, 9.7088e-11, 1.5251e-08, 1.0000e+00],\n",
      "        [1.5081e-09, 2.4753e-09, 4.9663e-07, 1.0000e+00],\n",
      "        [5.2265e-09, 3.8496e-09, 2.4611e-06, 1.0000e+00],\n",
      "        [7.9622e-08, 3.5896e-08, 8.2307e-06, 9.9999e-01],\n",
      "        [3.4977e-09, 5.3333e-10, 6.1002e-07, 1.0000e+00],\n",
      "        [1.4214e-09, 8.4933e-10, 4.1555e-07, 1.0000e+00],\n",
      "        [5.4916e-09, 2.5779e-09, 1.5510e-06, 1.0000e+00],\n",
      "        [3.0695e-09, 1.0210e-09, 7.0148e-07, 1.0000e+00],\n",
      "        [4.4975e-10, 1.2365e-09, 1.1084e-07, 1.0000e+00],\n",
      "        [2.7199e-10, 6.6632e-11, 1.8569e-08, 1.0000e+00],\n",
      "        [1.1647e-09, 2.9957e-10, 8.9508e-08, 1.0000e+00],\n",
      "        [1.4909e-09, 4.9999e-10, 1.0410e-07, 1.0000e+00],\n",
      "        [3.5516e-09, 2.6583e-09, 8.3630e-07, 1.0000e+00],\n",
      "        [3.1586e-10, 2.6059e-10, 5.8540e-09, 1.0000e+00],\n",
      "        [5.6774e-10, 3.5135e-10, 3.3470e-08, 1.0000e+00],\n",
      "        [1.5498e-09, 9.3707e-11, 5.0261e-08, 1.0000e+00],\n",
      "        [3.4783e-09, 1.6982e-10, 2.2116e-09, 1.0000e+00],\n",
      "        [2.5583e-10, 1.2650e-10, 7.3568e-09, 1.0000e+00],\n",
      "        [1.8610e-09, 5.0507e-10, 3.2136e-07, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(102.5053) tokens processed per second.\n",
      "['ayrılığın sınırlı ışığında¬ışıldar gözler¬dar gelir dünya¬sıkıcırtısız¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬bir gün¬', 'Şair sözün gösterer,¬Gözel gözün gösterer.¬ ⁇ ız özünle gösterer,¬Özel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer.¬Şair sözün gösterer,¬Gözel gözün gösterer', 'Ey yakarış¬Ey uyanış¬Ey sevgi¬Ey aşk¬Ey arayış¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬Ey aşk¬', 'ben ölsemde aşkım cümle alemde¬kulakdan kulaga yayılır belki¬ben ölsemde aşkım cümle alemde¬benle bir olup da ayrılır belki¬ben ölsemde aşkım cümle alemde¬benle bir olup da ayrılır belki¬ben ölsemde aşkım cümle alemde¬benle bir olup da ayrılır belki', 'Lale, sümbül, çiğdem, Nergizim derken,¬Hercai menekşe, çiğdem, nergis.¬Lale, sümbül, çiğdem, Nergizim derken,¬Hercai menekşe, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Lale, sümbül, çiğdem, çiğdem, çiğdem, çiğdem.¬Lale, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Lale, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem.¬Menekşe, sümbül, çiğdem, çiğdem, çiğdem.¬Menekşe,', 'herkes her şey¬yok hiçbir şey¬şey¬şey¬şey¬bir şey¬bir şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey¬şey', 'sak saklar gibi yaşımı¬Ihtıyarlığım işime bilmem¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬Bir gün olsun da bir gün olsun¬', 'Bu millet kimlerle gurur duymadı,¬Yurttaşa lan diyenleri alkışla...¬Bu millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet bir millet bir millet bir millet bir millet,¬Bu millet bir millet bir millet', 'Gülerken ağladım, gün yüzü görmedim¬Eller gibi dünyadan muradımı almadım¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim¬Bir gün olsun, bir gün olsun gülmedim', 'Kendi değiştirmek bazen bizim elimizde değilki¬Ve istiyorum¬Küçük bir evim olsun istiyorum¬Bir de bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir evim olsun istiyorum¬Bir de bir', 'İstanbullı Rum hastanesinden içeri¬Bir yaşlı kadın girdi üstelik Rum, Eminönü¬Bir de Eminönü’nün en güzel yerinde¬Bir de Eminönü’nde¬Bir de Eminönü’nde¬Bir de Eminönü’nde¬Bir de Eminönü’nde¬Bir de Eminönü’nde¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy’de¬Bir de Kadıköy', 'Güneşin kızıl yanakları allanınca¬Sürgün yüreklere¬Düşer sevdalar¬Asma suratlı¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir de¬Bir', 'Dışarısı ayaz¬Dışarısı beyaz¬Dışarısı buz¬Ağlamaklı¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬Dışarısı ayaz¬', 'Tesir etmez yağan kurşun,¬Allah diyen dilim varken,¬Kolay hesap olur işin,¬Allah diyen dilim varken.¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Allah diyen dilim varken.¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Allah diyen dilim varken.¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Allah diyen dilim varken.¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Allah diyen dilim varken.¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Hak yolunda can yoldaşım,¬Allah diyen dilim varken.', 'Gözlerim kapalı, hissetmiyorum dünyanın ahengini¬Adını duyuyorum ama, bilemiyorum¬Bir türlü çözemiyorum, çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü çözemiyorum¬Bir türlü', 'Mutluluk önünde bak,yakalamak zor,¬Seven sevilenin hep karşısında dur,¬Bu gönül seni çok, çok seviyor,¬Mutluluk senin için,çok zor.¬Mutluluk senin için,çok zor geliyor,¬Seven sevilenin hep karşısında dur,¬Bu gönül seni çok, çok seviyor,¬Mutluluk senin için,çok zor geliyor.', 'Ehlibeytim sevgim sana,¬Canım da can Ali, Ali.¬Bir ışık ver bana,¬Canım da can Ali, Ali.¬Bir gün gelir, gelirim,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.¬Senin için ölürüm,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.¬Senin için ölürüm,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.¬Senin için ölürüm,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.¬Senin için ölürüm,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.¬Senin için ölürüm,¬Senin için ölürüm,¬Senin için ölürüm,¬Canım da can Ali, Ali.', 'Oy Nazile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Şimdi gelir saz ile¬Oy Nazile¬Oy Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Şimdi gelir saz ile¬Saz ile Nazile¬Saz ile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Nazile¬Saz ile Naz', 'Bırakıp gidersen ben ben¬Sarhoş olur geceler birden¬Kör pınar gibi zamansız¬Ay dağları gibi¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir başıma¬Bir', 'İslam sancağını taşıyan sensin¬Yürü be Mehmet’im kim tutar seni¬Bu vatan uğruna can veren sensin¬Yürü be Mehmet’im kim tutar seni¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Yürü be Mehmet’im kim tutar seni¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Yürü be Mehmet’im kim tutar seni¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Sen ki bu milletin bir tekisin¬Yürü be Mehmet’im kim tutar seni']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss: tensor([[3.4629e-07, 1.0000e+00, 2.7159e-06, 2.7547e-07],\n",
      "        [1.3693e-05, 9.9975e-01, 2.3034e-04, 7.1837e-06],\n",
      "        [8.5408e-08, 9.9999e-01, 5.8753e-06, 5.7797e-07]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on real poetry tensor([[1.0000e+00, 3.5141e-11, 4.8570e-11, 3.9571e-09],\n",
      "        [1.0000e+00, 1.4033e-11, 6.1986e-12, 1.6762e-09],\n",
      "        [1.0000e+00, 7.6656e-11, 1.1023e-11, 2.1188e-09]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on scrambled tensor([[5.5091e-07, 2.2387e-05, 9.9997e-01, 2.4822e-06],\n",
      "        [1.3421e-06, 3.5875e-05, 9.9996e-01, 3.4647e-06],\n",
      "        [1.4542e-06, 1.6555e-05, 9.9998e-01, 2.5591e-06],\n",
      "        [3.0038e-07, 1.7039e-05, 9.9998e-01, 1.3524e-06],\n",
      "        [5.3318e-07, 4.4128e-05, 9.9995e-01, 6.1301e-06],\n",
      "        [1.3596e-06, 5.0304e-05, 9.9995e-01, 2.5272e-06],\n",
      "        [1.0718e-06, 2.7573e-05, 9.9997e-01, 1.8713e-06],\n",
      "        [2.4175e-06, 1.0826e-04, 9.9989e-01, 1.7930e-06],\n",
      "        [2.9790e-06, 4.3594e-05, 9.9994e-01, 8.6118e-06],\n",
      "        [1.4476e-07, 1.1656e-05, 9.9999e-01, 3.1476e-06],\n",
      "        [1.4799e-06, 3.9053e-05, 9.9995e-01, 6.2936e-06],\n",
      "        [6.0055e-07, 1.1798e-05, 9.9999e-01, 1.7677e-06],\n",
      "        [2.3466e-06, 4.7441e-05, 9.9994e-01, 1.4999e-05],\n",
      "        [5.2681e-07, 8.6034e-06, 9.9999e-01, 3.1354e-06],\n",
      "        [2.5042e-06, 7.5441e-05, 9.9992e-01, 6.2061e-06],\n",
      "        [9.7264e-07, 3.6847e-05, 9.9996e-01, 3.6962e-06],\n",
      "        [4.8524e-06, 1.8659e-04, 9.9979e-01, 1.4276e-05],\n",
      "        [9.7253e-07, 9.7945e-06, 9.9999e-01, 1.5506e-06],\n",
      "        [2.1337e-07, 4.8460e-06, 9.9999e-01, 1.2594e-06],\n",
      "        [5.2479e-07, 4.6916e-05, 9.9995e-01, 7.1062e-06],\n",
      "        [3.0834e-07, 1.8779e-05, 9.9998e-01, 2.7577e-06],\n",
      "        [1.6798e-06, 2.3399e-05, 9.9997e-01, 3.9923e-06],\n",
      "        [7.5489e-07, 3.7724e-05, 9.9996e-01, 6.2492e-06],\n",
      "        [1.6679e-05, 4.8867e-04, 9.9944e-01, 5.3316e-05],\n",
      "        [6.5396e-07, 2.4465e-05, 9.9997e-01, 7.1393e-06],\n",
      "        [3.2542e-06, 1.0183e-04, 9.9986e-01, 3.3421e-05],\n",
      "        [2.8032e-07, 2.9487e-05, 9.9997e-01, 3.4109e-06],\n",
      "        [3.7619e-07, 1.9282e-05, 9.9998e-01, 1.5802e-06],\n",
      "        [7.6104e-07, 3.1950e-05, 9.9996e-01, 7.0172e-06],\n",
      "        [5.0252e-06, 9.3440e-05, 9.9990e-01, 4.0119e-06],\n",
      "        [5.5007e-07, 8.2141e-06, 9.9999e-01, 1.0711e-06],\n",
      "        [6.2555e-07, 2.0302e-05, 9.9998e-01, 3.3694e-06],\n",
      "        [2.4003e-06, 4.6436e-05, 9.9995e-01, 8.9931e-07],\n",
      "        [3.9500e-07, 2.5124e-05, 9.9997e-01, 1.3288e-06],\n",
      "        [9.1832e-07, 2.5277e-05, 9.9997e-01, 4.1400e-06],\n",
      "        [2.5608e-07, 9.2646e-06, 9.9999e-01, 2.6980e-06],\n",
      "        [4.9002e-07, 2.4130e-05, 9.9997e-01, 3.2676e-06],\n",
      "        [7.7850e-07, 2.0094e-05, 9.9998e-01, 1.4532e-06],\n",
      "        [4.8852e-06, 4.5073e-05, 9.9993e-01, 1.6129e-05],\n",
      "        [2.4104e-07, 1.5385e-05, 9.9998e-01, 2.7524e-06],\n",
      "        [4.5647e-07, 2.9620e-05, 9.9997e-01, 3.2276e-06],\n",
      "        [1.4837e-06, 6.1229e-05, 9.9993e-01, 3.2472e-06],\n",
      "        [1.3628e-06, 1.6705e-05, 9.9998e-01, 4.5779e-06],\n",
      "        [1.5346e-05, 5.3300e-04, 9.9940e-01, 4.9788e-05],\n",
      "        [9.1352e-07, 2.1096e-05, 9.9997e-01, 6.0018e-06],\n",
      "        [1.0007e-06, 3.3655e-05, 9.9996e-01, 5.4615e-06],\n",
      "        [1.1507e-06, 2.2050e-05, 9.9997e-01, 7.0638e-06],\n",
      "        [6.5128e-07, 2.8726e-05, 9.9994e-01, 3.0949e-05],\n",
      "        [8.5023e-07, 2.1858e-05, 9.9997e-01, 3.1072e-06],\n",
      "        [1.8696e-06, 3.2086e-05, 9.9994e-01, 3.0138e-05],\n",
      "        [5.1000e-07, 3.3371e-05, 9.9996e-01, 1.4510e-06],\n",
      "        [9.2893e-07, 3.1740e-05, 9.9996e-01, 3.2948e-06],\n",
      "        [2.6854e-07, 1.7827e-05, 9.9998e-01, 2.9656e-06],\n",
      "        [3.0174e-07, 1.3626e-05, 9.9998e-01, 1.5906e-06],\n",
      "        [8.4135e-07, 1.8036e-05, 9.9998e-01, 5.4157e-06],\n",
      "        [9.1304e-06, 8.2065e-05, 9.9991e-01, 1.7359e-06],\n",
      "        [4.9178e-07, 3.2479e-05, 9.9996e-01, 2.4854e-06],\n",
      "        [1.5280e-07, 1.3810e-05, 9.9998e-01, 1.0706e-06],\n",
      "        [2.5529e-07, 1.3796e-05, 9.9998e-01, 1.8874e-06],\n",
      "        [6.7175e-07, 1.4062e-05, 9.9998e-01, 2.0181e-06],\n",
      "        [1.1554e-07, 1.1580e-05, 9.9999e-01, 1.2896e-06],\n",
      "        [7.0388e-07, 3.5296e-05, 9.9996e-01, 3.4456e-06],\n",
      "        [5.6149e-07, 2.1252e-05, 9.9997e-01, 4.9253e-06],\n",
      "        [5.6833e-07, 1.1221e-05, 9.9998e-01, 3.2549e-06],\n",
      "        [2.4245e-07, 1.2938e-05, 9.9998e-01, 1.8669e-06],\n",
      "        [6.6062e-07, 3.4006e-05, 9.9996e-01, 5.2958e-06],\n",
      "        [8.6585e-07, 2.3379e-05, 9.9997e-01, 3.6057e-06],\n",
      "        [3.9888e-07, 1.6756e-05, 9.9998e-01, 1.3632e-06],\n",
      "        [6.1759e-07, 2.7279e-05, 9.9997e-01, 3.4231e-06],\n",
      "        [2.7336e-07, 2.4901e-05, 9.9997e-01, 8.7132e-06],\n",
      "        [1.0543e-06, 2.6055e-05, 9.9997e-01, 5.3084e-06],\n",
      "        [1.3130e-06, 1.4507e-05, 9.9998e-01, 2.1144e-06],\n",
      "        [1.4480e-06, 2.1998e-05, 9.9997e-01, 2.3086e-06]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "Discriminator prediction on prose tensor([[4.1449e-09, 2.4745e-09, 1.3802e-06, 1.0000e+00],\n",
      "        [2.1706e-09, 2.9536e-09, 5.3772e-06, 9.9999e-01],\n",
      "        [6.6941e-10, 4.3904e-10, 2.7926e-07, 1.0000e+00],\n",
      "        [3.4125e-10, 1.7191e-10, 8.2676e-09, 1.0000e+00],\n",
      "        [3.6217e-09, 8.3990e-10, 7.1554e-07, 1.0000e+00],\n",
      "        [1.0019e-09, 5.9564e-10, 1.9068e-07, 1.0000e+00],\n",
      "        [2.3363e-10, 1.1025e-10, 1.4781e-08, 1.0000e+00],\n",
      "        [3.6837e-08, 5.4776e-10, 2.3075e-08, 1.0000e+00],\n",
      "        [8.5649e-10, 3.1445e-10, 6.0921e-08, 1.0000e+00],\n",
      "        [9.3106e-10, 5.5403e-11, 4.6247e-09, 1.0000e+00],\n",
      "        [1.1996e-09, 3.3972e-09, 5.3455e-06, 9.9999e-01],\n",
      "        [3.1763e-09, 2.3499e-09, 1.7016e-06, 1.0000e+00],\n",
      "        [5.1192e-10, 5.5337e-11, 2.0364e-09, 1.0000e+00],\n",
      "        [1.6250e-09, 7.0851e-10, 3.4546e-08, 1.0000e+00],\n",
      "        [1.1570e-09, 6.0349e-10, 3.3455e-07, 1.0000e+00],\n",
      "        [8.7522e-10, 1.3676e-10, 1.6799e-08, 1.0000e+00],\n",
      "        [1.4304e-09, 4.0367e-10, 4.7699e-08, 1.0000e+00],\n",
      "        [2.0132e-08, 5.2008e-09, 1.5114e-05, 9.9998e-01],\n",
      "        [4.3658e-10, 1.0032e-10, 8.3599e-09, 1.0000e+00],\n",
      "        [8.4835e-10, 1.3427e-10, 2.0186e-08, 1.0000e+00],\n",
      "        [1.9037e-08, 4.6289e-09, 1.9197e-07, 1.0000e+00],\n",
      "        [2.1887e-08, 1.7359e-08, 1.0410e-04, 9.9990e-01],\n",
      "        [8.1174e-10, 1.2345e-10, 6.3306e-09, 1.0000e+00],\n",
      "        [2.1819e-10, 5.3162e-11, 5.4436e-10, 1.0000e+00],\n",
      "        [1.0532e-09, 5.9056e-10, 4.5179e-07, 1.0000e+00],\n",
      "        [6.0975e-10, 5.0256e-10, 1.6350e-07, 1.0000e+00],\n",
      "        [1.7630e-09, 1.3277e-09, 9.8657e-07, 1.0000e+00],\n",
      "        [5.9085e-10, 1.6282e-10, 1.4697e-08, 1.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor(101.9036) tokens processed per second.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "start = time.time()\n",
    "all_tokens = 0\n",
    "for c, (poetry_batch, prose_batch, scrambled_batch) in enumerate(zip(rebatched, prose_iter, scrambled_iter)):\n",
    "    enc_dec_opt.optimizer.zero_grad()\n",
    "    token_optim.zero_grad()\n",
    "    all_tokens += poetry_batch.ntokens\n",
    "    tgt, tgt_mask = poetry_batch.trg.to(device), poetry_batch.trg_mask.to(device)\n",
    "    # classify tokens, get the first 15 tokens selected.\n",
    "    dae_input = get_dae_input(poetry_batch.trg, token_selector).transpose(0,1).to(device)\n",
    "    # create src and src mask from selected tokens\n",
    "    dae_input_mask = (dae_input != 3).unsqueeze(-2)\n",
    "    \n",
    "    # get output of poetry generator\n",
    "    #output_embeds = enc_dec.forward(dae_input, tgt, dae_input_mask, tgt_mask)\n",
    "    #output = enc_dec.generator(output_embeds)\n",
    "    #reconstruction_loss = label_smoothing(output.contiguous().view(-1, output.size(-1)),\n",
    "    #                         poetry_batch.trg_y.to(device).contiguous().view(-1)) / poetry_batch.ntokens\n",
    "    #reconstruction_loss.backward()\n",
    "    \n",
    "    # critic output\n",
    "    output_selected = greedy_generate(enc_dec, dae_input)\n",
    "    critic_scores = soft(style_critic.generator(style_critic.forward(output_selected.to(device), \n",
    "                                            (output_selected != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "\n",
    "    critic_loss = style_criterion(critic_scores[:, 0], torch.ones((critic_scores.shape[0])).to(device))\n",
    "    critic_loss.backward()\n",
    "    \n",
    "    \n",
    "    token_optim.step() \n",
    "    enc_dec_opt.step()\n",
    "    \n",
    "    # train critic (real, fake, scrambled, prose)\n",
    "    style_optim.zero_grad()\n",
    "\n",
    "    real_scores = soft(style_critic.generator(style_critic.forward(poetry_batch.trg_y.to(device), \n",
    "                                            (poetry_batch.trg_y != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    crit_bce = style_criterion(real_scores[:, 0], torch.ones((tgt.shape[0])).to(device))\n",
    "    \n",
    "    gen_scores = soft(style_critic.generator(style_critic.forward(output_selected.to(device), \n",
    "                                            (output_selected != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    crit_bce += style_criterion(gen_scores[:, 1], torch.ones((tgt.shape[0])).to(device))\n",
    "    \n",
    "    scramb_scores = soft(style_critic.generator(style_critic.forward(scrambled_batch.src.transpose(0,1).to(device),\n",
    "                                            (scrambled_batch.src.transpose(0,1) != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    crit_bce += style_criterion(scramb_scores[:, 2], torch.ones((scramb_scores.shape[0])).to(device))\n",
    "    \n",
    "    prose_scores = soft(style_critic.generator(style_critic.forward(prose_batch.src.transpose(0,1).to(device),\n",
    "                            (prose_batch.src.transpose(0,1) != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    crit_bce += style_criterion(prose_scores[:, 3], torch.ones((prose_scores.shape[0])).to(device))\n",
    "    crit_bce.backward()\n",
    "    style_optim.step()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if c % 10  == 0:\n",
    "        #print(\"Reconstruction loss:\", reconstruction_loss)\n",
    "        print(\"Discriminator loss:\", critic_scores)\n",
    "        print(\"Discriminator prediction on real poetry\", real_scores)\n",
    "        print(\"Discriminator prediction on scrambled\", scramb_scores)\n",
    "        print(\"Discriminator prediction on prose\", prose_scores)\n",
    "        print(all_tokens / (time.time() - start), \"tokens processed per second.\")\n",
    "        #print(torch.mean(gen_scores[:, 1]))\n",
    "        if c % 500 == 0:\n",
    "            val_src = get_dae_input(toyset.transpose(0, 1), token_selector).transpose(0,1).to(device)\n",
    "            validated = greedy_generate(enc_dec, val_src)\n",
    "            print([tok.Decode(x.tolist()) for x in validated])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f6688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d392ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d2307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a786bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4de57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6925e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700729aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc6ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d916387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
