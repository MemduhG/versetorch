{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca660e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6752d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9385901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t  jupyter.o7280433  prose_translations\ttranslations\r\n",
      "checkpoints\t  jupyter.o7284871  requirements.txt\tvenv\r\n",
      "data\t\t  jupyter.o7285616  runs\t\tvt-tr.o7146959\r\n",
      "jupyter.o7250076  logs\t\t    scripts\t\tvt-tr.o7209762\r\n",
      "jupyter.o7272725  notebooks\t    src\t\t\tvt-tr.o7242335\r\n",
      "jupyter.o7277176  out.txt\t    training\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474d6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fcc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils.batch import rebatch\n",
    "from src.data_utils.data import get_training_iterators\n",
    "from src.model.loss_optim import MultiGPULossCompute, SimpleLossCompute\n",
    "from src.model.model import make_model, NoamOpt, LabelSmoothing, translate_sentence\n",
    "from src.utils.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "853e827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = get_tokenizer(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2094ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: MyIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter, valid_iter, test_iter, train_idx, dev_idx, test_idx = get_training_iterators(\"tur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a76160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe2d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini dev set\n",
    "with open(\"data/tr/tur.dev.tgt\", encoding=\"utf-8\") as infile:\n",
    "    toystrings = [x.strip() for x in infile.readlines()[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e9227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toyset = [torch.LongTensor([1] + tok.Encode(x) + [2])  for x in toystrings]\n",
    "toyset = torch.nn.utils.rnn.pad_sequence(sequences=toyset, padding_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0c8188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
       "        [ 5605,     8,  1330,  ...,     8,   771,  2804],\n",
       "        [27861,  2475, 10284,  ...,  3987,  5057, 11694],\n",
       "        ...,\n",
       "        [    3,     3,     3,  ...,     3,     3,     3],\n",
       "        [    3,     3,     3,  ...,     3,     3,     3],\n",
       "        [    3,     3,     3,  ...,     3,     3,     3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa5a24",
   "metadata": {},
   "source": [
    "Two critics:\n",
    "- Input related to output or not\n",
    "- Classifier into poetry, prose, generated, scrambled poetry\n",
    "\n",
    "One word/token selector:\n",
    "- Choose tokens from input sequence to use for topic\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b709c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "import torchtext as tt\n",
    "from src.data_utils.batch import MyIterator\n",
    "from src.model.model import batch_size_val\n",
    "\n",
    "def each_line(fname):\n",
    "    c = 0\n",
    "    lines = []\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as infile:\n",
    "        for line in infile:\n",
    "            if line.count(\" \") > 200 or line.count(\" \") < 10:\n",
    "                continue\n",
    "            lines.append(line.strip())\n",
    "            c += 1\n",
    "            if c >= 2000000: \n",
    "                break\n",
    "    return lines\n",
    "\n",
    "def make_iter(lines, tokenizer, batch_size=256):\n",
    "    \n",
    "    def tok(seq):\n",
    "        return tokenizer.EncodeAsIds(seq)\n",
    "\n",
    "    field = data.Field(tokenize=tok, init_token=1, eos_token=2, pad_token=3, use_vocab=False)\n",
    "    #ds = data.TabularDataset(fpath, \"tsv\", [(\"src\", field)], skip_header=True)\n",
    "\n",
    "    examples = [tt.data.Example.fromdict({\"src\": x}, {\"src\": (\"src\", field)}) for x in lines]\n",
    "    ds = tt.data.Dataset(examples, {\"src\": field})\n",
    "    iter = MyIterator(ds, batch_size=batch_size, device=\"cpu\",\n",
    "                             repeat=False, sort_key=lambda x: len(x.src),\n",
    "                             batch_size_fn=batch_size_val, train=False, sort=True)\n",
    "\n",
    "    return iter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b8dcd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prose_iter = make_iter(each_line(\"data/tr/prose/prose_gan.txt\"), tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb60edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "to_scramble = each_line(\"data/tr/tur.train.tgt\")\n",
    "scrambled = []\n",
    "for poem in to_scramble:\n",
    "    new_poem = poem.split(\"¬\")\n",
    "    random.shuffle(new_poem)\n",
    "    scrambled.append(\"¬\".join(new_poem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrambled_iter = make_iter(scrambled, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a3757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbaa96c4",
   "metadata": {
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68c72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd4ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from src.model.model import MultiHeadedAttention, PositionwiseFeedForward, \\\n",
    "                    PositionalEncoding, Encoder, EncoderLayer, Generator, Embeddings\n",
    "import torch.nn as nn\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, src_embed, generator):\n",
    "        super(Critic, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        self.generator = generator\n",
    "        self.steps = 0\n",
    "\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"Pass the input (and mask) through each layer in turn.\"\"\"\n",
    "        x = self.src_embed(x)\n",
    "        for layer in self.encoder.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.encoder.norm(x)    \n",
    "\n",
    "\n",
    "def make_critic(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"\"\"Helper: Construct a model from hyper-parameters.\"\"\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    generator = Generator(d_model, tgt_vocab)\n",
    "    embed = nn.Sequential(Embeddings(d_model, src_vocab), c(position))\n",
    "    encoder = Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N)\n",
    "    critic = Critic(encoder, embed, generator)\n",
    "    \n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in critic.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "\n",
    "    return critic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01ac364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/plzen1/home/memduh/versetorch/src/model/model.py:264: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n",
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "ntokens = 32000\n",
    "enc_dec = make_model(ntokens, ntokens, N=6).to(device)\n",
    "token_selector = make_critic(ntokens, 2, N=2).to(device)\n",
    "style_critic = make_critic(ntokens, 4, N=2).to(device)\n",
    "relevance_critic = make_critic(ntokens + 1, 1, N=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d1f2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "\n",
    "def prep_tensors( src, trg, pad=3):\n",
    "    src_mask = (src != pad).unsqueeze(-2)\n",
    "    trg_in = trg[:, :-1]\n",
    "    trg_y = trg[:, 1:]\n",
    "    trg_mask = make_std_mask(trg_in, pad)\n",
    "    return src, trg_y, src_mask, trg_mask\n",
    "\n",
    "def make_std_mask(tgt, pad):\n",
    "    \"\"\"Create a mask to hide padding and future words.\"\"\"\n",
    "    tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "    tgt_mask = tgt_mask & Variable(\n",
    "        subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "    return tgt_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76a60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb11ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e1e475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f519b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a93f0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dae_input(tgt, token_selector):\n",
    "    select_prob_embeds = token_selector.forward(tgt.to(device), \n",
    "                                         (tgt != 3).unsqueeze(-2).to(device))\n",
    "    select_prob = token_selector.generator(select_prob_embeds)\n",
    "    select_indices = torch.max(select_prob, dim=2).indices.type(torch.ByteTensor)\n",
    "    dae_list = []\n",
    "    for ind, row in zip(select_indices, tgt):\n",
    "        dae_list.append(torch.masked_select(row, ind)[:15])\n",
    "    dae_input = torch.nn.utils.rnn.pad_sequence(dae_list, batch_first=False, padding_value=3)\n",
    "    return dae_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc47b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc8eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55acd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740266cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebatched = (rebatch(3, b) for b in train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa72320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548db73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.adafactor import Adafactor\n",
    "\n",
    "enc_dec_opt = NoamOpt(enc_dec.src_embed[0].d_model, 1, 2000,\n",
    "                        torch.optim.Adam(enc_dec.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "style_criterion = nn.BCELoss()\n",
    "relevance_criterion = nn.BCELoss()\n",
    "\n",
    "token_optim = Adafactor(token_selector.parameters())\n",
    "style_optim = Adafactor(style_critic.parameters())\n",
    "rel_optim = Adafactor(relevance_critic.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563f360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea9a064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance_input(dae_input, tgt):\n",
    "    mid_point = torch.ones((tgt.shape[0], 1), dtype=torch.long) * ntokens\n",
    "    return torch.cat((dae_input, mid_point.to(device), tgt), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9115fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/auto/praha1/memduh/versetorch/venv/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:733.)\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main model loss: tensor(1.3793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Main model loss: tensor(1.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "soft = torch.nn.Softmax(dim=1)\n",
    "for c, (poetry_batch, prose_batch, scrambled_batch) in enumerate(zip(rebatched, prose_iter, scrambled_iter)):\n",
    "    #zero_grad\n",
    "    enc_dec_opt.optimizer.zero_grad()\n",
    "    token_optim.zero_grad()\n",
    "    rel_optim.zero_grad()\n",
    "    style_optim.zero_grad()\n",
    "\n",
    "    \n",
    "    tgt, tgt_mask = poetry_batch.trg.to(device), poetry_batch.trg_mask.to(device)\n",
    "    # classify tokens, get the first 15 tokens selected.\n",
    "    dae_input = get_dae_input(poetry_batch.trg, token_selector).transpose(0,1).to(device)\n",
    "    # create src and src mask from selected tokens\n",
    "    dae_input_mask = (dae_input != 3).unsqueeze(-2)\n",
    "    # get output of poetry generator\n",
    "    output_embeds = enc_dec.forward(dae_input, tgt, dae_input_mask, tgt_mask)\n",
    "    # put through its generator, choose likeliest token\n",
    "    output = enc_dec.generator(output_embeds)\n",
    "    # torch.max that stuff\n",
    "    _, output_selected = torch.max(output, 2)\n",
    "    \n",
    "    #create rel critic input by concatenating dae input and tgt\n",
    "    rel_input = get_relevance_input(dae_input, tgt)\n",
    "    # get critic losses\n",
    "    style_scores = soft(style_critic.generator(style_critic.forward(output_selected.to(device), \n",
    "                                        (output_selected != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    rel_output = relevance_critic.generator(relevance_critic.forward(rel_input.to(device), \n",
    "                                        (rel_input != 3).unsqueeze(-2).to(device)))\n",
    "    relevance_scores = rel_output[:,0,:]\n",
    "    \n",
    "    style_loss = style_criterion(style_scores[:, 0], torch.ones((style_scores.shape[0])).to(device))\n",
    "    try:\n",
    "        relevance_loss = relevance_criterion(relevance_scores.squeeze(), \n",
    "                                         torch.ones(relevance_scores.shape[0]).to(device))\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    enc_dec_loss = style_loss + relevance_loss\n",
    "    enc_dec_loss.backward()\n",
    "    enc_dec_opt.step()\n",
    "    token_optim.step()\n",
    "\n",
    "    # samples and classes for relevance critic\n",
    "    \n",
    "    scramb_rel_input = get_relevance_input(dae_input[torch.randperm(dae_input.shape[0]), :], tgt)\n",
    "    scrambled_relevance_scores = relevance_critic.generator(relevance_critic.forward(scramb_rel_input.to(device), \n",
    "                                        (scramb_rel_input != 3).unsqueeze(-2).to(device)))[:,0,:]\n",
    "    rel_crit_loss = relevance_criterion(scrambled_relevance_scores.squeeze(), \n",
    "                                         torch.zeros(scrambled_relevance_scores.shape[0]).to(device))\n",
    "    rel_crit_loss.backward()\n",
    "    rel_optim.step()\n",
    "    \n",
    "    # samples and classes for style critic\n",
    "    # trg is poetry, prose batch is prose, model output is generated, scramble poetry lines for scrambled.\n",
    "    \n",
    "    # generated poetry\n",
    "    gen_scores = soft(style_critic.generator(style_critic.forward(output_selected.to(device), \n",
    "                                        (output_selected != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    gen_loss = style_criterion(gen_scores[:, 1], torch.ones((style_scores.shape[0])).to(device))\n",
    "\n",
    "    # real poetry \n",
    "    real_scores = soft(style_critic.generator(style_critic.forward(tgt.to(device), \n",
    "                                        (tgt != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    \n",
    "    real_loss = style_criterion(real_scores[:, 0], torch.ones((style_scores.shape[0])).to(device))\n",
    "    \n",
    "    \n",
    "    # scrambled poetry\n",
    "    scramb_scores = soft(style_critic.generator(style_critic.forward(scrambled_batch.src.transpose(0,1).to(device), \n",
    "                                        (scrambled_batch.src.transpose(0,1) != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    scramb_loss = style_criterion(scramb_scores[:, 2], torch.ones((scramb_scores.shape[0])).to(device))\n",
    "\n",
    "    # prose\n",
    "    prose_scores = soft(style_critic.generator(style_critic.forward(prose_batch.src.transpose(0,1).to(device), \n",
    "                                        (prose_batch.src.transpose(0,1) != 3).unsqueeze(-2).to(device)))[:,0,:])\n",
    "    prose_loss = style_criterion(prose_scores[:, 3], torch.ones((prose_scores.shape[0])).to(device))\n",
    "    \n",
    "    gen_loss.backward()\n",
    "    real_loss.backward()\n",
    "    scramb_loss.backward()\n",
    "    prose_loss.backward()\n",
    "    style_optim.step()\n",
    "    \n",
    "    if c% 50 == 0:\n",
    "        print(\"Main model loss:\", enc_dec_loss)\n",
    "        print(torch.mean(gen_scores[:, 1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f6688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d392ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d2307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a786bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4de57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6925e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700729aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc6ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d916387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
